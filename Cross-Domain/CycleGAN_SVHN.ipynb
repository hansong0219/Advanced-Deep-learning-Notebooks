{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN_SVHN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansong0219/Advanced-DeepLearning-Study/blob/master/Cross-Domain/CycleGAN_SVHN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi8IE66ovE8z"
      },
      "source": [
        "# CycleGAN MNIST - SVHN 교차 도메인\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61OVcbtVYpZ4"
      },
      "source": [
        "이전 Coloration Cycle GAN 에서 Data Set 의 종류만 바꾼 코드이다. Instance Normalization 을 사용하기 위해서는 tensorflow-addons 을 설치해야 한다.\n",
        "\n",
        "Data 처리 부분과 CycleGAN 의 모델 설정 부분 만 변환한 케이스이다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUxgtHEFvRH8"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from tensorflow.keras.layers import Input, Dropout, concatenate, add\n",
        "from tensorflow.keras.layers import Conv2DTranspose, Conv2D \n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LeakyReLU, Activation\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from scipy import io\n",
        "\n",
        "import cv2\n",
        "import math\n",
        "import datetime\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frQX6tMF62ZI"
      },
      "source": [
        "#GPU 할당"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAMUlhs46vH1"
      },
      "source": [
        "import tensorflow as tf \n",
        "physical_devices =tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BrVc7v34xjP"
      },
      "source": [
        "#유틸 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q-w6cuK3Oz6"
      },
      "source": [
        "def display_images(imgs, filename, title='', imgs_dir=None, show=False):\n",
        "  \n",
        "    #이미지를 nxn 으로 나타냄\n",
        "    rows = imgs.shape[1]\n",
        "    cols = imgs.shape[2]\n",
        "    channels = imgs.shape[3]\n",
        "    side = int(math.sqrt(imgs.shape[0]))\n",
        "    assert int(side * side) == imgs.shape[0]\n",
        "\n",
        "    # 이미지 저장을 위한 폴더를 만듦\n",
        "    if imgs_dir is None:\n",
        "        imgs_dir = 'saved_images'\n",
        "    save_dir = os.path.join(os.getcwd(), imgs_dir)\n",
        "    if not os.path.isdir(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    filename = os.path.join(imgs_dir, filename)\n",
        "    # 이미지의 shape 을 지정\n",
        "    if channels==1:\n",
        "        imgs = imgs.reshape((side, side, rows, cols))\n",
        "    else:\n",
        "        imgs = imgs.reshape((side, side, rows, cols, channels))\n",
        "    imgs = np.vstack([np.hstack(i) for i in imgs])\n",
        "    plt.figure()\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    if channels==1:\n",
        "        plt.imshow(imgs, interpolation='none', cmap='gray')\n",
        "    else:\n",
        "        plt.imshow(imgs, interpolation='none')\n",
        "    plt.savefig(filename)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    \n",
        "    plt.close('all')\n",
        "\n",
        "\n",
        "def test_generator(generators, test_data, step, titles, dirs, todisplay=100, show=False):\n",
        "    # generator 모델을 테스트함\n",
        "    # 입력 인수\n",
        "    \"\"\"\n",
        "    generators (tuple): 소스와 타겟 생성기\n",
        "    test_data (tuple): 소스와 타겟 데이터\n",
        "    step (int): 진행 단계\n",
        "    titles (tuple): 표시 이미지의 타이틀\n",
        "    dirs (tuple): 이미지 저장 폴더\n",
        "    todisplay (int): 저장이미지의 수 (정사각형 형태로 생성되어야 한다.)\n",
        "    show (bool): 이미지 표시 여부\n",
        "    \"\"\"\n",
        "\n",
        "    # test data 로 부터 output 예측\n",
        "    g_source, g_target = generators\n",
        "    test_source_data, test_target_data = test_data\n",
        "    t1, t2, t3, t4 = titles\n",
        "    title_pred_source = t1\n",
        "    title_pred_target = t2\n",
        "    title_reco_source = t3\n",
        "    title_reco_target = t4\n",
        "    dir_pred_source, dir_pred_target = dirs\n",
        "\n",
        "    pred_target_data = g_target.predict(test_source_data)\n",
        "    pred_source_data = g_source.predict(test_target_data)\n",
        "    reco_source_data = g_source.predict(pred_target_data)\n",
        "    reco_target_data = g_target.predict(pred_source_data)\n",
        "\n",
        "    # 정사각형 형태의 하나의 이미지로 나타냄\n",
        "    imgs = pred_target_data[:todisplay]\n",
        "    filename = '%06d.png' % step\n",
        "    step = \" Step: {:,}\".format(step)\n",
        "    title = title_pred_target + step\n",
        "    display_images(imgs,\n",
        "                   filename=filename,\n",
        "                   imgs_dir=dir_pred_target,\n",
        "                   title=title,\n",
        "                   show=show)\n",
        "\n",
        "    imgs = pred_source_data[:todisplay]\n",
        "    title = title_pred_source\n",
        "    display_images(imgs,\n",
        "                   filename=filename,\n",
        "                   imgs_dir=dir_pred_source,\n",
        "                   title=title,\n",
        "                   show=show)\n",
        "\n",
        "    imgs = reco_source_data[:todisplay]\n",
        "    title = title_reco_source\n",
        "    filename = \"reconstructed_source.png\"\n",
        "    display_images(imgs,\n",
        "                   filename=filename,\n",
        "                   imgs_dir=dir_pred_source,\n",
        "                   title=title,\n",
        "                   show=show)\n",
        "\n",
        "    imgs = reco_target_data[:todisplay]\n",
        "    title = title_reco_target\n",
        "    filename = \"reconstructed_target.png\"\n",
        "    display_images(imgs,\n",
        "                   filename=filename,\n",
        "                   imgs_dir=dir_pred_target,\n",
        "                   title=title,\n",
        "                   show=show)\n",
        "\n",
        "\n",
        "def loaded_data(data, titles, filenames, todisplay=100):\n",
        "    source_data, target_data, test_source_data, test_target_data = data\n",
        "    test_source_filename, test_target_filename = filenames\n",
        "    test_source_title, test_target_title = titles\n",
        "\n",
        "    # 테스트 타겟 이미지 표시\n",
        "    imgs = test_target_data[:todisplay]\n",
        "    display_images(imgs,\n",
        "                   filename=test_target_filename,\n",
        "                   title=test_target_title)\n",
        "\n",
        "    # 테스트 소스이미지 표시\n",
        "    imgs = test_source_data[:todisplay]\n",
        "    display_images(imgs,\n",
        "                   filename=test_source_filename,\n",
        "                   title=test_source_title)\n",
        "\n",
        "    # 이미지 표시 정리\n",
        "    target_data = target_data.astype('float32')  / 255\n",
        "    test_target_data = test_target_data.astype('float32') / 255\n",
        "\n",
        "    source_data = source_data.astype('float32')  / 255\n",
        "    test_source_data = test_source_data.astype('float32') / 255\n",
        "\n",
        "    # 소스, 타겟, 테스트 데이터\n",
        "    data = (source_data, target_data, test_source_data, test_target_data)\n",
        "\n",
        "    rows = source_data.shape[1]\n",
        "    cols = source_data.shape[2]\n",
        "    channels = source_data.shape[3]\n",
        "    source_shape = (rows, cols, channels)\n",
        "\n",
        "    rows = target_data.shape[1]\n",
        "    cols = target_data.shape[2]\n",
        "    channels = target_data.shape[3]\n",
        "    target_shape = (rows, cols, channels)\n",
        "\n",
        "    shapes = (source_shape, target_shape)\n",
        "    \n",
        "    return data, shapes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrJItE7PvWUk"
      },
      "source": [
        "# 모델 함수 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPE8N9EFdtsS"
      },
      "source": [
        "#모델 구성 단위 블럭 정의\n",
        "def encoder_layer(inputs, filters=16, kernel_size=3, strides=2, activation='relu', instance_norm=True):\n",
        "  # Conv2D - IN - LeakyReLU 로 구성된 일반 인코더 계층을 구성한다.\n",
        "  conv = Conv2D(filters=filters,kernel_size=kernel_size, strides=strides, padding='same')\n",
        "  x = inputs\n",
        "  if instance_norm:\n",
        "    x = InstanceNormalization()(x)\n",
        "  if activation == 'relu':\n",
        "    x = Activation('relu')(x)\n",
        "  else:\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = conv(x)\n",
        "  return x\n",
        "\n",
        "def decoder_layer(inputs, paired_inputs, filters=16, kernel_size=3, strides=2,activation='relu', instance_norm=True):\n",
        "  #Conv2DTranspose-IN-LeakyReLU로 구성된 디코더 계층구성, 활성화 함수는 ReLU 로 교체될 수 있음\n",
        "  #paired_inputs 는 U-net 의 skip connection 을 의미하며 입력에 연결된다.\n",
        "\n",
        "  conv=Conv2DTranspose(filters=filters,kernel_size=kernel_size, strides=strides, padding='same')\n",
        "  \n",
        "  x = inputs\n",
        "  if instance_norm:\n",
        "    x = InstanceNormalization()(x)\n",
        "  if activation=='relu':\n",
        "    x = Activation('relu')(x)\n",
        "  else:\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = conv(x)\n",
        "  x = concatenate([x, paired_inputs])\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH2rvu07pdgf"
      },
      "source": [
        "#생성기 U-Net Build\n",
        "def build_generator(input_shape, output_shape=None, kernel_size=3, name=None):\n",
        "  # 4계층 인코더와 4계층 디코더로 구성된 U-Net 을 구성한다.\n",
        "\n",
        "  inputs = Input(shape=input_shape)\n",
        "  channels = int(output_shape[-1])\n",
        "\n",
        "  e1 = encoder_layer(inputs, filters=32, kernel_size=kernel_size, activation='leaky_relu', strides=1)\n",
        "  e2 = encoder_layer(e1, filters=64, kernel_size= kernel_size, activation='leaky_relu')\n",
        "  e3 = encoder_layer(e2, filters=128, kernel_size= kernel_size, activation='leaky_relu')\n",
        "  e4 = encoder_layer(e3, filters=128, kernel_size= kernel_size, activation='leaky_relu')\n",
        "\n",
        "  d1 = decoder_layer(e4,e3,filters=128,kernel_size=kernel_size)\n",
        "  d2 = decoder_layer(d1,e2,filters=64,kernel_size=kernel_size)\n",
        "  d3 = decoder_layer(d2,e1,filters=64,kernel_size=kernel_size)\n",
        "\n",
        "  outputs = Conv2DTranspose(channels, kernel_size=kernel_size, strides=1, activation='sigmoid',padding='same')(d3)\n",
        "\n",
        "  generator = Model(inputs, outputs, name=name)\n",
        "  \n",
        "  return generator\n",
        "\n",
        "#PatchGAN Discriminator Build\n",
        "def build_discriminator(input_shape,kernel_size=3, patchgan=True,name=None):\n",
        "  inputs = Input(shape=input_shape)\n",
        "  x = encoder_layer(inputs,32,kernel_size=kernel_size,activation='leaky_relu',instance_norm=False)\n",
        "  x = encoder_layer(x, 64,kernel_size=kernel_size,activation='leaky_relu',instance_norm=False)\n",
        "  x = encoder_layer(x, 128,kernel_size=kernel_size,activation='leaky_relu',instance_norm=False)\n",
        "  x = encoder_layer(x, 256,kernel_size=kernel_size,activation='leaky_relu',instance_norm=False)\n",
        "\n",
        "  #patchgan=True 이면 n x n 차원 확률 출력 사용\n",
        "  if patchgan:\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    outputs = Conv2D(1, kernel_size=kernel_size, strides=1, padding='same')(x)\n",
        "  else:\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1)(x)\n",
        "    outputs - Activation('linear')(x)\n",
        "\n",
        "  discriminator = Model(inputs, outputs, name=name)\n",
        "\n",
        "  return discriminator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KImz4AJKt0Tz"
      },
      "source": [
        "# CycleGAN Build 함수 지정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0SaD3MCk6xX"
      },
      "source": [
        "아래에서 동질성 Loss identify 는 색상을 재현하는데 있어, 발생한 문제에 대해 본래의 색상을 찾아가도록 훈련시키는 과정이다. 이를 위해 타겟데이터 y 가 들어왔을 때 본래 이미지로 재구성할 수 있는 능력을 훈련시키는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCfN1_ozt2X4"
      },
      "source": [
        "def build_cyclegan(shape, source_name='source', target_name='target', kernel_size=3, patchgan=False, identify=False):\n",
        "  #Cycle GAN 의 구성\n",
        "  \"\"\"\n",
        "  1) 타깃과 소스의 판별기\n",
        "  2) 타깃과 소스의 생성기\n",
        "  3) 적대적 네트워크 구성\n",
        "  \"\"\"\n",
        "\n",
        "  #입력 인수\n",
        "  \"\"\"\n",
        "  shape(tuple): 소스와 타깃 형상\n",
        "  source_name (string): 판별기/생성기 모델 이름 뒤에 붙는 소스이름 문자열\n",
        "  target_name (string): 판별기/생성기 모델 이름 뒤에 붙는 타깃이름 문자열\n",
        "  target_size (int): 인코더/디코더 혹은 판별기/생성기 모델에 사용될 커널 크기\n",
        "  patchgan(bool): 판별기에 patchgan 사용 여부\n",
        "  identify(bool): 동질성 사용 여부\n",
        "  \"\"\"\n",
        "  #출력 결과:\n",
        "  #list : 2개의 생성기, 2개의 판별기, 1개의 적대적 모델 \n",
        "\n",
        "  source_shape, target_shape = shapes\n",
        "  lr = 2e-4\n",
        "  decay = 6e-8\n",
        "  gt_name = \"gen_\" + target_name\n",
        "  gs_name = \"gen_\" + source_name\n",
        "  dt_name = \"dis_\" + target_name\n",
        "  ds_name = \"dis_\" + source_name\n",
        "\n",
        "  #타깃과 소스 생성기 구성\n",
        "  g_target = build_generator(source_shape, target_shape, kernel_size=kernel_size, name=gt_name)\n",
        "  g_source = build_generator(target_shape, source_shape, kernel_size=kernel_size, name=gs_name)\n",
        "\n",
        "  print('-----Target Generator-----')\n",
        "  g_target.summary()\n",
        "  print('-----Source Generator-----')\n",
        "  g_source.summary()\n",
        "\n",
        "  #타깃과 소스 판별기 구성\n",
        "  d_target = build_discriminator(target_shape, patchgan=patchgan, kernel_size=kernel_size,name=dt_name)\n",
        "  d_source = build_discriminator(source_shape, patchgan=patchgan, kernel_size=kernel_size,name=ds_name)\n",
        "\n",
        "  print('-----Targent Discriminator-----')\n",
        "  d_target.summary()\n",
        "  print('-----Source Discriminator-----')\n",
        "  d_source.summary()\n",
        "\n",
        "  optimizer = RMSprop(lr=lr, decay=decay)\n",
        "  d_target.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
        "  d_source.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "  #적대적 모델에서 판별기 가중치 고정\n",
        "  d_target.trainable=False\n",
        "  d_source.trainable=False\n",
        "\n",
        "  #적대적 모델의 계산 그래프 구성\n",
        "\n",
        "  #전방순환 네트워크와 타깃 판별기 \n",
        "  source_input = Input(shape=source_shape)\n",
        "  fake_target = g_target(source_input)\n",
        "  preal_target = d_target(fake_target)\n",
        "  reco_source = g_source(fake_target)\n",
        "\n",
        "  #후방순환 네트워크와 타깃 판별기\n",
        "  target_input = Input(shape=target_shape)\n",
        "  fake_source = g_source(target_input)\n",
        "  preal_source = d_source(fake_source)\n",
        "  reco_target = g_target(fake_source)\n",
        "\n",
        "  #동질성 손실 사용 시, 두개의 손실항과 출력을 추가한다.\n",
        "  if identify:\n",
        "    iden_source = g_source(source_input)\n",
        "    iden_target = g_target(target_input)\n",
        "    loss = ['mse', 'mse', 'mae', 'mae', 'mae', 'mae']\n",
        "    loss_weight = [1.,1.,10.,10.,0.5,0.5]\n",
        "    inputs = [source_input, target_input]\n",
        "    outputs = [preal_source, preal_target, reco_source, reco_target, iden_source, iden_target]\n",
        "\n",
        "  else:\n",
        "    loss = ['mse', 'mse', 'mae', 'mae']\n",
        "    loss_weights = [1., 1., 10., 10.]\n",
        "    inputs = [source_input, target_input]\n",
        "    outputs = [preal_source, preal_target, reco_source, reco_target]\n",
        "\n",
        "  #적대적 모델 구성\n",
        "  adv = Model(inputs, outputs, name='adversarial')\n",
        "  optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
        "  adv.compile(loss=loss, loss_weights=loss_weights, optimizer=optimizer,metrics=['accuracy'])\n",
        "  print('-----Adversarial Network-----')\n",
        "  adv.summary()\n",
        "\n",
        "  return g_source, g_target, d_source, d_target, adv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BWADpRB-X1M"
      },
      "source": [
        "# 모델 훈련 함수 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCwHbtjSyPTK"
      },
      "source": [
        "def train_cyclegan(models, data, params, test_params, test_generator):\n",
        "  #Cycle GAN 훈련\n",
        "  \"\"\"\n",
        "  1) 타깃 판별기 훈련\n",
        "  2) 소스 판별기 훈련\n",
        "  3) 적대적 네트워크의 전방/ 후방 순환 훈련\n",
        "  \"\"\"\n",
        "  # 입력 인수:\n",
        "  \"\"\"\n",
        "  models (list): 소스/타깃에 대한 판별기/생성기, 적대적 모델\n",
        "  data (tuple): 소스와 타깃 훈련데이터\n",
        "  params (tuple): 네트워크 매개변수\n",
        "  test_params (tuple): 테스트 매개변수\n",
        "  test_generator (function): 예측 타깃/소스 이미지생성에 사용됨.\n",
        "  \"\"\"\n",
        "  #모델\n",
        "  g_source, g_target, d_source, d_target, adv = models\n",
        "  #네트워크 매개변수 지정\n",
        "  batch_size, train_steps, patch, model_name = params\n",
        "  #훈련 데이터 세트 \n",
        "  source_data, target_data, test_source_data, test_target_data = data\n",
        "  titles, dirs = test_params\n",
        "\n",
        "  #생성기 이미지는 2000단계마다 저장됨\n",
        "  save_interval = 2000\n",
        "  target_size = target_data.shape[0]\n",
        "  source_size = source_data.shape[0]\n",
        "\n",
        "  #patchgan 사용 여부\n",
        "  if patch > 1:\n",
        "    d_patch = (patch, patch, 1)\n",
        "    valid = np.ones((batch_size,) + d_patch)\n",
        "    fake = np.zeros((batch_size,) + d_patch)\n",
        "\n",
        "  else:\n",
        "    valid = np.ones([batch_size, 1])\n",
        "    fake = np.zeros([batch_size, 1])\n",
        "\n",
        "  valid_fake = np.concatenate((valid,fake))\n",
        "  start_time = datetime.datetime.now()\n",
        "\n",
        "  for step in range(train_steps):\n",
        "    #실제 타깃 데이터 배치 샘플링\n",
        "    rand_indices = np.random.randint(0, target_size, size=batch_size)\n",
        "    real_target = target_data[rand_indices]\n",
        "\n",
        "    #실제 소스 데이터 배치 샘플링\n",
        "    rand_indices = np.random.randint(0, source_size, size=batch_size)\n",
        "    real_source = source_data[rand_indices]\n",
        "\n",
        "    #실제 소스 데이터에서 가짜 타깃 데이터 배치를 생성\n",
        "    fake_target = g_target.predict(real_source)\n",
        "    \n",
        "    #실제 타겟 데이터와 가짜 타겟데이터를 하나의 배치로 결합\n",
        "    x = np.concatenate((real_target, fake_target))\n",
        "    #타겟 판별자를 훈련시킴\n",
        "    metrics = d_target.train_on_batch(x, valid_fake)\n",
        "    log = \"%d: [d_target loss: %f]\" %(step, metrics[0])\n",
        "\n",
        "    #실제 타깃 데이터에서 가짜 소스 데이터 배치 생성\n",
        "    fake_source = g_source.predict(real_target)\n",
        "    x = np.concatenate((real_source, fake_source))\n",
        "    #가짜/실제 데이터를 사용해 소스 판별기 훈련\n",
        "    metrics = d_source.train_on_batch(x, valid_fake)\n",
        "    log = \"%s [d_source loss: %f]\" %(log, metrics[0])\n",
        "\n",
        "    #전방/후방 순환을 사용해 적대적 네트워크 훈련\n",
        "    #생성된 가짜 소스/타깃 데이터는 판별기를 속이려고 시도함\n",
        "    x = [real_source, real_target]\n",
        "    y = [valid, valid, real_source, real_target]\n",
        "\n",
        "    metrics = adv.train_on_batch(x, y)\n",
        "\n",
        "    elapsed_time = datetime.datetime.now()-start_time\n",
        "    fmt = \"%s [adv loss: %f] [time: %s]\"\n",
        "    log = fmt %(log, metrics[0], elapsed_time)\n",
        "    print(log)\n",
        "\n",
        "    if (step+1) % save_interval == 0:\n",
        "      if (step+1) == train_steps:\n",
        "        show = True\n",
        "      else:\n",
        "        show = False\n",
        "\n",
        "      test_generator((g_source, g_target), (test_source_data, test_target_data), step = step+1, titles=titles, dirs=dirs, show=show)\n",
        "\n",
        "  g_source.save(model_name + \"-g_source.h5\")\n",
        "  g_target.save(model_name + \"-g_target.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJTBEvX0ptkS"
      },
      "source": [
        "#SVHN 을 위한 데이터 로딩 함수지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zKV4OG7ptI3"
      },
      "source": [
        "def get_datadir():\n",
        "    cache_dir = os.path.join(os.path.expanduser('~'), '.keras')\n",
        "    cache_subdir = 'datasets'\n",
        "    datadir_base = os.path.expanduser(cache_dir)\n",
        "    if not os.access(datadir_base, os.W_OK):\n",
        "        datadir_base = os.path.join('/tmp', '.keras')\n",
        "\n",
        "    datadir = os.path.join(datadir_base, cache_subdir)\n",
        "    if not os.path.exists(datadir):\n",
        "        os.makedirs(datadir)\n",
        "\n",
        "    return datadir\n",
        "\n",
        "def loadmat(filename):\n",
        "    # SVHN 데이터셋을 로딩한다.\n",
        "    mat = io.loadmat(filename)\n",
        "    # 이미지 데이터의 키는 'X' 이고 ,이미지 라벨의 키는 'y' 로 구성되어 있다. \n",
        "    # 본 예제에세는 X 만을 사용한다.\n",
        "    data = mat['X']\n",
        "    rows =data.shape[0]\n",
        "    cols = data.shape[1]\n",
        "    channels = data.shape[2]\n",
        "    # 매트랩 데이터에서, 이미지의 인덱스는 마지막에 지정된다.\n",
        "    # 케라스에서, 이미지의 인덱스는 첫번째로 지정된다.\n",
        "    # 케라스의 방식으로 매트랩 데이터를 바꾸어준다.\n",
        "    data = np.transpose(data, (3, 0, 1, 2))\n",
        "    return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmL6yzipqxDx"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import get_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_chni6v_49mh"
      },
      "source": [
        "#MNIST 데이터 로딩 및 전처리\n",
        "(source_data, _), (test_source_data, _) = mnist.load_data()\n",
        "\n",
        "#28x28 사이즈의 MNIST 데이터를 SVHN 의 32x32로 변환하기위한 패드를 지정한다.\n",
        "source_data = np.pad(source_data, ((0,0), (2,2), (2,2)),'constant', constant_values=0)\n",
        "test_source_data = np.pad(test_source_data, ((0,0), (2,2), (2,2)), 'constant', constant_values=0)\n",
        "\n",
        "#Input 이미지의 차원을 data format을 채널값이 마지막 값인것으로 유추하여 지정한다.\n",
        "rows = source_data.shape[1]\n",
        "cols = source_data.shape[2]\n",
        "channels = 1\n",
        "\n",
        "# 이미지의 크기를 rowxcolxchannels 의 CNN 이미지를 위해 재정의 한다.\n",
        "size = source_data.shape[0]\n",
        "source_data = source_data.reshape(size, rows, cols, channels)\n",
        "size = test_source_data.shape[0]\n",
        "test_source_data = test_source_data.reshape(size, rows, cols, channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0LWrcPwsSY6"
      },
      "source": [
        "#SVHN 데이터 로딩 및 전처리\n",
        "datadir = get_datadir()\n",
        "get_file('train_32x32.mat', origin='http://ufldl.stanford.edu/housenumbers/train_32x32.mat')\n",
        "get_file('test_32x32.mat', 'http://ufldl.stanford.edu/housenumbers/test_32x32.mat')\n",
        "path = os.path.join(datadir, 'train_32x32.mat')\n",
        "target_data = loadmat(path)\n",
        "path = os.path.join(datadir, 'test_32x32.mat')\n",
        "test_target_data = loadmat(path)\n",
        "\n",
        "# 소스 데이터, 타겟데이터, 테스트 데이터 지정\n",
        "data = (source_data, target_data, test_source_data, test_target_data)\n",
        "filenames = ('mnist_test_source.png', 'svhn_test_target.png')\n",
        "titles = ('MNIST test source images', 'SVHN test target images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG87HCz_9sk4"
      },
      "source": [
        "# 이미지 저장 및 shape 재지정\n",
        "data, shapes = loaded_data(data, titles, filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JbYyyOWsviN"
      },
      "source": [
        "# 모델 Parameter 설정 및 빌드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0qR2nk-6AG9"
      },
      "source": [
        "model_name = 'cyclegan_svhn'\n",
        "batch_size = 32\n",
        "train_steps = 100000\n",
        "patchgan = True\n",
        "kernel_size = 5\n",
        "postfix = ('%dp' % kernel_size) if patchgan else ('%d' % kernel_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdtaBQV29rFc"
      },
      "source": [
        "titles = ('MNIST predicted source images.', 'SVHN predicted target images.', 'MNIST reconstructed source images.', 'SVHN reconstructed target images.')\n",
        "dirs = ('mnist_source-%s' % postfix, 'svhn_target-%s' % postfix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki2gTlLr_qpN",
        "outputId": "bf6d9723-c5d0-4f67-b5fb-5ab3a828d465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = build_cyclegan(shapes, \"gray-%s\" % postfix, \"color-%s\" % postfix, kernel_size=kernel_size, patchgan=patchgan)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----Target Generator-----\n",
            "Model: \"gen_color-5p\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization (Instanc (None, 32, 32, 1)    2           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 32, 32, 1)    0           instance_normalization[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 32)   832         leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_1 (Insta (None, 32, 32, 32)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 32)   0           instance_normalization_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 16, 16, 64)   51264       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_2 (Insta (None, 16, 16, 64)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 16, 16, 64)   0           instance_normalization_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 8, 8, 128)    204928      leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_3 (Insta (None, 8, 8, 128)    256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 8, 8, 128)    0           instance_normalization_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 4, 4, 128)    409728      leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_4 (Insta (None, 4, 4, 128)    256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 4, 4, 128)    0           instance_normalization_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 8, 8, 128)    409728      activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 256)    0           conv2d_transpose[0][0]           \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_5 (Insta (None, 8, 8, 256)    512         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 8, 8, 256)    0           instance_normalization_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 64)   409664      activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16, 16, 128)  0           conv2d_transpose_1[0][0]         \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_6 (Insta (None, 16, 16, 128)  256         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 16, 16, 128)  0           instance_normalization_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 64)   204864      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 96)   0           conv2d_transpose_2[0][0]         \n",
            "                                                                 conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 32, 32, 3)    7203        concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,699,685\n",
            "Trainable params: 1,699,685\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "-----Source Generator-----\n",
            "Model: \"gen_gray-5p\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_7 (Insta (None, 32, 32, 3)    6           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 32, 32, 3)    0           instance_normalization_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   2432        leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_8 (Insta (None, 32, 32, 32)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 32)   0           instance_normalization_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   51264       leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_9 (Insta (None, 16, 16, 64)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 64)   0           instance_normalization_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 8, 8, 128)    204928      leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_10 (Inst (None, 8, 8, 128)    256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 8, 8, 128)    0           instance_normalization_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 4, 4, 128)    409728      leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_11 (Inst (None, 4, 4, 128)    256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 4, 4, 128)    0           instance_normalization_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 8, 8, 128)    409728      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8, 8, 256)    0           conv2d_transpose_4[0][0]         \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_12 (Inst (None, 8, 8, 256)    512         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8, 8, 256)    0           instance_normalization_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 16, 16, 64)   409664      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 16, 16, 128)  0           conv2d_transpose_5[0][0]         \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_13 (Inst (None, 16, 16, 128)  256         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 128)  0           instance_normalization_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 32, 32, 64)   204864      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 96)   0           conv2d_transpose_6[0][0]         \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 32, 32, 1)    2401        concatenate_5[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,696,487\n",
            "Trainable params: 1,696,487\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "-----Targent Generator-----\n",
            "Model: \"dis_color-5p\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 32)        2432      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 8, 8, 64)          51264     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 4, 4, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 2, 2, 256)         819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 2, 2, 1)           6401      \n",
            "=================================================================\n",
            "Total params: 1,084,481\n",
            "Trainable params: 1,084,481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "-----Source Generator-----\n",
            "Model: \"dis_gray-5p\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 32, 32, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 32)        832       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 64)          51264     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 4, 4, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 2, 2, 256)         819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 2, 2, 1)           6401      \n",
            "=================================================================\n",
            "Total params: 1,082,881\n",
            "Trainable params: 1,082,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "-----Adversarial Network-----\n",
            "Model: \"adversarial\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gen_gray-5p (Functional)        (None, 32, 32, 1)    1696487     gen_color-5p[0][0]               \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gen_color-5p (Functional)       (None, 32, 32, 3)    1699685     input_5[0][0]                    \n",
            "                                                                 gen_gray-5p[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dis_gray-5p (Functional)        (None, 2, 2, 1)      1082881     gen_gray-5p[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dis_color-5p (Functional)       (None, 2, 2, 1)      1084481     gen_color-5p[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 5,563,534\n",
            "Trainable params: 3,396,172\n",
            "Non-trainable params: 2,167,362\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02W5nNtm_gEr"
      },
      "source": [
        "#판별기의 입력을 2^n 만큼 척도를 줄임 -> patch 크기를 2^n 으로 나눔(즉 strides=2를 n회 사용함)\n",
        "patch = int(source_data.shape[1] / 2**4) if patchgan else 1\n",
        "params = (batch_size, train_steps, patch, model_name)\n",
        "test_params = (titles, dirs)\n",
        "\n",
        "#cyclegan 훈련\n",
        "train_cyclegan(models, data, params, test_params, test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46fvB7b-EOly"
      },
      "source": [
        ""
      ]
    }
  ]
}