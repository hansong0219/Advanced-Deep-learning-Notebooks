{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN-ResNet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansong0219/Advanced-Deep-learning-Notebooks/blob/master/Cross-Domain/CycleGAN_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrgLgGGhyTEM"
      },
      "source": [
        "# ResNet 생성자를 이용한 Cycle GAN 모델 \n",
        "\n",
        "ResNet 구조는 이전 층의 전보를 네트워 앞쪽에 한개 이상의 층으로 스킵한다는 부분에서 U-Net 과 비슷하나, U-Net 은 다운샘플링 층을 이에 상응하는 업샘플링 층으로 연결하여 U 모양을 구성하는 대신 ResNet은 Residual block 을 차례대로 쌓아 구성하게된다. \n",
        "\n",
        "각 블록은 다음의 층으로 출력을 전달하기 전에 입력과 출력을 합하는 스킵 연결층을 가지고 있다.\n",
        "\n",
        "ResNet  구조는 수백 또는 수천개의 층도 훈련할 수 있는데 앞쪽에 층에 도달하는 그레디언트가 매우 작아져 매우 느리게 훈련되는 vanishing gradient 문제가 없고,Error gradient 가 Residual Block 의 스킵 연결을 통해 네트워크에 그대로 역전파 되기 때문이다. 또, 층을 추가해도 모델의 정확도를 떨어뜨리지 않는데 추가적인 특성이 추출되지 않는다면, 스킵연결로 인해 언제든지 이전 층의 특성이 identify mapping 을 통과하기 때문이다.\n",
        "\n",
        "본 Notebook 에서는 Residual block 을 사용한 생성자를 구성하여 Image Style Transfer 를 수행할 예정이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dje1KlSYj56a"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from tensorflow.keras.layers import Input, Dropout, concatenate, add, Layer\n",
        "from tensorflow.keras.layers import Conv2DTranspose, Conv2D \n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LeakyReLU, Activation\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import cv2\n",
        "import math\n",
        "import datetime\n",
        "import imageio\n",
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P46g6-NzzYHd"
      },
      "source": [
        "# GPU 할당"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNDhgjQDzY6h"
      },
      "source": [
        "import tensorflow as tf \n",
        "physical_devices =tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxTYa37605u5"
      },
      "source": [
        "# 유틸 함수 정의\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmBOzCVFcrFV"
      },
      "source": [
        "### 이미지 및 데이터 재구성 유틸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpm_sVhf08eT"
      },
      "source": [
        "def display_images(imgs, filename, title='', imgs_dir=None, show=False):\n",
        "  \n",
        "    #이미지를 nxn 으로 나타냄\n",
        "    rows = imgs.shape[1]\n",
        "    cols = imgs.shape[2]\n",
        "    channels = imgs.shape[3]\n",
        "    side = int(math.sqrt(imgs.shape[0]))\n",
        "    assert int(side * side) == imgs.shape[0]\n",
        "\n",
        "    # 이미지 저장을 위한 폴더를 만듦\n",
        "    if imgs_dir is None:\n",
        "        imgs_dir = 'saved_images'\n",
        "    save_dir = os.path.join(os.getcwd(), imgs_dir)\n",
        "    if not os.path.isdir(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    filename = os.path.join(imgs_dir, filename)\n",
        "    # 이미지의 shape 을 지정\n",
        "    if channels==1:\n",
        "        imgs = imgs.reshape((side, side, rows, cols))\n",
        "    else:\n",
        "        imgs = imgs.reshape((side, side, rows, cols, channels))\n",
        "    imgs = np.vstack([np.hstack(i) for i in imgs])\n",
        "    \n",
        "    if np.min(imgs)< 0:\n",
        "      imgs = imgs * 0.5 + 0.5\n",
        "    \n",
        "    plt.figure(figsize = (8,8))\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    if channels==1:\n",
        "        plt.imshow(imgs, interpolation='none', cmap='gray')\n",
        "    else:\n",
        "        plt.imshow(imgs, interpolation='none')\n",
        "    plt.savefig(filename)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    \n",
        "    plt.close('all')\n",
        "\n",
        "\n",
        "def test_generator(generators, test_data, step, titles, dirs, todisplay=4, show=False):\n",
        "    # generator 모델을 테스트함\n",
        "    # 입력 인수\n",
        "    \"\"\"\n",
        "    generators (tuple): 소스와 타겟 생성기\n",
        "    test_data (tuple): 소스와 타겟 데이터\n",
        "    step (int): 진행 단계\n",
        "    titles (tuple): 표시 이미지의 타이틀\n",
        "    dirs (tuple): 이미지 저장 폴더\n",
        "    todisplay (int): 저장이미지의 수 (정사각형 형태로 생성되어야 한다.)\n",
        "    show (bool): 이미지 표시 여부\n",
        "    \"\"\"\n",
        "\n",
        "    # test data 로 부터 output 예측\n",
        "    g_source, g_target = generators\n",
        "    test_source_data, test_target_data = test_data\n",
        "    t1, t2, t3, t4 = titles\n",
        "    title_pred_source = t1\n",
        "    title_pred_target = t2\n",
        "    title_reco_source = t3\n",
        "    title_reco_target = t4\n",
        "    dir_pred_source, dir_pred_target = dirs\n",
        "\n",
        "    pred_target_data = g_target.predict(test_source_data)\n",
        "    pred_source_data = g_source.predict(test_target_data)\n",
        "    reco_source_data = g_source.predict(pred_target_data)\n",
        "    reco_target_data = g_target.predict(pred_source_data)\n",
        "\n",
        "    # 정사각형 형태의 하나의 이미지로 나타냄\n",
        "    imgs = pred_target_data[:todisplay]\n",
        "    filename = '%06d.png' % step\n",
        "    step = \" Step: {:,}\".format(step)\n",
        "    title = title_pred_target + step\n",
        "    display_images(imgs,\n",
        "                   filename=filename,\n",
        "                   imgs_dir=dir_pred_target,\n",
        "                   title=title,\n",
        "                   show=show)\n",
        "\n",
        "    imgs = pred_source_data[:todisplay]\n",
        "    title = title_pred_source\n",
        "    display_images(imgs,\n",
        "                   filename=filename,\n",
        "                   imgs_dir=dir_pred_source,\n",
        "                   title=title,\n",
        "                   show=show)\n",
        "\n",
        "    imgs = reco_source_data[:todisplay]\n",
        "    title = title_reco_source\n",
        "    filename = \"reconstructed_source.png\"\n",
        "    display_images(imgs,\n",
        "                   filename=filename,\n",
        "                   imgs_dir=dir_pred_source,\n",
        "                   title=title,\n",
        "                   show=show)\n",
        "\n",
        "    imgs = reco_target_data[:todisplay]\n",
        "    title = title_reco_target\n",
        "    filename = \"reconstructed_target.png\"\n",
        "    display_images(imgs,\n",
        "                   filename=filename,\n",
        "                   imgs_dir=dir_pred_target,\n",
        "                   title=title,\n",
        "                   show=show)\n",
        "\n",
        "\n",
        "def process_data(data, titles, filenames, todisplay=4):\n",
        "    source_data, target_data, test_source_data, test_target_data = data\n",
        "    test_source_filename, test_target_filename = filenames\n",
        "    test_source_title, test_target_title = titles\n",
        "\n",
        "    # 테스트 타겟 이미지 표시\n",
        "    imgs = test_target_data[:todisplay]\n",
        "    display_images(imgs,\n",
        "                   filename=test_target_filename,\n",
        "                   title=test_target_title)\n",
        "\n",
        "    # 테스트 소스이미지 표시\n",
        "    imgs = test_source_data[:todisplay]\n",
        "    display_images(imgs,\n",
        "                   filename=test_source_filename,\n",
        "                   title=test_source_title)\n",
        "\n",
        "    # 이미지 표시 정리\n",
        "    target_data = target_data.astype('float32')  / 127.5 - 1\n",
        "    test_target_data = test_target_data.astype('float32') / 127.5 - 1\n",
        "\n",
        "    source_data = source_data.astype('float32')  / 127.5 - 1\n",
        "    test_source_data = test_source_data.astype('float32') / 127.5 - 1\n",
        "\n",
        "    # 소스, 타겟, 테스트 데이터\n",
        "    data = (source_data, target_data, test_source_data, test_target_data)\n",
        "\n",
        "    rows = source_data.shape[1]\n",
        "    cols = source_data.shape[2]\n",
        "    channels = source_data.shape[3]\n",
        "    source_shape = (rows, cols, channels)\n",
        "\n",
        "    rows = target_data.shape[1]\n",
        "    cols = target_data.shape[2]\n",
        "    channels = target_data.shape[3]\n",
        "    target_shape = (rows, cols, channels)\n",
        "\n",
        "    shapes = (source_shape, target_shape)\n",
        "    \n",
        "    return data, shapes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kEAyg-Acfvz"
      },
      "source": [
        "### 데이터 불러오기 유틸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X794mDO0yu-"
      },
      "source": [
        "def imread(path):\n",
        "    return imageio.imread(path,as_gray=False,pilmode='RGB').astype(np.float)\n",
        "\n",
        "def load_data(dataset_path, is_test=False):\n",
        "  data_type = \"train\" if not is_test else \"test\"\n",
        "  path_source = glob(dataset_path + '/%sA/*' %(data_type))\n",
        "  path_target = glob(dataset_path + '/%sB/*' %(data_type))\n",
        "    \n",
        "  source_data, target_data = [], []\n",
        "  for source, target in zip(path_source, path_target):\n",
        "    img_source = imread(source)\n",
        "    img_target = imread(target)\n",
        "\n",
        "    img_source = np.array(img_source)\n",
        "    img_target = np.array(img_target)\n",
        "\n",
        "    if is_test and np.random.random()>0.5:\n",
        "      img_source = np.fliplr(img_source)\n",
        "      img_target = np.fliplr(img_target)\n",
        "    \n",
        "    source_data.append(img_source)\n",
        "    target_data.append(img_target)\n",
        "    \n",
        "  return np.array(source_data), np.array(target_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csOU3Kwb3P0C"
      },
      "source": [
        "# 데이터 불러오기 및 확인\n",
        "dataset_path = \"D:/data/vangogh2photo\"\n",
        "source_data, target_data = load_data(dataset_path)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(source_data[0]/255.0)\n",
        "plt.figure()\n",
        "plt.imshow(target_data[0]/255.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFA5vFkm08K-"
      },
      "source": [
        "# 모델 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3dUobX5Z7Pe"
      },
      "source": [
        "### ReflectionPadding2D\n",
        "\n",
        "CycleGAN 논문 및 Source 를 통해 ResNet 생성기의 Layer 구조에서 Reflection Padding을 사용하는 것이 ZerosPadding을 사용하는 Conv2D의 padding=same 조건에 비해 권장 되었다. 따라서 ResNet 생성기에는 ReflectionPadding2D의 Class를 지정하여 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_cEFPbNNM1c"
      },
      "source": [
        "class ReflectionPadding2D(Layer):\n",
        "    # ReflectionPadding Layer 를 실행할 수 있도록 구성된 class\n",
        "    \n",
        "    # 입력인수\n",
        "    \"\"\"\n",
        "    padding(tuple): padding을 위한 특정 차원의 크기로 지정된다. \n",
        "    \"\"\"\n",
        "    # 출력 : padding 이 실행된 텐서를 출력한다.\n",
        "\n",
        "    def __init__(self, padding=(1, 1), **kwargs):\n",
        "        self.padding = tuple(padding)\n",
        "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, input_tensor, mask=None):\n",
        "        padding_width, padding_height = self.padding\n",
        "        padding_tensor = [\n",
        "            [0, 0],\n",
        "            [padding_height, padding_height],\n",
        "            [padding_width, padding_width],\n",
        "            [0, 0],\n",
        "        ]\n",
        "        return tf.pad(input_tensor, padding_tensor, mode=\"REFLECT\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKqLYhCv1AaX"
      },
      "source": [
        "# 모델 Build 함수 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLpCGf36dcgw"
      },
      "source": [
        "### 모델 구성층 구성 함수\n",
        "ResNet 을 생성자로 하는 Cycle GAN 의 구성요소는 크게 3가지로 분류할 수 있다. \n",
        "\n",
        "1. 생성자와 판별자의 encoder(downsampling) layer\n",
        "2. 생성자의 Residual Block Unit\n",
        "3. 생성자의 decoder(upsampling) layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RskIW2RndhQH"
      },
      "source": [
        "def encoder_layer(inputs, filters=16, kernel_size=3, strides = 2,  activation='relu', instance_norm=True):\n",
        "  #Conv2D -IN - ReLU(LeakyReLU) 의 인코더 층을 구성한다.\n",
        "  kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "  x = inputs\n",
        "  x = Conv2D(filters, kernel_size=kernel_size, strides=strides,kernel_initializer=kernel_init, padding = 'same')(x)\n",
        "  if instance_norm:\n",
        "    x = InstanceNormalization()(x)\n",
        "\n",
        "  if activation=='relu':\n",
        "    x = Activation(activation)(x)\n",
        "  else:\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def decoder_layer(inputs, filters=16, kernel_size=3, strides=2, activation='relu', instance_norm = True):\n",
        "  #Conv2DTranspose-IN-LeakyReLU로 구성된 디코더 계층구성, 활성화 함수는 ReLU 로 교체될 수 있음\n",
        "  kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "  x = inputs\n",
        "  x = Conv2DTranspose(filters, kernel_size=kernel_size, strides=strides, kernel_initializer = kernel_init, padding='same')(x)\n",
        "  if instance_norm:\n",
        "    x = InstanceNormalization()(x)\n",
        "  \n",
        "  if activation=='relu':\n",
        "    x = Activation(activation)(x)\n",
        "  else:\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def residual_block(inputs, filters=64, kernel_size=3, resblock=2):\n",
        "  # shorcut 연결 구현한 Residual Block\n",
        "  kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "  shortcut = inputs\n",
        "\n",
        "  for num_unit in range(resblock):\n",
        "    if num_unit == 0:\n",
        "      x = ReflectionPadding2D(padding=(1,1))(inputs)\n",
        "    else:\n",
        "      x = ReflectionPadding2D(padding=(1,1))(x)\n",
        "    \n",
        "    x = Conv2D(filters, kernel_size=kernel_size, strides=1, padding='valid', kernel_initializer=kernel_init)(x)\n",
        "    x = InstanceNormalization()(x)\n",
        "\n",
        "    if num_unit != resblock-1:\n",
        "      x = Activation('relu')(x)\n",
        " \n",
        "  return add([shortcut, x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2QipE2PuVus"
      },
      "source": [
        "### 생성기 Build 함수 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjjsn-FJ1CZv"
      },
      "source": [
        "# 생성기 Build 함수\n",
        "def build_generator(input_shape, output_shape=None, filters = 64, num_encoders = 2, num_residual_blocks= 9, num_decoders = 2, name=None):\n",
        "  inputs = Input(shape=input_shape)\n",
        "  channels = int(output_shape[-1])\n",
        "  kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "  x = ReflectionPadding2D(padding=(3, 3))(inputs)\n",
        "  x = Conv2D(filters, kernel_size=7, strides=1, padding='valid', kernel_initializer = kernel_init, use_bias=False)(x)\n",
        "  x = InstanceNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  #DownSampling\n",
        "  for _ in range(num_encoders):\n",
        "    filters *=2\n",
        "    x = encoder_layer(x, filters=filters)\n",
        "  \n",
        "  #Residual Block 층 구성\n",
        "  for _ in range(num_residual_blocks):\n",
        "    x = residual_block(x, filters=filters)\n",
        "\n",
        "  #UpSampling\n",
        "  for _ in range(num_decoders):\n",
        "    filters//=2\n",
        "    x = decoder_layer(x, filters=filters)\n",
        "\n",
        "  #Final Block\n",
        "  x = ReflectionPadding2D(padding=(3, 3))(x)\n",
        "  x = Conv2D(channels, (7, 7), strides=1, padding=\"valid\")(x)\n",
        "  x = Activation(\"tanh\")(x)\n",
        "\n",
        "  return Model(inputs, x, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_EjktEJvGxW"
      },
      "source": [
        "### 판별자 Build 함수 (Patch GAN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irb7UBFCsCK1"
      },
      "source": [
        "def build_discriminator(input_shape, filters=64, kernel_size=4, num_encoder=4, name=None):\n",
        "  kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "  \n",
        "  inputs = Input(shape=input_shape)\n",
        "  x = encoder_layer(inputs, filters = filters, kernel_size = kernel_size, strides=2, activation='leaky_relu', instance_norm=False) \n",
        "\n",
        "  num_filters=filters\n",
        "  for num_block in range(num_encoder):\n",
        "    num_filters *= 2\n",
        "    if num_block < num_encoder-1:\n",
        "      x = encoder_layer(x, filters=num_filters, kernel_size = kernel_size, strides = 2, activation='leaky_relu') \n",
        "    else:\n",
        "      x = encoder_layer(x, filters=num_filters, kernel_size = kernel_size, strides = 1, activation='leaky_relu')\n",
        "\n",
        "  outputs = Conv2D(1, (4,4), strides=1, padding='same', kernel_initializer = kernel_init)(x)\n",
        "\n",
        "  return Model(inputs, outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SnqRfGgWu-m"
      },
      "source": [
        "### Cycle GAN Build 함수 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSj01gLqtNyd"
      },
      "source": [
        "def build_cyclegan(shape, source_name='source', target_name='target', kernel_size=3, patchgan=False, identify=False):\n",
        "  #Cycle GAN 의 구성\n",
        "  \"\"\"\n",
        "  1) 타깃과 소스의 판별기\n",
        "  2) 타깃과 소스의 생성기\n",
        "  3) 적대적 네트워크 구성\n",
        "  \"\"\"\n",
        "\n",
        "  #입력 인수\n",
        "  \"\"\"\n",
        "  shape(tuple): 소스와 타깃 형상\n",
        "  source_name (string): 판별기/생성기 모델 이름 뒤에 붙는 소스이름 문자열\n",
        "  target_name (string): 판별기/생성기 모델 이름 뒤에 붙는 타깃이름 문자열\n",
        "  target_size (int): 인코더/디코더 혹은 판별기/생성기 모델에 사용될 커널 크기\n",
        "  patchgan(bool): 판별기에 patchgan 사용 여부\n",
        "  identify(bool): 동질성 사용 여부\n",
        "  \"\"\"\n",
        "  #출력 결과:\n",
        "  #list : 2개의 생성기, 2개의 판별기, 1개의 적대적 모델 \n",
        "\n",
        "  source_shape, target_shape = shapes\n",
        "  lr = 2e-4\n",
        "  decay = 6e-8\n",
        "  gt_name = \"gen_\" + target_name\n",
        "  gs_name = \"gen_\" + source_name\n",
        "  dt_name = \"dis_\" + target_name\n",
        "  ds_name = \"dis_\" + source_name\n",
        "\n",
        "  #타깃과 소스 생성기 구성\n",
        "  g_target = build_generator(source_shape, target_shape, name=gt_name)\n",
        "  g_source = build_generator(target_shape, source_shape, name=gs_name)\n",
        "\n",
        "  print('-----Target Generator-----')\n",
        "  g_target.summary()\n",
        "  print('-----Source Generator-----')\n",
        "  g_source.summary()\n",
        "\n",
        "  #타깃과 소스 판별기 구성\n",
        "  d_target = build_discriminator(target_shape, name=dt_name)\n",
        "  d_source = build_discriminator(source_shape, name=ds_name)\n",
        "\n",
        "  print('-----Targent Discriminator-----')\n",
        "  d_target.summary()\n",
        "  print('-----Source Discriminator-----')\n",
        "  d_source.summary()\n",
        "\n",
        "  optimizer = RMSprop(lr=lr, decay=decay)\n",
        "  d_target.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
        "  d_source.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "  #적대적 모델에서 판별기 가중치 고정\n",
        "  d_target.trainable=False\n",
        "  d_source.trainable=False\n",
        "\n",
        "  #적대적 모델의 계산 그래프 구성\n",
        "\n",
        "  #전방순환 네트워크와 타깃 판별기 \n",
        "  source_input = Input(shape=source_shape)\n",
        "  fake_target = g_target(source_input)\n",
        "  preal_target = d_target(fake_target)\n",
        "  reco_source = g_source(fake_target)\n",
        "\n",
        "  #후방순환 네트워크와 타깃 판별기\n",
        "  target_input = Input(shape=target_shape)\n",
        "  fake_source = g_source(target_input)\n",
        "  preal_source = d_source(fake_source)\n",
        "  reco_target = g_target(fake_source)\n",
        "\n",
        "  #동질성 손실 사용 시, 두개의 손실항과 출력을 추가한다.\n",
        "  if identify:\n",
        "    iden_source = g_source(source_input)\n",
        "    iden_target = g_target(target_input)\n",
        "    loss = ['mse', 'mse', 'mae', 'mae', 'mae', 'mae']\n",
        "    loss_weights = [1., 1., 10., 10., 0.5, 0.5]\n",
        "    inputs = [source_input, target_input]\n",
        "    outputs = [preal_source, preal_target, reco_source, reco_target, iden_source, iden_target]\n",
        "\n",
        "  else:\n",
        "    loss = ['mse', 'mse', 'mae', 'mae']\n",
        "    loss_weights = [1., 1., 10., 10.]\n",
        "    inputs = [source_input, target_input]\n",
        "    outputs = [preal_source, preal_target, reco_source, reco_target]\n",
        "\n",
        "  #적대적 모델 구성\n",
        "  adv = Model(inputs, outputs, name='adversarial')\n",
        "  optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
        "  adv.compile(loss=loss, loss_weights=loss_weights, optimizer=optimizer)\n",
        "  print('-----Adversarial Network-----')\n",
        "  adv.summary()\n",
        "\n",
        "  return g_source, g_target, d_source, d_target, adv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXp84S4IbWtO"
      },
      "source": [
        "def train_cyclegan(models, data, params, test_params, test_generator, identify=False):\n",
        "  #Cycle GAN 훈련\n",
        "  \"\"\"\n",
        "  1) 타깃 판별기 훈련\n",
        "  2) 소스 판별기 훈련\n",
        "  3) 적대적 네트워크의 전방/ 후방 순환 훈련\n",
        "  \"\"\"\n",
        "  # 입력 인수:\n",
        "  \"\"\"\n",
        "  models (list): 소스/타깃에 대한 판별기/생성기, 적대적 모델\n",
        "  data (tuple): 소스와 타깃 훈련데이터\n",
        "  params (tuple): 네트워크 매개변수\n",
        "  test_params (tuple): 테스트 매개변수\n",
        "  test_generator (function): 예측 타깃/소스 이미지생성에 사용됨.\n",
        "  \"\"\"\n",
        "  #모델\n",
        "  g_source, g_target, d_source, d_target, adv = models\n",
        "  #네트워크 매개변수 지정\n",
        "  batch_size, train_steps, patch, model_name = params\n",
        "  #훈련 데이터 세트 \n",
        "  source_data, target_data, test_source_data, test_target_data = data\n",
        "  titles, dirs = test_params\n",
        "\n",
        "  #생성기 이미지는 2000단계마다 저장됨\n",
        "  save_interval = 2000\n",
        "  target_size = target_data.shape[0]\n",
        "  source_size = source_data.shape[0]\n",
        "\n",
        "  #patchgan 사용 여부\n",
        "  if patch > 1:\n",
        "    d_patch = (patch, patch, 1)\n",
        "    valid = np.ones((batch_size,) + d_patch)\n",
        "    fake = np.zeros((batch_size,) + d_patch)\n",
        "\n",
        "  else:\n",
        "    valid = np.ones([batch_size, 1])\n",
        "    fake = np.zeros([batch_size, 1])\n",
        "\n",
        "  valid_fake = np.concatenate((valid,fake))\n",
        "  start_time = datetime.datetime.now()\n",
        "\n",
        "  for step in range(train_steps):\n",
        "    #실제 타깃 데이터 배치 샘플링\n",
        "    rand_indices = np.random.randint(0, target_size, size=batch_size)\n",
        "    real_target = target_data[rand_indices]\n",
        "\n",
        "    #실제 소스 데이터 배치 샘플링\n",
        "    rand_indices = np.random.randint(0, source_size, size=batch_size)\n",
        "    real_source = source_data[rand_indices]\n",
        "\n",
        "    #실제 소스 데이터에서 가짜 타깃 데이터 배치를 생성\n",
        "    fake_target = g_target.predict(real_source)\n",
        "    \n",
        "    #실제 타겟 데이터와 가짜 타겟데이터를 하나의 배치로 결합\n",
        "    x = np.concatenate((real_target, fake_target))\n",
        "    #타겟 판별자를 훈련시킴\n",
        "    metrics = d_target.train_on_batch(x, valid_fake)\n",
        "    log = \"%d: [d_target loss: %f]\" %(step, metrics[0])\n",
        "\n",
        "    #실제 타깃 데이터에서 가짜 소스 데이터 배치 생성\n",
        "    fake_source = g_source.predict(real_target)\n",
        "    x = np.concatenate((real_source, fake_source))\n",
        "    #가짜/실제 데이터를 사용해 소스 판별기 훈련\n",
        "    metrics = d_source.train_on_batch(x, valid_fake)\n",
        "    log = \"%s [d_source loss: %f]\" %(log, metrics[0])\n",
        "    \n",
        "    #전방/후방 순환을 사용해 적대적 네트워크 훈련\n",
        "    #생성된 가짜 소스/타깃 데이터는 판별기를 속이려고 시도함\n",
        "    \n",
        "    if identify:\n",
        "        x = [real_source, real_target]\n",
        "        y = [valid, valid, real_source, real_target, real_source, real_target]\n",
        "    \n",
        "    else:\n",
        "        x = [real_source, real_target]\n",
        "        y = [valid, valid, real_source, real_target]\n",
        "\n",
        "    metrics = adv.train_on_batch(x, y)\n",
        "\n",
        "    elapsed_time = datetime.datetime.now()-start_time\n",
        "    fmt = \"%s [adv loss: %f] [time: %s]\"\n",
        "    log = fmt %(log, metrics[0], elapsed_time)\n",
        "    print(log)\n",
        "\n",
        "    if (step+1) % save_interval == 0:\n",
        "      if (step+1) == train_steps:\n",
        "        show = True\n",
        "      else:\n",
        "        show = False\n",
        "\n",
        "      test_generator((g_source, g_target), (test_source_data, test_target_data), step = step+1, titles=titles, dirs=dirs, show=show)\n",
        "\n",
        "  g_source.save(model_name + \"-g_source.h5\")\n",
        "  g_target.save(model_name + \"-g_target.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abHQprC3YmCi"
      },
      "source": [
        "# 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCh0tcoMYkum"
      },
      "source": [
        "test_source_data, test_target_data = load_data(dataset_path, is_test=True)\n",
        "\n",
        "filenames = ('vangogh_test_source.png', 'picture_test_target.png')\n",
        "titles = ('Van Gogh test source images', 'picture test target images')\n",
        "data = (source_data, target_data, test_source_data, test_target_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-muPJ6E2Sav"
      },
      "source": [
        "# 이미지 저장 및 shape 재지정\n",
        "data, shapes = loaded_data(data, titles, filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wd2EXD7eIxr"
      },
      "source": [
        "#model_fine tuning 변수 지정\n",
        "model_name = 'cyclegan_vangogh'\n",
        "batch_size = 1\n",
        "train_steps = 100000\n",
        "patchgan = True\n",
        "kernel_size = 3\n",
        "postfix = ('%dp' % kernel_size) if patchgan else ('%d' % kernel_size)\n",
        "\n",
        "titles = ('vangogh2pic predicted source images.',\n",
        "          'vangogh2pic predicted target images.',\n",
        "          'vangogh2pic reconstructed source images.',\n",
        "          'vangogh2pic reconstructed target images.')\n",
        "dirs = ('vangogh2pic_source-%s' % postfix, 'vangogh2pic_target-%s' % postfix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz7ZOlKsam3R"
      },
      "source": [
        "models = build_cyclegan(shapes, \"vangogh-%s\" % postfix, \"picture-%s\" % postfix, kernel_size=kernel_size, patchgan=patchgan)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAZnwCeIbGpU"
      },
      "source": [
        "#판별기의 입력을 2^n 만큼 척도를 줄임 -> patch 크기를 2^n 으로 나눔(즉 strides=2를 n회 사용함)\n",
        "patch = int(source_data.shape[1] / 2**4) if patchgan else 1\n",
        "params = (batch_size, train_steps, patch, model_name)\n",
        "test_params = (titles, dirs)\n",
        "\n",
        "#cyclegan 훈련\n",
        "train_cyclegan(models, data, params, test_params, test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}