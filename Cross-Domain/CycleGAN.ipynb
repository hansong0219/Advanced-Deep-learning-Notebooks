{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansong0219/Advanced-DeepLearning-Study/blob/master/Cross-Domain/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifFt1Xs_d1Bf"
      },
      "source": [
        "# CycleGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi8IE66ovE8z"
      },
      "source": [
        "# CycleGAN 의 원리\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxs2UgyivKZJ"
      },
      "source": [
        "\n",
        "CycleGAN 의 목적은 가짜 타깃 데이터 y'을 생성기를 통해 생성하는데에 있다.\n",
        "가짜 이미지 y' 을 x 의 함수로 생성하기 위해서, 소스도메인의 실제이미지 x 와 타깃 도메인의 실제 이미지 y를 활용함으로써 비지도 방식으로 훈련된다.\n",
        "\n",
        "일반 GAN 과의 차이점은 CycleGAN 은 순환-일관성(cycle-consistency) 제약을 둔다.\n",
        "전방 순환의 경우 생성기 G 와 F 에 의해 실제 소스 데이터가 가짜 타깃 데이터로부터 재구성 될 수 있다고 가정하는 것이다. \n",
        "\n",
        "이를 수식으로 표현하면 다음과 같다.\n",
        "\n",
        "* ***X' = F(G(X))***\n",
        "\n",
        "마찬가지로 후방 순환에 대해서도 타깃 데이터 y 는 네트워크에 의해 재구성 될 수 있다. \n",
        "\n",
        "전방 순환과 후방순환에서의 일관성을 바탕으로하여 L1 손실을 최소화 시키는 방향으로 훈련을 해야하며 두 순환의 손실을 더한 값을 순환-일관성 손실이라고 한다.\n",
        "\n",
        "L1, MAE (Mean Absolute Error, MAE) 를 사용하는 이유는 이것이 L2(MSE) 보다 재구성 된 결과 이미지가 더 선명하게 주어지는 것이 Cycle GAN 의 논문에서 제시되었다. \n",
        "\n",
        "다른 GAN 모델과 마찬가지로 CycleGAN의 궁극적 목표는 생성기가 판별기를 속일 수 있는 가짜 타깃 데이터를 합성하는 방법을 학습하는 것이다. 본 예제에서는 LSGAN 에서 품질이 더 낫다는 것을 토대로 이진 교차 엔트로피 손실 대신 MSE 손실을 사용한다.\n",
        "\n",
        "GAN 의 손실은 순환 일관성 검사에 더 무게를 두어 전체 GAN 의 손실로 정의한다.\n",
        "Cycle GAN 의 훈련 방법은 GAN 과 비슷하다 대략적인 훈련의 Step 은 다음과 같다\n",
        "\n",
        "- 1. 실제 소스와 타깃 데이터를 사용해 전방-순환 판별기를 훈련해 전방순환 손실을 최소화 한다. 실제 타깃 데이터 배치인 y의 레이블은 1 이고 가짜 타깃 데이터 배치인 y' 의 레이블은 0 으로 한다.\n",
        "\n",
        "- 2. 실제 소스와 타깃데이터를 사용해 후방 순환 판별기를 훈련해 후방순환 손실을 최소화 한다.실제 소스 데이터 배치인 x 의 레이블은 1이고 가짜 소스 데이터인 x' 의 레이블은 0 으로 학습한다ㅏ.\n",
        "\n",
        "- 3. 적대적 신경망에서 전방 순환 생성기와 후방 순환 생성기를 훈련해 GAN 의 손실과 순환 일관성의 손실을 최소화 한다. 이때 가짜 타깃 배치와 가짜 소스 배치의 레이블을 1로 하고 판별기의 가중치를 고정한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrAOZ3WVvRoR"
      },
      "source": [
        "# CIFAR 10 의 Coloration 예제\n",
        "\n",
        "본 예제에서는 기존 AutoEncoder 의 Coloration 을 CycleGAN 으로 재현한다.\n",
        "생성기는 U-Net 을 판별기는 Patch GAN 을 사용하였다.\n",
        "\n",
        "CIFAR10 세트가 32x32 의 사이즈 이기에 더 큰 크기의 이미지를 사용할 경우 U-Net의 입력/출력 차원이 높아질 경우 인코더/디코더의 깊이가 깊어져야하며, 이것이 문제가 될 수 있다. 본래 논문에서는 256 x 256 사이즈의 이미지를 사용하며, ResNet 의 경우도 소개되어 있으니 참고하도록 하자.\n",
        "\n",
        "인코더 계층은 IN-LeakyReLU-Conv2D 로 구성되며 디코더 계층은 IN-ReLU-Conv2DTranspose 로 구성된다.\n",
        "\n",
        "스타일 변경에서는 Instance Normalization 을 사용하는데 데이터 샘플마다 적용되는 Batch Normalization 의 역할을 한다. 즉 IN 은 이미지 또는 특징마다 수행되는 BN 이라고 생각할 수 있는데, 이는 스타일 전이에서는 배치가 아니라 샘플마다 contrast를 정규화 하는 것이 더 중요하기 때문이다.\n",
        "\n",
        "이미지가 클 경우, 한자릿수의 실제 혹은 가짜 확률로 이미지를 계산하는 것은 매개변수로 비효율 적이며, 생성기에서의 이미지 품질을 떨어뜨리는 결과를 가져온다. 이문제에 대한 해결책으로 위에서와 같이 PatchGAN 을 사용하는데 기존의 출력을 2X2 의 Patch 로써 4개가 되는 것이다.\n",
        "\n",
        "이미지의 크기가 커질수록 Patch 가 많을 경우 이미지가 더 실제와 같이 변환된다.\n",
        "본 예제에서는 32X32 사이즈이기에 2x2 출력을 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUxgtHEFvRH8"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from tensorflow.keras.layers import Input, Dropout, concatenate, add\n",
        "from tensorflow.keras.layers import Conv2DTranspose, Conv2D \n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LeakyReLU, Activation\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "import math"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BrVc7v34xjP"
      },
      "source": [
        "#유틸 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q-w6cuK3Oz6"
      },
      "source": [
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
        "\n",
        "\n",
        "def display_images(imgs, filename, title='', imgs_dir=None, show=False):\n",
        "  \n",
        "    #이미지를 nxn 으로 나타냄\n",
        "    rows = imgs.shape[1]\n",
        "    cols = imgs.shape[2]\n",
        "    channels = imgs.shape[3]\n",
        "    side = int(math.sqrt(imgs.shape[0]))\n",
        "    assert int(side * side) == imgs.shape[0]\n",
        "\n",
        "    # 이미지 저장을 위한 폴더를 만듦\n",
        "    if imgs_dir is None:\n",
        "        imgs_dir = 'saved_images'\n",
        "    save_dir = os.path.join(os.getcwd(), imgs_dir)\n",
        "    if not os.path.isdir(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    filename = os.path.join(imgs_dir, filename)\n",
        "    # 이미지의 shape 을 지정\n",
        "    if channels==1:\n",
        "        imgs = imgs.reshape((side, side, rows, cols))\n",
        "    else:\n",
        "        imgs = imgs.reshape((side, side, rows, cols, channels))\n",
        "    imgs = np.vstack([np.hstack(i) for i in imgs])\n",
        "    plt.figure()\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    if channels==1:\n",
        "        plt.imshow(imgs, interpolation='none', cmap='gray')\n",
        "    else:\n",
        "        plt.imshow(imgs, interpolation='none')\n",
        "    plt.savefig(filename)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    \n",
        "    plt.close('all')\n",
        "\n",
        "\n",
        "def test_generator(generators, test_data, step, titles, dirs, todisplay=100, show=False):\n",
        "    # generator 모델을 테스트함\n",
        "    # 입력 인수\n",
        "    \"\"\"\n",
        "    generators (tuple): 소스와 타겟 생성기\n",
        "    test_data (tuple): 소스와 타겟 데이터\n",
        "    step (int): 진행 단계\n",
        "    titles (tuple): 표시 이미지의 타이틀\n",
        "    dirs (tuple): 이미지 저장 폴더\n",
        "    todisplay (int): 저장이미지의 수 (정사각형 형태로 생성되어야 한다.)\n",
        "    show (bool): 이미지 표시 여부\n",
        "    \"\"\"\n",
        "\n",
        "    # test data 로 부터 output 예측\n",
        "    g_source, g_target = generators\n",
        "    test_source_data, test_target_data = test_data\n",
        "    t1, t2, t3, t4 = titles\n",
        "    title_pred_source = t1\n",
        "    title_pred_target = t2\n",
        "    title_reco_source = t3\n",
        "    title_reco_target = t4\n",
        "    dir_pred_source, dir_pred_target = dirs\n",
        "\n",
        "    pred_target_data = g_target.predict(test_source_data)\n",
        "    pred_source_data = g_source.predict(test_target_data)\n",
        "    reco_source_data = g_source.predict(pred_target_data)\n",
        "    reco_target_data = g_target.predict(pred_source_data)\n",
        "\n",
        "    # 정사각형 형태의 하나의 이미지로 나타냄\n",
        "    imgs = pred_target_data[:todisplay]\n",
        "    filename = '%06d.png' % step\n",
        "    step = \" Step: {:,}\".format(step)\n",
        "    title = title_pred_target + step\n",
        "    display_images(imgs,\n",
        "                   filename=filename,\n",
        "                   imgs_dir=dir_pred_target,\n",
        "                   title=title,\n",
        "                   show=show)\n",
        "\n",
        "    imgs = pred_source_data[:todisplay]\n",
        "    title = title_pred_source\n",
        "    display_images(imgs,\n",
        "                   filename=filename,\n",
        "                   imgs_dir=dir_pred_source,\n",
        "                   title=title,\n",
        "                   show=show)\n",
        "\n",
        "    imgs = reco_source_data[:todisplay]\n",
        "    title = title_reco_source\n",
        "    filename = \"reconstructed_source.png\"\n",
        "    display_images(imgs,\n",
        "                   filename=filename,\n",
        "                   imgs_dir=dir_pred_source,\n",
        "                   title=title,\n",
        "                   show=show)\n",
        "\n",
        "    imgs = reco_target_data[:todisplay]\n",
        "    title = title_reco_target\n",
        "    filename = \"reconstructed_target.png\"\n",
        "    display_images(imgs,\n",
        "                   filename=filename,\n",
        "                   imgs_dir=dir_pred_target,\n",
        "                   title=title,\n",
        "                   show=show)\n",
        "\n",
        "\n",
        "def loaded_data(data, titles, filenames, todisplay=100):\n",
        "    source_data, target_data, test_source_data, test_target_data = data\n",
        "    test_source_filename, test_target_filename = filenames\n",
        "    test_source_title, test_target_title = titles\n",
        "\n",
        "    # 테스트 타겟 이미지 표시\n",
        "    imgs = test_target_data[:todisplay]\n",
        "    display_images(imgs,\n",
        "                   filename=test_target_filename,\n",
        "                   title=test_target_title)\n",
        "\n",
        "    # 테스트 소스이미지 표시\n",
        "    imgs = test_source_data[:todisplay]\n",
        "    display_images(imgs,\n",
        "                   filename=test_source_filename,\n",
        "                   title=test_source_title)\n",
        "\n",
        "    # 이미지 표시 정리\n",
        "    target_data = target_data.astype('float32')  / 255\n",
        "    test_target_data = test_target_data.astype('float32') / 255\n",
        "\n",
        "    source_data = source_data.astype('float32')  / 255\n",
        "    test_source_data = test_source_data.astype('float32') / 255\n",
        "\n",
        "    # 소스, 타겟, 테스트 데이터\n",
        "    data = (source_data, target_data, test_source_data, test_target_data)\n",
        "\n",
        "    rows = source_data.shape[1]\n",
        "    cols = source_data.shape[2]\n",
        "    channels = source_data.shape[3]\n",
        "    source_shape = (rows, cols, channels)\n",
        "\n",
        "    rows = target_data.shape[1]\n",
        "    cols = target_data.shape[2]\n",
        "    channels = target_data.shape[3]\n",
        "    target_shape = (rows, cols, channels)\n",
        "\n",
        "    shapes = (source_shape, target_shape)\n",
        "    \n",
        "    return data, shapes"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq64olbL3MFZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrJItE7PvWUk"
      },
      "source": [
        "# 모델 함수 정의\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_LkMnPcvkNX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPE8N9EFdtsS"
      },
      "source": [
        "#모델 구성 단위 블럭 정의\n",
        "def encoder_layer(inputs, filters=16, kernel_size=3, strides=2, activation='relu', instance_norm=True):\n",
        "  # Conv2D - IN - LeakyReLU 로 구성된 일반 인코더 계층을 구성한다.\n",
        "  conv = Conv2D(filters=filters,kernel_size=kernel_size, strides=strides, padding='same')\n",
        "  x = inputs\n",
        "  if instance_norm:\n",
        "    x = InstanceNormalization()(x)\n",
        "  if activation == 'relu':\n",
        "    x = Activation('relu')(x)\n",
        "  else:\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = conv(x)\n",
        "  return x\n",
        "\n",
        "def decoder_layer(inputs, paired_inputs, filters=16, kernel_size=3, strides=2,activation='relu', instance_norm=True):\n",
        "  #Conv2DTranspose-IN-LeakyReLU로 구성된 디코더 계층구성, 활성화 함수는 ReLU 로 교체될 수 있음\n",
        "  #paired_inputs 는 U-net 의 skip connection 을 의미하며 입력에 연결된다.\n",
        "\n",
        "  conv=Conv2DTranspose(filters=filters,kernel_size=kernel_size, strides=strides, padding='same')\n",
        "  \n",
        "  x = inputs\n",
        "  if instance_norm:\n",
        "    x = InstanceNormalization()(x)\n",
        "  if activation=='relu':\n",
        "    x = Activation('relu')(x)\n",
        "  else:\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = conv(x)\n",
        "  x = concatenate([x, paired_inputs])\n",
        "  return x"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH2rvu07pdgf"
      },
      "source": [
        "#생성기 U-Net Build\n",
        "def build_generator(input_shape, output_shape=None, kernel_size=3, name=None):\n",
        "  # 4계층 인코더와 4계층 디코더로 구성된 U-Net 을 구성한다.\n",
        "\n",
        "  inputs = Input(shape=input_shape)\n",
        "  channels = int(output_shape[-1])\n",
        "\n",
        "  e1 = encoder_layer(inputs, filters=32, kernel_size=kernel_size, activation='leaky_relu', strides=1)\n",
        "  e2 = encoder_layer(e1, filters=64, kernel_size= kernel_size, activation='leaky_relu')\n",
        "  e3 = encoder_layer(e2, filters=128, kernel_size= kernel_size, activation='leaky_relu')\n",
        "  e4 = encoder_layer(e3, filters=128, kernel_size= kernel_size, activation='leaky_relu')\n",
        "\n",
        "  d1 = decoder_layer(e4,e3,filters=128,kernel_size=kernel_size)\n",
        "  d2 = decoder_layer(d1,e2,filters=64,kernel_size=kernel_size)\n",
        "  d3 = decoder_layer(d2,e1,filters=64,kernel_size=kernel_size)\n",
        "\n",
        "  outputs = Conv2DTranspose(channels, kernel_size=kernel_size, strides=1, activation='sigmoid',padding='same')(d3)\n",
        "\n",
        "  generator = Model(inputs, outputs, name=name)\n",
        "  \n",
        "  return generator\n",
        "\n",
        "#PatchGAN Discriminator Build\n",
        "def build_discriminator(input_shape,kernel_size=3, patchgan=True,name=None):\n",
        "  inputs = Input(shape=input_shape)\n",
        "  x = encoder_layer(inputs,32,kernel_size=kernel_size,activation='leaky_relu',instance_norm=False)\n",
        "  x = encoder_layer(x, 64,kernel_size=kernel_size,activation='leaky_relu',instance_norm=False)\n",
        "  x = encoder_layer(x, 128,kernel_size=kernel_size,activation='leaky_relu',instance_norm=False)\n",
        "  x = encoder_layer(x, 256,kernel_size=kernel_size,activation='leaky_relu',instance_norm=False)\n",
        "\n",
        "  #patchgan=True 이면 n x n 차원 확률 출력 사용\n",
        "  if patchgan:\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    outputs = Conv2D(1, kernel_size=kernel_size, strides=1, padding='same')(x)\n",
        "  else:\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1)(x)\n",
        "    outputs - Activation('linear')(x)\n",
        "\n",
        "  discriminator = Model(inputs, outputs, name=name)\n",
        "\n",
        "  return discriminator"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KImz4AJKt0Tz"
      },
      "source": [
        "# CycleGAN Build 함수 지정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0SaD3MCk6xX"
      },
      "source": [
        "아래에서 동질성 Loss identify 는 색상을 재현하는데 있어, 발생한 문제에 대해 본래의 색상을 찾아가도록 훈련시키는 과정이다. 이를 위해 타겟데이터 y 가 들어왔을 때 본래 이미지로 재구성할 수 있는 능력을 훈련시키는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCfN1_ozt2X4"
      },
      "source": [
        "def build_cyclegan(shape, source_name='source', target_name='target', kernel_size=3, patchgan=False, identify=False):\n",
        "  #Cycle GAN 의 구성\n",
        "  \"\"\"\n",
        "  1) 타깃과 소스의 판별기\n",
        "  2) 타깃과 소스의 생성기\n",
        "  3) 적대적 네트워크 구성\n",
        "  \"\"\"\n",
        "\n",
        "  #입력 인수\n",
        "  \"\"\"\n",
        "  shape(tuple): 소스와 타깃 형상\n",
        "  source_name (string): 판별기/생성기 모델 이름 뒤에 붙는 소스이름 문자열\n",
        "  target_name (string): 판별기/생성기 모델 이름 뒤에 붙는 타깃이름 문자열\n",
        "  target_size (int): 인코더/디코더 혹은 판별기/생성기 모델에 사용될 커널 크기\n",
        "  patchgan(bool): 판별기에 patchgan 사용 여부\n",
        "  identify(bool): 동질성 사용 여부\n",
        "  \"\"\"\n",
        "  #출력 결과:\n",
        "  #list : 2개의 생성기, 2개의 판별기, 1개의 적대적 모델 \n",
        "\n",
        "  source_shape, target_shape = shapes\n",
        "  lr = 2e-4\n",
        "  decay = 6e-8\n",
        "  gt_name = \"gen_\" + target_name\n",
        "  gs_name = \"gen_\" + source_name\n",
        "  dt_name = \"dis_\" + target_name\n",
        "  ds_name = \"dis_\" + source_name\n",
        "\n",
        "  #타깃과 소스 생성기 구성\n",
        "  g_target = build_generator(source_shape, target_shape, kernel_size=kernel_size, name=gt_name)\n",
        "  g_source = build_generator(target_shape, source_shape, kernel_size=kernel_size, name=gs_name)\n",
        "\n",
        "  print('-----Target Generator-----')\n",
        "  g_target.summary()\n",
        "  print('-----Source Generator-----')\n",
        "  g_source.summary()\n",
        "\n",
        "  #타깃과 소스 판별기 구성\n",
        "  d_target = build_discriminator(target_shape, patchgan=patchgan, kernel_size=kernel_size,name=dt_name)\n",
        "  d_source = build_discriminator(source_shape, patchgan=patchgan, kernel_size=kernel_size,name=ds_name)\n",
        "\n",
        "  print('-----Targent Generator-----')\n",
        "  d_target.summary()\n",
        "  print('-----Source Generator-----')\n",
        "  d_source.summary()\n",
        "\n",
        "  optimizer = RMSprop(lr=lr, decay=decay)\n",
        "  d_target.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
        "  d_source.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "  #적대적 모델에서 판별기 가중치 고정\n",
        "  d_target.trainable=False\n",
        "  d_source.trainable=False\n",
        "\n",
        "  #적대적 모델의 계산 그래프 구성\n",
        "\n",
        "  #전방순환 네트워크와 타깃 판별기 \n",
        "  source_input = Input(shape=source_shape)\n",
        "  fake_target = g_target(source_input)\n",
        "  preal_target = d_target(fake_target)\n",
        "  reco_source = g_source(fake_target)\n",
        "\n",
        "  #후방순환 네트워크와 타깃 판별기\n",
        "  target_input = Input(shape=target_shape)\n",
        "  fake_source = g_source(target_input)\n",
        "  preal_source = d_source(fake_source)\n",
        "  reco_target = g_target(fake_source)\n",
        "\n",
        "  #동질성 손실 사용 시, 두개의 손실항과 출력을 추가한다.\n",
        "  if identify:\n",
        "    iden_source = g_source(source_input)\n",
        "    iden_target = g_target(target_input)\n",
        "    loss = ['mse', 'mse', 'mae', 'mae', 'mae', 'mae']\n",
        "    loss_weight = [1.,1.,10.,10.,0.5,0.5]\n",
        "    inputs = [source_input, target_input]\n",
        "    outputs = [preal_source, preal_target, reco_source, reco_target, iden_source, iden_target]\n",
        "\n",
        "  else:\n",
        "    loss = ['mse', 'mse', 'mae', 'mae']\n",
        "    loss_weights = [1., 1., 10., 10.]\n",
        "    inputs = [source_input, target_input]\n",
        "    outputs = [preal_source, preal_target, reco_source, reco_target]\n",
        "\n",
        "  #적대적 모델 구성\n",
        "  adv = Model(inputs, outputs, name='adversarial')\n",
        "  optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
        "  adv.compile(loss=loss, loss_weight=loss_weight, optimizer=optimizer,metrics=['accuracy'])\n",
        "  print('-----Adversarial Network-----')\n",
        "  adv.summary()\n",
        "\n",
        "  return g_source, g_target, d_source, d_target, adv"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BWADpRB-X1M"
      },
      "source": [
        "# 모델 훈련 함수 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCwHbtjSyPTK"
      },
      "source": [
        "def train_cyclegan(models, data, params, test_params, test_generator):\n",
        "  #Cycle GAN 훈련\n",
        "  \"\"\"\n",
        "  1) 타깃 판별기 훈련\n",
        "  2) 소스 판별기 훈련\n",
        "  3) 적대적 네트워크의 전방/ 후방 순환 훈련\n",
        "  \"\"\"\n",
        "  # 입력 인수:\n",
        "  \"\"\"\n",
        "  models (list): 소스/타깃에 대한 판별기/생성기, 적대적 모델\n",
        "  data (tuple): 소스와 타깃 훈련데이터\n",
        "  params (tuple): 네트워크 매개변수\n",
        "  test_params (tuple): 테스트 매개변수\n",
        "  test_generator (function): 예측 타깃/소스 이미지생성에 사용됨.\n",
        "  \"\"\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLD9xU7OAWBp"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_chni6v_49mh"
      },
      "source": [
        "# CIFAR10 데이터 로딩\n",
        "(target_data, _), (test_target_data, _) = cifar10.load_data()\n",
        "\n",
        "rows = target_data.shape[1]\n",
        "cols = target_data.shape[2]\n",
        "channels = target_data.shape[3]\n",
        "\n",
        "# 이미지를 변환함.\n",
        "source_data = rgb2gray(target_data)\n",
        "test_source_data = rgb2gray(test_target_data)\n",
        "\n",
        "# CNN 입력을 위한 이미지 재규격화\n",
        "source_data = source_data.reshape(source_data.shape[0], rows, cols, 1)\n",
        "test_source_data = test_source_data.reshape(test_source_data.shape[0], rows, cols, 1)\n",
        "\n",
        "# 소스데이터, 타겟데이터, 테스트 소스데이터 리스트화\n",
        "data = (source_data, target_data, test_source_data, test_target_data)\n",
        "filenames = ('cifar10_test_source.png', 'cifar10_test_target.png')\n",
        "titles = ('CIFAR10 test source images', 'CIFAR10 test target images')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG87HCz_9sk4"
      },
      "source": [
        "# 이미지 저장 및 shape 재지정\n",
        "data, shapes = loaded_data(data, titles, filenames)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0qR2nk-6AG9"
      },
      "source": [
        "model_name = 'cyclegan_cifar10'\n",
        "batch_size = 32\n",
        "train_steps = 100000\n",
        "patchgan = True\n",
        "kernel_size = 3\n",
        "postfix = ('%dp' % kernel_size) if patchgan else ('%d' % kernel_size)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdtaBQV29rFc"
      },
      "source": [
        "titles = ('CIFAR10 predicted source images.',\n",
        "          'CIFAR10 predicted target images.',\n",
        "          'CIFAR10 reconstructed source images.',\n",
        "          'CIFAR10 reconstructed target images.')\n",
        "dirs = ('cifar10_source-%s' % postfix, 'cifar10_target-%s' % postfix)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki2gTlLr_qpN",
        "outputId": "59be8404-ec6f-46b5-b709-1ff8bb0ec7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = build_cyclegan(shapes,\n",
        "                            \"gray-%s\" % postfix,\n",
        "                            \"color-%s\" % postfix,\n",
        "                            kernel_size=kernel_size,\n",
        "                            patchgan=patchgan)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----Target Generator-----\n",
            "Model: \"gen_color-3p\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_32 (Inst (None, 32, 32, 1)    2           input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, 32, 32, 1)    0           instance_normalization_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 32)   320         leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_33 (Inst (None, 32, 32, 32)   64          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, 32, 32, 32)   0           instance_normalization_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18496       leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_34 (Inst (None, 16, 16, 64)   128         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, 16, 16, 64)   0           instance_normalization_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 128)    73856       leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_35 (Inst (None, 8, 8, 128)    256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, 8, 8, 128)    0           instance_normalization_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 4, 4, 128)    147584      leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_36 (Inst (None, 4, 4, 128)    256         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 4, 4, 128)    0           instance_normalization_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_13 (Conv2DTran (None, 8, 8, 128)    147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 8, 8, 256)    0           conv2d_transpose_13[0][0]        \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_37 (Inst (None, 8, 8, 256)    512         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 256)    0           instance_normalization_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_14 (Conv2DTran (None, 16, 16, 64)   147520      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 16, 16, 128)  0           conv2d_transpose_14[0][0]        \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_38 (Inst (None, 16, 16, 128)  256         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 128)  0           instance_normalization_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_15 (Conv2DTran (None, 32, 32, 64)   73792       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 96)   0           conv2d_transpose_15[0][0]        \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_16 (Conv2DTran (None, 32, 32, 3)    2595        concatenate_12[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 613,221\n",
            "Trainable params: 613,221\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "-----Source Generator-----\n",
            "Model: \"gen_gray-3p\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_39 (Inst (None, 32, 32, 3)    6           input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, 32, 32, 3)    0           instance_normalization_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 32)   896         leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_40 (Inst (None, 32, 32, 32)   64          conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, 32, 32, 32)   0           instance_normalization_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 64)   18496       leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_41 (Inst (None, 16, 16, 64)   128         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, 16, 16, 64)   0           instance_normalization_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 128)    73856       leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_42 (Inst (None, 8, 8, 128)    256         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, 8, 8, 128)    0           instance_normalization_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 4, 4, 128)    147584      leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_43 (Inst (None, 4, 4, 128)    256         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 4, 4, 128)    0           instance_normalization_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_17 (Conv2DTran (None, 8, 8, 128)    147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 8, 8, 256)    0           conv2d_transpose_17[0][0]        \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_44 (Inst (None, 8, 8, 256)    512         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 256)    0           instance_normalization_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_18 (Conv2DTran (None, 16, 16, 64)   147520      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 16, 16, 128)  0           conv2d_transpose_18[0][0]        \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_45 (Inst (None, 16, 16, 128)  256         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 128)  0           instance_normalization_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_19 (Conv2DTran (None, 32, 32, 64)   73792       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 96)   0           conv2d_transpose_19[0][0]        \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_20 (Conv2DTran (None, 32, 32, 1)    865         concatenate_15[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 612,071\n",
            "Trainable params: 612,071\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "-----Targent Generator-----\n",
            "Model: \"dis_color-3p\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)   (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 16, 16, 32)        896       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 8, 8, 64)          18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 2, 2, 256)         295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 2, 2, 1)           2305      \n",
            "=================================================================\n",
            "Total params: 390,721\n",
            "Trainable params: 390,721\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "-----Source Generator-----\n",
            "Model: \"dis_gray-3p\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)   (None, 32, 32, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 16, 16, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 8, 8, 64)          18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 2, 2, 256)         295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 2, 2, 1)           2305      \n",
            "=================================================================\n",
            "Total params: 390,145\n",
            "Trainable params: 390,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input Tensor(\"input_9:0\", shape=(None, 32, 32, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 1).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5d9a1c00a278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0;34m\"color-%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpostfix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                             patchgan=patchgan)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-0759066b4875>\u001b[0m in \u001b[0;36mbuild_cyclegan\u001b[0;34m(shape, source_name, target_name, kernel_size, patchgan, identify)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0mtarget_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mfake_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m   \u001b[0mpreal_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0mreco_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[1;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 386\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1090\u001b[0m       \u001b[0;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m       \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;34m' incompatible with the layer: expected axis '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;34m' of input shape to have value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 ' but received input with shape ' + str(shape))\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer instance_normalization_39 is incompatible with the layer: expected axis -1 of input shape to have value 3 but received input with shape [None, 32, 32, 1]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_liBS2OuAr4v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02W5nNtm_gEr"
      },
      "source": [
        "#판별기의 입력을 2^n 만큼 척도를 줄임 -> patch 크기를 2^n 으로 나눔(즉 strides=2를 n회 사용함)\n",
        "patch = int(source_data.shape[1] / 2**4) if patchgan else 1\n",
        "params = (batch_size, train_steps, patch, model_name)\n",
        "test_params = (titles, dirs)\n",
        "\n",
        "#cyclegan 훈련\n",
        "train_cyclegan(models, data, params, test_params, test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}