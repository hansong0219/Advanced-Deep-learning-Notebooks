{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansong0219/Advanced-DeepLearning-Study/blob/master/Cross-Domain/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifFt1Xs_d1Bf"
      },
      "source": [
        "# CycleGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi8IE66ovE8z"
      },
      "source": [
        "# CycleGAN 의 원리\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxs2UgyivKZJ"
      },
      "source": [
        "\n",
        "CycleGAN 의 목적은 가짜 타깃 데이터 y'을 생성기를 통해 생성하는데에 있다.\n",
        "가짜 이미지 y' 을 x 의 함수로 생성하기 위해서, 소스도메인의 실제이미지 x 와 타깃 도메인의 실제 이미지 y를 활용함으로써 비지도 방식으로 훈련된다.\n",
        "\n",
        "일반 GAN 과의 차이점은 CycleGAN 은 순환-일관성(cycle-consistency) 제약을 둔다.\n",
        "전방 순환의 경우 생성기 G 와 F 에 의해 실제 소스 데이터가 가짜 타깃 데이터로부터 재구성 될 수 있다고 가정하는 것이다. \n",
        "\n",
        "이를 수식으로 표현하면 다음과 같다.\n",
        "\n",
        "* ***X' = F(G(X))***\n",
        "\n",
        "마찬가지로 후방 순환에 대해서도 타깃 데이터 y 는 네트워크에 의해 재구성 될 수 있다. \n",
        "\n",
        "전방 순환과 후방순환에서의 일관성을 바탕으로하여 L1 손실을 최소화 시키는 방향으로 훈련을 해야하며 두 순환의 손실을 더한 값을 순환-일관성 손실이라고 한다.\n",
        "\n",
        "L1, MAE (Mean Absolute Error, MAE) 를 사용하는 이유는 이것이 L2(MSE) 보다 재구성 된 결과 이미지가 더 선명하게 주어지는 것이 Cycle GAN 의 논문에서 제시되었다. \n",
        "\n",
        "다른 GAN 모델과 마찬가지로 CycleGAN의 궁극적 목표는 생성기가 판별기를 속일 수 있는 가짜 타깃 데이터를 합성하는 방법을 학습하는 것이다. 본 예제에서는 LSGAN 에서 품질이 더 낫다는 것을 토대로 이진 교차 엔트로피 손실 대신 MSE 손실을 사용한다.\n",
        "\n",
        "GAN 의 손실은 순환 일관성 검사에 더 무게를 두어 전체 GAN 의 손실로 정의한다.\n",
        "Cycle GAN 의 훈련 방법은 GAN 과 비슷하다 대략적인 훈련의 Step 은 다음과 같다\n",
        "\n",
        "- 1. 실제 소스와 타깃 데이터를 사용해 전방-순환 판별기를 훈련해 전방순환 손실을 최소화 한다. 실제 타깃 데이터 배치인 y의 레이블은 1 이고 가짜 타깃 데이터 배치인 y' 의 레이블은 0 으로 한다.\n",
        "\n",
        "- 2. 실제 소스와 타깃데이터를 사용해 후방 순환 판별기를 훈련해 후방순환 손실을 최소화 한다.실제 소스 데이터 배치인 x 의 레이블은 1이고 가짜 소스 데이터인 x' 의 레이블은 0 으로 학습한다ㅏ.\n",
        "\n",
        "- 3. 적대적 신경망에서 전방 순환 생성기와 후방 순환 생성기를 훈련해 GAN 의 손실과 순환 일관성의 손실을 최소화 한다. 이때 가짜 타깃 배치와 가짜 소스 배치의 레이블을 1로 하고 판별기의 가중치를 고정한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrAOZ3WVvRoR"
      },
      "source": [
        "# CIFAR 10 의 Coloration 예제\n",
        "\n",
        "본 예제에서는 기존 AutoEncoder 의 Coloration 을 CycleGAN 으로 재현한다.\n",
        "생성기는 U-Net 을 판별기는 Patch GAN 을 사용하였다.\n",
        "\n",
        "CIFAR10 세트가 32x32 의 사이즈 이기에 더 큰 크기의 이미지를 사용할 경우 U-Net의 입력/출력 차원이 높아질 경우 인코더/디코더의 깊이가 깊어져야하며, 이것이 문제가 될 수 있다. 본래 논문에서는 256 x 256 사이즈의 이미지를 사용하며, ResNet 의 경우도 소개되어 있으니 참고하도록 하자.\n",
        "\n",
        "인코더 계층은 IN-LeakyReLU-Conv2D 로 구성되며 디코더 계층은 IN-ReLU-Conv2DTranspose 로 구성된다.\n",
        "\n",
        "스타일 변경에서는 Instance Normalization 을 사용하는데 데이터 샘플마다 적용되는 Batch Normalization 의 역할을 한다. 즉 IN 은 이미지 또는 특징마다 수행되는 BN 이라고 생각할 수 있는데, 이는 스타일 전이에서는 배치가 아니라 샘플마다 contrast를 정규화 하는 것이 더 중요하기 때문이다.\n",
        "\n",
        "이미지가 클 경우, 한자릿수의 실제 혹은 가짜 확률로 이미지를 계산하는 것은 매개변수로 비효율 적이며, 생성기에서의 이미지 품질을 떨어뜨리는 결과를 가져온다. 이문제에 대한 해결책으로 위에서와 같이 PatchGAN 을 사용하는데 기존의 출력을 2X2 의 Patch 로써 4개가 되는 것이다.\n",
        "\n",
        "이미지의 크기가 커질수록 Patch 가 많을 경우 이미지가 더 실제와 같이 변환된다.\n",
        "본 예제에서는 32X32 사이즈이기에 2x2 출력을 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUxgtHEFvRH8"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from tensorflow.keras.layers import Input, Dropout, Concatenate, add\n",
        "from tensorflow.keras.layers import Conv2DTranspose, Conv2D, \n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LeakyReLU, Activation\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrJItE7PvWUk"
      },
      "source": [
        "# 모델 함수 정의\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_LkMnPcvkNX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPE8N9EFdtsS"
      },
      "source": [
        "#모델 구성 단위 블럭 정의\n",
        "def encoder_layer(inputs, filters=16, kernel_size=3, strides=2, activation='relu', instance_norm=True):\n",
        "  # Conv2D - IN - LeakyReLU 로 구성된 일반 인코더 계층을 구성한다.\n",
        "  conv = Conv2D(filters=filters,kernel_size=kernel_size, strides=strides, padding='same')\n",
        "  x = inputs\n",
        "  if instance_norm:\n",
        "    x = InstanceNormalization()(x)\n",
        "  if activation == 'relu':\n",
        "    x = Activation('relu')(x)\n",
        "  else:\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = conv(x)\n",
        "  return x\n",
        "\n",
        "def decoder_layer(inputs, paired_inputs, filters=16, kernel_size=3, strides=2,activation='relu', instance_norm=True):\n",
        "  #Conv2DTranspose-IN-LeakyReLU로 구성된 디코더 계층구성, 활성화 함수는 ReLU 로 교체될 수 있음\n",
        "  #paired_inputs 는 U-net 의 skip connection 을 의미하며 입력에 연결된다.\n",
        "\n",
        "  conv=Conv2DTranspose(filters=filters,kernel_size=kernel_size, strides=strides, padding='same')\n",
        "  \n",
        "  x = inputs\n",
        "  if instance_norm:\n",
        "    x = InstanceNormalization()(x)\n",
        "  if activation=='relu':\n",
        "    x = Activation('relu')(x)\n",
        "  else:\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "  \n",
        "  x = conv(x)\n",
        "  x = concatenate([x, paired_inputs])\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH2rvu07pdgf"
      },
      "source": [
        "#생성기 U-Net Build\n",
        "def build_generator(input_shape, output_shape=None, kernel_size=3, name=None):\n",
        "  # 4계층 인코더와 4계층 디코더로 구성된 U-Net 을 구성한다.\n",
        "\n",
        "  inputs = Input(shape=input_shape)\n",
        "  channels = int(output_shape[-1])\n",
        "\n",
        "  e1 = encoder_layer(inputs, filters=32, kernel_size=kernel_size, activation='leaky_relu', stride=1)\n",
        "  e2 = encoder_layer(e1, filters=64, kernel_size= kernel_size, activation='leaky_relu')\n",
        "  e3 = encoder_layer(e2, filters=128, kernel_size= kernel_size, activation='leaky_relu')\n",
        "  e4 = encoder_layer(e3, filters=128, kernel_size= kernel_size, activation='leaky_relu')\n",
        "\n",
        "  d1 = decoder_layer(e4,e3,filters=128,kernel_size=kernel_size)\n",
        "  d2 = decoder_layer(d1,e2,filters=64,kernel_size=kernel_size)\n",
        "  d3 = decoder_layer(d2,e1,filters=64,kernel_size=kernel_size)\n",
        "\n",
        "  ourtputs = Conv2DTranspoze(channels, kernel_size=kernel_size,stride=1, activation='sigmoid',padding='same')(d3)\n",
        "\n",
        "  generator = Model(inputs, outputs, name=name)\n",
        "  \n",
        "  return generator\n",
        "\n",
        "#PatchGAN Discriminator Build\n",
        "def build_discriminator(input_shape,kernel_size=3, patchgan=True,name=None):\n",
        "  inputs = Input(shape=input_shape)\n",
        "  x = encoder_layer(inputs,32,kernel_size=kernel_size,activation='leaky_relu',instance_norm=False)\n",
        "  x = encoder_layer(x, 64,kernel_size=kernel_size,activation='leaky_relu',instance_norm=False)\n",
        "  x = encoder_layer(x, 128,kernel_size=kernel_size,activation='leaky_relu',instance_norm=False)\n",
        "  x = encoder_layer(x, 256,kernel_size=kernel_size,activation='leaky_relu',instance_norm=False)\n",
        "\n",
        "  #patchgan=True 이면 n x n 차원 확률 출력 사용\n",
        "  if patchgan:\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    outputs = Conv2D(1, kernel_size=kernel_size, strides=1, padding='same')(x)\n",
        "  else:\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1)(x)\n",
        "    outputs - Activation('linear')(x)\n",
        "\n",
        "  discriminator = Model(inputs, outputs, name=name)\n",
        "\n",
        "  return discriminator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KImz4AJKt0Tz"
      },
      "source": [
        "# CycleGAN Build 및 훈련"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0SaD3MCk6xX"
      },
      "source": [
        "아래에서 동질성 Loss identify 는 색상을 재현하는데 있어, 발생한 문제에 대해 본래의 색상을 찾아가도록 훈련시키는 과정이다. 이를 위해 타겟데이터 y 가 들어왔을 때 본래 이미지로 재구성할 수 있는 능력을 훈련시키는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCfN1_ozt2X4",
        "outputId": "8ad2cb35-1fd2-4a83-c260-665a53a7f331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "def build_cyclegan(shape, source_name='source', target_name='target', kernel_size=3,patchgan=False, identify=False):\n",
        "  #Cycle GAN 의 구성\n",
        "  \"\"\"\n",
        "  1) 타깃과 소스의 판별기\n",
        "  2) 타깃과 소스의 생성기\n",
        "  3) 적대적 네트워크 구성\n",
        "  \"\"\"\n",
        "\n",
        "  #입력 인수\n",
        "  \"\"\"\n",
        "  shape(tuple): 소스와 타깃 형상\n",
        "  source_name (string): 판별기/생성기 모델 이름 뒤에 붙는 소스이름 문자열\n",
        "  target_name (string): 판별기/생성기 모델 이름 뒤에 붙는 타깃이름 문자열\n",
        "  target_size (int): 인코더/디코더 혹은 판별기/생성기 모델에 사용될 커널 크기\n",
        "  patchgan(bool): 판별기에 patchgan 사용 여부\n",
        "  identify(bool): 동질성 사용 여부\n",
        "  \"\"\"\n",
        "  #출력 결과:\n",
        "  #list : 2개의 생성기, 2개의 판별기, 1개의 적대적 모델 \n",
        "\n",
        "  source_shape, target_shape = shapes\n",
        "  lr = 2e-4\n",
        "  decay = 6e-8\n",
        "  gt_name = \"gen_\" + target_name\n",
        "  gs_name = \"gen_\" + source_name\n",
        "  dt_name = \"dis_\" + target_name\n",
        "  ds_name = \"dis_\" + source_name\n",
        "\n",
        "  #타깃과 소스 생성기 구성\n",
        "  g_target = build_generater(source_shape, target_shape, kernel_size=kernel_size, name=gt_name)\n",
        "  g_source = build_generater(target_shape, source_shape, kernel_size=kernel_size, name=gs_name)\n",
        "\n",
        "  print('-----Target Generator-----')\n",
        "  g_target.summary()\n",
        "  print('-----Source Generator-----')\n",
        "  g_source.summary()\n",
        "\n",
        "  #타깃과 소스 판별기 구성\n",
        "  d_target = build_discriminator(target_shape, patchgan=patchgan, kernel_size=kernel_size,name=dt_name)\n",
        "  d_source = build_discriminator(source_shape, patchgan=patchgan, kernel_size=kernel_size,name=ds_name)\n",
        "\n",
        "  print('-----Targent Generator-----')\n",
        "  d_target.summary()\n",
        "  print('-----Source Generator-----')\n",
        "  d_source.summary()\n",
        "\n",
        "  optimizer = RMSprop(lr=lr, decay=decay)\n",
        "  d_target.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
        "  d_source.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "  #적대적 모델에서 판별기 가중치 고정\n",
        "  d_target.trainable=False\n",
        "  d_source.trainable=False\n",
        "\n",
        "  #적대적 모델의 계산 그래프 구성\n",
        "\n",
        "  #전방순환 네트워크와 타깃 판별기 \n",
        "  source_input = Input(shape=source_shape)\n",
        "  fake_target = g_target(source_input)\n",
        "  preal_target = d_target(fake_target)\n",
        "  reco_source = g_source(fake_target)\n",
        "\n",
        "  #후방순환 네트워크와 타깃 판별기\n",
        "  target_input = Input(shape=target_shape)\n",
        "  fake_source = g_source(target_input)\n",
        "  preal_source = g_source(fake_source)\n",
        "  reco_target = g_target(fake_source)\n",
        "\n",
        "  #동질성 손실 사용 시, 두개의 손실항과 출력을 추가한다.\n",
        "  if identify:\n",
        "    iden_source = g_source(source_input)\n",
        "    iden_target = g_target(target_input)\n",
        "    loss = ['mse', 'mse', 'mae', 'mae', 'mae', 'mae']\n",
        "    loss_weight = [1.,1.,10.,10.,0.5,0.5]\n",
        "    inputs = [source_input, target_input]\n",
        "    outputs = [preal_source, preal_target, reco_source, reco_target, iden_source, iden_target]\n",
        "\n",
        "  else:\n",
        "    loss = ['mse', 'mse', 'mae', 'mae']\n",
        "    loss_weights = [1., 1., 10., 10.]\n",
        "    inputs = [source_input, target_input]\n",
        "    outputs = [preal_source, preal_target, reco_source, reco_target]\n",
        "\n",
        "  #적대적 모델 구성\n",
        "  adv = Model(inputs, outputs, name='adversarial')\n",
        "  optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
        "  adv.compile(loss=loss, loss_weight=loss_weight, optimizer=optimizer,metrics=['accuracy'])\n",
        "  print('-----Adversarial Network-----')\n",
        "  adv.summary()\n",
        "\n",
        "  return g_source, g_target, d_source, d_target, adv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c9e0ecdacd9f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCwHbtjSyPTK"
      },
      "source": [
        "ㅊ"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}