{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3DGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNOlkWnZPdTHTln0c7X/BJV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansong0219/Advanced-DeepLearning-Study/blob/master/GAN/3DGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0GmlNyJHMxV"
      },
      "source": [
        "# 3D - GAN\n",
        "Conv2D 대신 Conv3D 를 사용하여 3D 데이터셋을 처리한 모델이다. \n",
        "\n",
        "일반 DCGAN 대신 LSGAN 을 사용하여 손실을 최소화 시키기 위해 loss 를 mse 를 사용하였다. \n",
        "\n",
        "추가로 최적화를 위해서는 아래의 논문을 보고 모델을 구성하길 바란다.\n",
        "\n",
        "http://3dgan.csail.mit.edu/papers/3dgan_nips.pdf\n",
        "\n",
        "데이터 셋은 해당 저자의 홈페이지에서 가입을 통해 다운로드 받을 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaeezns0GY0o"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io as io\n",
        "import scipy.ndimage as nd\n",
        "from tensorflow.keras.layers import Input, Activation, Flatten, Dense\n",
        "from tensorflow.keras.layers import Conv3D, Conv3DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ9g8OyXKdxH"
      },
      "source": [
        "# GPU 할당"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjgw7wZUKgPk"
      },
      "source": [
        "import tensorflow as tf \n",
        "physical_devices =tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qZsBFyIKiZQ"
      },
      "source": [
        "# 모델 구성함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj6Dznq4KjX1"
      },
      "source": [
        "def build_generator():\n",
        "    z_size = 200\n",
        "    layer_filters = [256, 128, 64]\n",
        "    kernel_sizes = 4\n",
        "    strides = 2\n",
        "    input_shape = (1, 1, 1, z_size)\n",
        "    \n",
        "    inputs = Input(shape = input_shape, name = 'generator_input')\n",
        "     \n",
        "    # input 다음의 Conv3DTranspose BN ReLU 층\n",
        "    x = Conv3DTranspose(filters = 512,\n",
        "                       kernel_size = kernel_sizes,\n",
        "                       strides = 1)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation='relu')(x)\n",
        "    \n",
        "    # Conv3DTranspose 층 \n",
        "    for filters in layer_filters:\n",
        "        x = Conv3DTranspose(filters=filters,\n",
        "                           kernel_size = kernel_sizes,\n",
        "                           strides = strides,\n",
        "                           padding='same')(x)\n",
        "        \n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation(activation = 'relu')(x)\n",
        "    \n",
        "    # 마지막 층은 활성화 함수를 SIgmoid 로 한다.\n",
        "    x = Conv3DTranspose(filters = 1, \n",
        "                          kernel_size = kernel_sizes, \n",
        "                          strides = strides,\n",
        "                          padding = 'same')(x)\n",
        "\n",
        "    x = Activation(activation='sigmoid')(x)\n",
        "    \n",
        "    return Model(inputs, x, name='generator')\n",
        "\n",
        "def build_discriminator():\n",
        "    input_shape = (64,64,64,1)\n",
        "    layer_filters = [64, 128, 256]\n",
        "    kernel_sizes = 4\n",
        "    strides = 2\n",
        "        \n",
        "    #LeakyReLU 의 alpha 값\n",
        "    alphas = 0.2\n",
        "    \n",
        "    inputs = Input(shape=input_shape, name= \"discriminator_input\")\n",
        "    \n",
        "    # 첫번째 Conv3D 층\n",
        "    x = Conv3D(filters = 32, \n",
        "               kernel_size=kernel_sizes,\n",
        "               strides=strides,\n",
        "               padding='same')(inputs)\n",
        "    \n",
        "    #x = BatchNormalization()(x, training=True)\n",
        "    x = LeakyReLU(alpha=alphas)(x)\n",
        "    \n",
        "    for filters in layer_filters:\n",
        "        x = Conv3D(filters = filters,\n",
        "                   kernel_size = kernel_sizes,\n",
        "                   strides = strides,\n",
        "                   padding = 'same')(x)\n",
        "        x = LeakyReLU(alpha=alphas)(x)\n",
        "    \n",
        "    x = Conv3D(filters=512, kernel_size = kernel_sizes, strides = strides, padding = 'same')(x)\n",
        "    \n",
        "    return Model(inputs, x, name = 'discriminator')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkQfIMNUKsVt"
      },
      "source": [
        "# 유틸함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq32p4HhKtj1"
      },
      "source": [
        "def get3DImages(data_dir):\n",
        "    all_files = np.random.choice(glob.glob(data_dir), size=500)\n",
        "    #all_files = glob.glob(data_dir)\n",
        "    all_volumes = np.asarray([getVoxelsFromMat(f) for f in all_files], dtype = np.bool)\n",
        "    \n",
        "    return all_volumes\n",
        "\n",
        "def getVoxelsFromMat(path, cube_len=64):\n",
        "    voxels = io.loadmat(path)['instance']\n",
        "    voxels = np.pad(voxels, (1,1), 'constant', constant_values = (0,0))\n",
        "    if cube_len != 32 and cube_len == 64:\n",
        "        voxels = nd.zoom(voxels, (2,2,2),mode='constant', order=0)\n",
        "    \n",
        "    return voxels\n",
        "\n",
        "def saveFromVoxels(voxels,path):\n",
        "    x,y,z = voxels.nonzero()\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    ax.scatter(x, y, -z, zdir='z', c='green')\n",
        "    \n",
        "    plt.savefig(path)\n",
        "    \n",
        "def plotAndSaveVoxel(file_path, voxel):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.gca(projection='3d')\n",
        "    ax.set_aspect('equal')\n",
        "    ax.voxels(voxel, edgecolor=\"green\")\n",
        "    #plt.show()\n",
        "    plt.savefig(file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZnSXNrTKv35"
      },
      "source": [
        "# 데이터 디렉토리 및 모델 파라미터 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grTXyQP3Kyy1"
      },
      "source": [
        "object_name = \"airplane\"\n",
        "data_dir = \"D:/data_sets/3DShapeNets/volumetric_data/{}/30/train/*.mat\".format(object_name)\n",
        "print(data_dir)\n",
        "\n",
        "lr = 2e-4\n",
        "decay = 6e-8\n",
        "beta = 0.5\n",
        "batch_size = 10\n",
        "z_size = 200\n",
        "epochs = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kpDX72QK17i"
      },
      "source": [
        "# 모델 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi39nhdcK6FM"
      },
      "source": [
        "#모델 옵티마이저 정의\n",
        "optimizer = RMSprop(lr=lr, decay=decay)\n",
        "\n",
        "#판별기 구성\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='mse',optimizer=optimizer, metrics=['accuracy'])\n",
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czc_LkFwK-Ys"
      },
      "source": [
        "#생성기 구성\n",
        "generator = build_generator()\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCjNqN2tLAlH"
      },
      "source": [
        "#적대적 모델 구성\n",
        "optimizer = RMSprop(lr=0.5*lr, decay=0.5*decay)\n",
        "\n",
        "discriminator.trainable = False\n",
        "inputs = Input(shape = (1, 1, 1, z_size), name='z_input')\n",
        "adversarial = Model(inputs, discriminator(generator(inputs)), name='3D-GAN')\n",
        "\n",
        "adversarial.compile(loss = 'mse', optimizer=optimizer,metrics=['accuracy'])\n",
        "adversarial.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHyBWEPhLHIx"
      },
      "source": [
        "# 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F1gV4gVLC_6"
      },
      "source": [
        "# 데이터 로딩\n",
        "volumes = get3DImages(data_dir=data_dir)\n",
        "volumes = volumes[...,np.newaxis].astype(np.float)\n",
        "\n",
        "train_size = volumes.shape[0]\n",
        "print(train_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCpvkEQHLL_9"
      },
      "source": [
        "# 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf6upz50LIq9"
      },
      "source": [
        "models = (generator, discriminator, adversarial)\n",
        "params = (batch_size, z_size ,epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g66lAOfRLLnq"
      },
      "source": [
        "# 모델 훈련 \n",
        "def train(models, x_train, params):\n",
        "    generator, discriminator, adversarial = models\n",
        "    batch_size, z_size, epochs = params    \n",
        "    \n",
        "    train_size = x_train.shape[0]\n",
        "    number_of_batches = int(x_train.shape[0]/batch_size)\n",
        "    \n",
        "    real_labels = np.ones([batch_size,1])\n",
        "    fake_labels = np.zeros([batch_size,1])\n",
        "    \n",
        "    for epoch in range(epochs):     \n",
        "              \n",
        "        print(\"epoch : \", (epoch+1))\n",
        "        \n",
        "        for index in range (number_of_batches):\n",
        "            process = round((index+1)/number_of_batches, 3)\n",
        "            rep_star = \"[\"+int(process*20)*\"=\"+int((1-process)*20)*\" \"+\"]\"+str(process)\n",
        "            volumes_batch = x_train[index*batch_size:(index+1)*batch_size,:,:,:]\n",
        "            \n",
        "            z_sample = np.random.uniform(-1.0, 1.0, size=[batch_size,1,1,1,z_size])\n",
        "            \n",
        "            gen_volumes = generator.predict_on_batch(z_sample)\n",
        "            discriminator.trainable = True\n",
        "            real_loss, real_acc = discriminator.train_on_batch(volumes_batch, real_labels)   \n",
        "            fake_loss, fake_acc = discriminator.train_on_batch(gen_volumes, fake_labels)\n",
        "            \n",
        "            d_loss = 0.5*(real_loss+fake_loss)\n",
        "            d_acc = 0.5*(real_acc+fake_acc)\n",
        "            \n",
        "            discriminator.trainable = False\n",
        "            z = np.random.uniform(-1.0, 1.0, size=[batch_size,1,1,1,z_size])\n",
        "            g_loss, g_acc = adversarial.train_on_batch(z, real_labels)\n",
        "            \n",
        "            log = \"[discriminator loss : %f, acc: %f] [adversarial loss: %f, acc: %f] process:%s\" %(d_loss, d_acc, g_loss, g_acc, rep_star)\n",
        "            print(log, end=\"\\r\")\n",
        "            \n",
        "        print(log)\n",
        "        \n",
        "        if (epoch+1)%10 ==0:\n",
        "            z_sample2 = np.random.normal(0, 0.33, size = [batch_size, 1, 1, 1, z_size]).astype(np.float32)\n",
        "            generated_volumes = generator.predict(z_sample2, verbose=3)\n",
        "            \n",
        "            for i, generated_volume in enumerate(generated_volumes[:5]):\n",
        "                voxels = np.squeeze(generated_volume)\n",
        "                voxels[voxels<0.5] = 0.\n",
        "                voxels[voxels>=0.5] = 1.\n",
        "                saveFromVoxels(voxels, \"D:/data_sets/3D_results/img_{}_{}\".format(epoch+1,i))\n",
        "                \n",
        "    generator.save('3D_generator.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqknLoweLRI6"
      },
      "source": [
        "train(models, volumes, params)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}