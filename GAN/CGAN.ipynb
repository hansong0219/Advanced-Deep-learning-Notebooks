{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxZuySYhR43qgvHBFqgUID",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansong0219/Advanced-DeepLearning-Study/blob/master/GAN/CGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crSSsf6DhooD"
      },
      "source": [
        "# Conditional GAN\n",
        "\n",
        "DCGAN 에서는 이미지가 임의로 생성되며, 생성기에서 어떤 숫자를 생성할지는 제어할 수 없다. 이 문제를 원-핫 벡터를 추가로 입력을 받는 것으로 해결한 것이 바로 Conditional GAN (CGAN) 이다. \n",
        "\n",
        "동일한 GAN의 구조를 사용하면서도 생성기에서 원-핫 벡터를 추가로 받고 새로운 Dense 계층을 추가해 잠재벡터와 연결된다. 또, 판별기에서는 새로운 Dense 계층이 추가된다. 이 새로운 게층은 원-핫 벡터를 처리하고 뒤따라나오는 CNN 계층의 다른 입력과 연결하기에 적합한 형상으로 변경하기 위해 사용된다.\n",
        "\n",
        "생성기는 100차원 입력 벡터와 특정 숫자로 부터 가짜 이미지를 생성하는 것을 학습하며, 판별기는 진짜와 가짜 이미지, 그리고 그에 대응하는 레이블을 기반으로 진짜와 가짜 이미지를 분류한다.\n",
        "\n",
        "CGAN 의 기본 원리는 GAN 과 동일하지만,  판별기와 생성기 입력에 원-핫 레이블 y 라는 조건이 부여된다는 점이 다르다.\n",
        "\n",
        "판별기와 생성기는 아래와 같이 구성된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxUGoxGjOill"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vORp_28lOmji"
      },
      "source": [
        "## GPU 할당\n",
        "\n",
        "Colab 이 아닌 windows 환경에서는 아래의 코드를 실행하여 gpu의 할당을 구현할 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_umBkt67OP-s"
      },
      "source": [
        "#import tensorflow as tf \n",
        "#physical_devices =tf.config.experimental.list_pysical_devices('GPU')\n",
        "#tf.config.exprimental.set_memory_growth(physical_devices[0],True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzTtl6FrOpAh"
      },
      "source": [
        "## Module 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2-qf7l7N9XM"
      },
      "source": [
        "from tensorflow.keras.layers import Activation, Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import argparse"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUjXoyBWOvbC"
      },
      "source": [
        "# Model 빌드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rRsc_y_jBkE"
      },
      "source": [
        "# 판별기 구성 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KE5n2_zhmUf"
      },
      "source": [
        "def build_discriminator(inputs, y_labels, image_size):\n",
        "  # 판별기 모델 구성\n",
        "  \"\"\"\n",
        "  입력은 Dense 계층 다음에서 연결되며, 진짜와 가짜를 판별하기 위한 LeakyReLU-Conv2D 스택으로 구성되어있다. \n",
        "  \"\"\"\n",
        "\n",
        "  # 입력 인자 \n",
        "  \"\"\"\n",
        "  inputs (layer) : 판별기의 입력계층\n",
        "  y_labels (layer) : 입력에 조건을 부여하는 원-핫 벡터를 위한 입력 계층\n",
        "  image_size : 한변의 목표 크기 (이미지는 정사각형으로 가정한다)\n",
        "  \"\"\"\n",
        "\n",
        "  #return - Model : 판별기의 모델을 반환한다.\n",
        "\n",
        "  kernel_size = 5\n",
        "  layer_filters = [32, 64, 128, 256]\n",
        "\n",
        "  x = inputs\n",
        "  y = Dense(image_size*image_size)(y_labels)\n",
        "  y = Reshape((image_size,image_size, 1))(y)\n",
        "  x = concatenate([x,y])\n",
        "\n",
        "  for filters in layer_filters:\n",
        "    # 첫 3개 합성곱 계층에서는 strides = 2 이며, 마지막 계층은 strides = 1 을 사용한다.\n",
        "    if filters == layer_filters[-1]:\n",
        "      strides = 1\n",
        "    else:\n",
        "      strides = 2\n",
        "\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "    x = Conv2D(filters = filters, kernel_size = kernel_size, strides= strides, padding='same')(x)\n",
        "\n",
        "  \n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1)(x)\n",
        "  x = Activation('sigmoid')(x)\n",
        "\n",
        "  # 입력은 y_labels 에 의해 조건이 부여됨 \n",
        "  discriminator = Model([inputs, y_labels], x, name='discriminator')\n",
        "\n",
        "  return discriminator"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_LAOe2ZjGFP"
      },
      "source": [
        "# 생성기 모델 구성 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl6KSCnjjIMi"
      },
      "source": [
        "def build_generator(inputs, y_labels, image_size):\n",
        "  # 생성기 모델 구성\n",
        "  \"\"\"\n",
        "  입력은 Dense 계층 전에 연결된다. \n",
        "  가짜 이미지를 생성하기 위한 BN-ReLU-Conv2DTranspose 스택, 출력계층의 활성화 함수로 sigmoid를 사용함\n",
        "  \"\"\"\n",
        "\n",
        "  # 함수 입력 인수 \n",
        "  \"\"\"\n",
        "  inputs (layer): 생성기의 입력 계층 (노이즈 벡터)\n",
        "  y_labels (layer): 입력에 조건을 부여하는 원-핫 벡터 입력계층\n",
        "  image_size : 한변의 목표 크기 \n",
        "  \"\"\"\n",
        "  \n",
        "  #return - Model : 생성기 모델 \n",
        "\n",
        "  image_resize = image_size//4\n",
        "\n",
        "  #네트워크 매개 변수 \n",
        "  kernel_size = 5\n",
        "  layer_filters = [128, 64, 32, 1]\n",
        "\n",
        "  x = concatenate([inputs, y_labels], axis=1)\n",
        "  x = Dense(image_resize * image_resize * layer_filters[0])(x)\n",
        "  x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n",
        "\n",
        "  for filters in layer_filters:\n",
        "    # 처음 두 합성곱 계층은 strides = 2를 사용\n",
        "    # 마지막 두 계층은 strides = 1을 사용\n",
        "    if filters > layer_filters[-2]:\n",
        "      strides = 2\n",
        "    else:\n",
        "      strides = 1\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "\n",
        "  \n",
        "  x = Activation('sigmoid')(x)\n",
        "\n",
        "  # 입력은 y_label에 의해 조건이 부여됨\n",
        "  generator = Model([inputs, y_labels], x, name='generator')\n",
        "\n",
        "  return generator"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNb-rOmDpMgv"
      },
      "source": [
        "# Data Set 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXcQcX3opNXy"
      },
      "source": [
        "# MNIST 불러오기 \n",
        "(x_train, y_train), (_, _) = mnist.load_data()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxKZ3FYlpy96"
      },
      "source": [
        "# CNN 을 위한 데이터형상 조정 및 정규화\n",
        "image_size = x_train.shape[1]\n",
        "x_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
        "x_train = x_train.astype('float32')/255\n",
        "\n",
        "# 라벨 지정\n",
        "num_labels = np.amax(y_train) + 1\n",
        "y_train = to_categorical(y_train)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ik-YjHEo9-q"
      },
      "source": [
        "# CGAN 모델 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCIXSvyko9oX"
      },
      "source": [
        "model_name = \"cgan_mnist\"\n",
        "\n",
        "# 네트워크 매개 변수 지정\n",
        "latent_size = 100\n",
        "batch_size = 64\n",
        "train_steps = 40000\n",
        "lr = 2e-4\n",
        "decay = 6e-8\n",
        "input_shape = (image_size, image_size, 1)\n",
        "label_shape = (num_labels, )"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG7CtRwqqU4t",
        "outputId": "7cc9ee77-4dd7-4080-bd12-f530b9679471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "source": [
        "# 판별기 구성\n",
        "inputs = Input(shape=input_shape, name='discriminator_input')\n",
        "labels = Input(shape=label_shape, name='class_labels')\n",
        "\n",
        "discriminator = build_discriminator(inputs, labels, image_size)\n",
        "optimizer = RMSprop(lr=lr, decay=decay)\n",
        "\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "discriminator.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "class_labels (InputLayer)       [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 784)          8624        class_labels[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "discriminator_input (InputLayer [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 28, 28, 1)    0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 28, 28, 2)    0           discriminator_input[0][0]        \n",
            "                                                                 reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 28, 28, 2)    0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 14, 14, 32)   1632        leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 14, 14, 32)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 7, 7, 64)     51264       leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 7, 7, 64)     0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 4, 4, 128)    204928      leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 4, 4, 128)    0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 4, 4, 256)    819456      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 4096)         0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            4097        flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 1)            0           dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,090,001\n",
            "Trainable params: 1,090,001\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXUhCf8wrp9q",
        "outputId": "40bf9a3e-c1ec-4158-e5fb-b3f803e958dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        }
      },
      "source": [
        "# 생성기 구성\n",
        "input_shape = (latent_size, )\n",
        "inputs = Input(shape=input_shape, name='z_input')\n",
        "generator = build_generator(inputs, labels, image_size)\n",
        "generator.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "z_input (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "class_labels (InputLayer)       [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 110)          0           z_input[0][0]                    \n",
            "                                                                 class_labels[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 6272)         696192      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 7, 7, 128)    0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 7, 7, 128)    512         reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 7, 7, 128)    0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 14, 14, 128)  409728      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 14, 14, 128)  512         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 14, 14, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 28, 28, 64)   204864      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 28, 28, 64)   256         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 28, 28, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 28, 28, 32)   51232       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 28, 28, 32)   128         conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTrans (None, 28, 28, 1)    801         activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 1)    0           conv2d_transpose_8[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 1,364,225\n",
            "Trainable params: 1,363,521\n",
            "Non-trainable params: 704\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEOsyF_IrwC7",
        "outputId": "9d386a35-bbc0-4eb9-c551-194afeaa6a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "# 적대적 모델 구성\n",
        "optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
        "\n",
        "# 적대적 모델의 훈련에서는 판별기에 가중치를 반영하지 않는다\n",
        "discriminator.trainable = False\n",
        "    \n",
        "outputs = discriminator([generator([inputs, labels]), labels])\n",
        "adversarial = Model([inputs, labels], outputs, name=model_name)\n",
        "\n",
        "adversarial.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "adversarial.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"cgan_mnist\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "z_input (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "class_labels (InputLayer)       [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "generator (Functional)          (None, 28, 28, 1)    1364225     z_input[0][0]                    \n",
            "                                                                 class_labels[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "discriminator (Functional)      (None, 1)            1090001     generator[0][0]                  \n",
            "                                                                 class_labels[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 2,454,226\n",
            "Trainable params: 1,363,521\n",
            "Non-trainable params: 1,090,705\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OafMeLAytUzZ"
      },
      "source": [
        "모델 변수 입력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACoMNDOWtS0V"
      },
      "source": [
        "models = (generator, discriminator, adversarial)\n",
        "data = (x_train, y_train)\n",
        "params = (batch_size, latent_size, train_steps, num_labels, model_name)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u89f5Jf0lZzm"
      },
      "source": [
        "# Plot 함수정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzfIUoy2lZdU"
      },
      "source": [
        "def plot_images(generator,\n",
        "                noise_input,\n",
        "                noise_class,\n",
        "                show=False,\n",
        "                step=0,\n",
        "                model_name=\"gan\"):\n",
        "\n",
        "    os.makedirs(model_name, exist_ok=True)\n",
        "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
        "    images = generator.predict([noise_input, noise_class])\n",
        "    print(model_name , \" labels for generated images: \", np.argmax(noise_class, axis=1))\n",
        "    plt.figure(figsize=(2.2, 2.2))\n",
        "    num_images = images.shape[0]\n",
        "    image_size = images.shape[1]\n",
        "    rows = int(math.sqrt(noise_input.shape[0]))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(rows, rows, i + 1)\n",
        "        image = np.reshape(images[i], [image_size, image_size])\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.savefig(filename)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close('all')\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhtiEziWtCU8"
      },
      "source": [
        "# 모델 훈련\n",
        "\n",
        "모델 훈련 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbHs2b-dkHyK"
      },
      "source": [
        "def train(models, data, params):\n",
        "  # 판별기와 적대적 네트워크의 훈련 \n",
        "  \"\"\"\n",
        "  배치 단위로 판별기와 적대적 네트워크가 교대로 훈련된다. 판별기는 우선 적절한 레이블을 붙인 진짜와 가짜 이미지를 사용하여 운련된다.\n",
        "  그 다음으로 적대적 네트워크는 진짜인 척 하는 가짜 이미지를 사용하여 훈련이 된다. \n",
        "\n",
        "  판별기의 입력은 진짜 이미지에 대한 훈련 라벨과 가짜 이미지에 대한 랜덤 레이블에 의해 조건이 부여된다. \n",
        "  적대적 네트워크의 입력은 랜덤 레이블에 의해 조건이 부여된다.\n",
        "  \"\"\"\n",
        "\n",
        "  # 함수 입력 인수\n",
        "  \"\"\"\n",
        "  model (list) : Generator, Discriminator, Adversarial models\n",
        "  data (list): x_train, y_train 데이터\n",
        "  params (list): 네트워크 매개 변수\n",
        "  \"\"\"\n",
        "\n",
        "  # GAN 모델 \n",
        "  generator, discriminator, adversarial = models\n",
        "  # 이미지 레이블 \n",
        "  x_train, y_train = data  \n",
        "  # 네트워크 매개변수\n",
        "  batch_size, latent_size, train_steps, num_labels, model_name = params\n",
        "\n",
        "  # 생성기의 이미지는 500 epochs 마다 저장됨\n",
        "  save_interval = 500\n",
        "  # 훈련하는 동안 생성기 출력을 보여주기 위한 노이즈 벡터\n",
        "  noise_input = np.random.uniform(-1.0, 1.0, size=[16,latent_size])\n",
        "\n",
        "  #노이즈에 조건을 부여할 원-핫 레이블\n",
        "  noise_class = np.eye(num_labels)[np.arange(0, 16) % num_labels]\n",
        "  \n",
        "  # 훈련 데이터 세트의 요소 개수 \n",
        "  train_size = x_train.shape[0]\n",
        "\n",
        "  print(model_name, \"Labels for generated images:\", np.argmax(noise_class,axis=1))\n",
        "\n",
        "  for i in range(train_steps):\n",
        "    # 1 배치 에 대한 판별기 훈련 \n",
        "    \n",
        "    # 데이터 세트에서 진짜 이미지를 임의로 선정\n",
        "    rand_indices = np.random.randint(0, train_size, size=batch_size)\n",
        "    real_images = x_train[rand_indices]\n",
        "    # 대응하는 원-핫 레이블 생성 \n",
        "    real_labels = y_train[rand_indices]\n",
        "\n",
        "    #생성기를 사용해 노이즈로 부터 가짜 이미지 생성\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "    \n",
        "    #임의의 원-핫 레이블 할당\n",
        "    fake_labels = np.eye(num_labels)[np.random.choice(num_labels, batch_size)]\n",
        "    #가짜레이블 조건으로 하는 가짜이미지 생성\n",
        "    fake_images = generator.predict([noise, fake_labels])\n",
        "\n",
        "    #진짜 이미지 + 가짜이미지 를 1배치 훈련데이터로 사용\n",
        "    x = np.concatenate((real_images, fake_images))\n",
        "    y_labels = np.concatenate((real_labels, fake_labels))\n",
        "\n",
        "    #진짜와 가짜 이미지에 레이블을 붙임\n",
        "    #진짜이미지 레이블은 1, 가짜 이미지 레이블은 0\n",
        "    y = np.ones([2*batch_size,1])\n",
        "    y[batch_size:,:] = 0.0\n",
        "\n",
        "    #log 기록 \n",
        "    loss, acc = discriminator.train_on_batch([x, y_labels],y)\n",
        "    log = \"%d: [discriminator loss: %f, acc:%f]\" %(i, loss, acc)\n",
        "\n",
        "    #1 배치에 대한 적대적 네트워크 훈련\n",
        "    #레이블이 1인 가짜 원핫 레이블을 조건으로 하는 가짜 이미지의 1배치\n",
        "    #적대적 네으퉈크에서 파별기의 가중치는 고정되기 때문에 생성기만 훈련이된다. \n",
        "\n",
        "    #균등분포를 통해 노이즈 생성 \n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size,latent_size])\n",
        "\n",
        "    #임의의 원-핫 레이블 할당\n",
        "    fake_labels = np.eye(num_labels)[np.random.choice(num_labels,batch_size)]\n",
        "\n",
        "    # 가짜 이미지에 진짜로 속이는 레이블을 붙임\n",
        "    y = np.ones([batch_size, 1])\n",
        "    \n",
        "    #적대적 네으퉈크 훈련\n",
        "    #판별기 훈련과 달리 변수에 가짜 이미지를 별도의 변수로 저장하지 않으며, 분류를 위해 가짜 이미지는 적대적 네트워크의 판별기 입력으로 전달됨\n",
        "\n",
        "    #log 기록\n",
        "    loss, acc = adversarial.train_on_batch([noise, fake_labels], y)\n",
        "    log = \"%s [adversarial loss : %f, acc : %f]\" %(log, loss, acc)\n",
        "    print(log)\n",
        "\n",
        "    if (i+1) % save_interval == 0:\n",
        "      if (i+1) == train_steps:\n",
        "        show = True\n",
        "      else:\n",
        "        show = False\n",
        "\n",
        "      plot_images(generator, noise_input=noise_input,noise_class=noise_class,show=show, step=(i+1), model_name=model_name) \n",
        "\n",
        "  generator.save(model_name+\".h5\")"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG7qAuO-Ie6r",
        "outputId": "0744294c-5f97-4dc5-a39a-5d353befcc69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        }
      },
      "source": [
        "train(models, data, params)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cgan_mnist Labels for generated images: [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]\n",
            "0: [discriminator loss: 0.614064, acc:0.828125] [adversarial loss : 1.154150, acc : 0.000000]\n",
            "1: [discriminator loss: 0.493613, acc:1.000000] [adversarial loss : 1.486888, acc : 0.000000]\n",
            "2: [discriminator loss: 0.347265, acc:1.000000] [adversarial loss : 0.965978, acc : 0.000000]\n",
            "3: [discriminator loss: 0.206373, acc:1.000000] [adversarial loss : 2.836246, acc : 0.000000]\n",
            "4: [discriminator loss: 0.203657, acc:0.976562] [adversarial loss : 0.236512, acc : 1.000000]\n",
            "5: [discriminator loss: 0.140484, acc:1.000000] [adversarial loss : 2.231820, acc : 0.000000]\n",
            "6: [discriminator loss: 0.085524, acc:1.000000] [adversarial loss : 0.942631, acc : 0.000000]\n",
            "7: [discriminator loss: 0.036926, acc:1.000000] [adversarial loss : 0.601828, acc : 1.000000]\n",
            "8: [discriminator loss: 0.025494, acc:1.000000] [adversarial loss : 0.462506, acc : 1.000000]\n",
            "9: [discriminator loss: 0.019973, acc:1.000000] [adversarial loss : 0.342037, acc : 1.000000]\n",
            "10: [discriminator loss: 0.014898, acc:1.000000] [adversarial loss : 0.263484, acc : 1.000000]\n",
            "11: [discriminator loss: 0.013273, acc:1.000000] [adversarial loss : 0.184404, acc : 1.000000]\n",
            "12: [discriminator loss: 0.010481, acc:1.000000] [adversarial loss : 0.145810, acc : 1.000000]\n",
            "13: [discriminator loss: 0.009726, acc:1.000000] [adversarial loss : 0.104962, acc : 1.000000]\n",
            "14: [discriminator loss: 0.007249, acc:1.000000] [adversarial loss : 0.078916, acc : 1.000000]\n",
            "15: [discriminator loss: 0.006354, acc:1.000000] [adversarial loss : 0.062372, acc : 1.000000]\n",
            "16: [discriminator loss: 0.005534, acc:1.000000] [adversarial loss : 0.047092, acc : 1.000000]\n",
            "17: [discriminator loss: 0.005502, acc:1.000000] [adversarial loss : 0.030012, acc : 1.000000]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-974c702a5273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-841f581fa195>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(models, data, params)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m#log 기록\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s [adversarial loss : %f, acc : %f]\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQq8hv16sbXw"
      },
      "source": [
        "# 생성기 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbCxTLjisauC"
      },
      "source": [
        "def test_generator(generator, class_label=None):\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
        "    step = 0\n",
        "    if class_label is None:\n",
        "        num_labels = 10\n",
        "        noise_class = np.eye(num_labels)[np.random.choice(num_labels, 16)]\n",
        "    else:\n",
        "        noise_class = np.zeros((16, 10))\n",
        "        noise_class[:,class_label] = 1\n",
        "        step = class_label\n",
        "\n",
        "    plot_images(generator,\n",
        "                noise_input=noise_input,\n",
        "                noise_class=noise_class,\n",
        "                show=True,\n",
        "                step=step,\n",
        "                model_name=\"test_outputs\")\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAymybSjsdMq"
      },
      "source": [
        "class_label = None\n",
        "test_generator(generator, class_label)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}