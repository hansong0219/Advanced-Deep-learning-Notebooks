{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansong0219/Advanced-DeepLearning-Study/blob/master/GAN/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrgrAucLW8_q"
      },
      "source": [
        "DCGAN\n",
        "----\n",
        "DCGAN 은 초기 심층 CNN 을 이용해 GAN 을 성공적으로 구현한 사례중 하나로, 다음과 같은 설계 원칙을 가지고 있다.\n",
        "\n",
        "- MaxPooling2D 나 UpSampling2D 대신 stride>1 인 합성곱을 사용한다. stride 가 >1 일 경우, CNN 은 특징 맵 크기를 조정하는 방법을 학습하게 된다.\n",
        "\n",
        "- Dense 계층의 사용을 피한다. 모든 계층에서 CNN 을 사용하도록 하며, Dense 계층은 생성기의 첫 번째 계층에서만 Z-vector 를 받기위해 사용된다. Dense 계층의 출력 크기는 조정되어 뒤따라 나오는 CNN 계층의 입력이 된다.\n",
        "\n",
        "- 각 계층의 입력이 평균 0 에 단위 분산을 가져서 학습을 안정화 시키도록 Batch Normaliztion 을 사용한다. 생성기 출력 계층과 판별기 입력 계층에는 Batch Normalization을 사용하지 않는다.\n",
        "\n",
        "- Rectitfied Linear Unit, ReLU 는 tanh 활성화 함수를 사용하는 출력 계층을 제외하고 생성기 전 층에서 사용된다. 아래에서는 tanh 대신 sigmoid 가 사용되는데, 일반적으로 MNIST 숫자에 대해 더 안정적으로 훈련시킬 수 있기 때문이다.\n",
        "\n",
        "- 판별기의 전 계층에서 Leaky ReLU 를 사용한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ke_xgxBW5Wl"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Activation, Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90c6Kh_WeJRT"
      },
      "source": [
        "모델 Build 를 위한 함수\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6PMI00PeQth"
      },
      "source": [
        "## 생성자 함수구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv_CbRR8eGI1"
      },
      "source": [
        "# 생성기 모델 구성\n",
        "\"\"\"\n",
        "가짜 이미지 생성을 위한 BN-ReLU-Conv2DTranspose 스택 \n",
        "출력계층의 활성화 함수로는 sigmoid 를 사용한다.\n",
        "\n",
        "함수의 인수\n",
        "inputs(Layer) : 생성기의 입력계층(z-vector 형태)\n",
        "image_size: 이미지의 한 축의 목표 scale  (정사각형으로 가정)\n",
        "\n",
        "return \n",
        "model: 생성기 모델\n",
        "\"\"\"\n",
        "\n",
        "def build_generator(inputs, image_size):\n",
        "  image_resize = image_size//4\n",
        "\n",
        "  kernel_size = 5\n",
        "  layer_filters = [128, 64, 32, 1]\n",
        "\n",
        "  x = Dense(image_resize*image_resize*layer_filters[0])(inputs)\n",
        "  x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n",
        "\n",
        "  for filters in layer_filters:\n",
        "    # 첫 두 합성곱 계층만 strides = 2 사용\n",
        "    if filters > layer_filters[-2]:\n",
        "      strides = 2\n",
        "    else:\n",
        "      strides = 1\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(filters=filters,\n",
        "                        kernel_size = kernel_size,\n",
        "                        strides = strides,\n",
        "                        padding = 'same')(x)\n",
        "  \n",
        "  x = Activation('sigmoid')(x)\n",
        "\n",
        "  generator = Model(inputs, x, name = 'generator')\n",
        "  \n",
        "  return generator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krQbbFgSeY8n"
      },
      "source": [
        "## 판별자 함수 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMPJMeqpeaTZ"
      },
      "source": [
        "# 판별기 모델 구성 \n",
        "\"\"\"\n",
        "진짜와 가짜를 구분하는 LeakyReLu - Conv2D 스택으로 구성이 되어있다.\n",
        "BN 으로는 네트워크가 수렴하지 않으므로 BN을 사용하지 않았다.\n",
        "\n",
        "inputs(Layer): 판별기의 입력 계층 (이미지)\n",
        "\n",
        "return\n",
        "Model: 판별기 모델 \n",
        "\"\"\"\n",
        "\n",
        "def build_discriminator(inputs):\n",
        "  kernel_size = 5\n",
        "  layer_filters = [32, 64, 128, 256]\n",
        "\n",
        "  x = inputs\n",
        "  for filters in layer_filters:\n",
        "    # 첫 3개의 합성곱 계층은 strides = 2 개 사용, 마지막 계층은 stride = 1 사용\n",
        "    if filters == layer_filters[-1]:\n",
        "      strides = 1\n",
        "    else:\n",
        "      strides = 2\n",
        "    \n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Conv2D(filters= filters,\n",
        "               kernel_size= kernel_size,\n",
        "               strides= strides,\n",
        "               padding= 'same')(x)\n",
        "    \n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1)(x)\n",
        "  x = Activation('sigmoid')(x)\n",
        "\n",
        "  discriminator = Model(inputs, x, name='discriminator')\n",
        "  \n",
        "  return discriminator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsBpRODHEFqZ"
      },
      "source": [
        "def plot_images(generator,\n",
        "                noise_input,\n",
        "                show=False,\n",
        "                step=0,\n",
        "                model_name=\"gan\"):\n",
        "    \"\"\"\n",
        "    생성한 이미지를 visualize 해주는 코드 \n",
        "    \"\"\"\n",
        "    os.makedirs(model_name, exist_ok=True)\n",
        "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
        "    images = generator.predict(noise_input)\n",
        "    plt.figure(figsize=(2.2, 2.2))\n",
        "    num_images = images.shape[0]\n",
        "    image_size = images.shape[1]\n",
        "    rows = int(math.sqrt(noise_input.shape[0]))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(rows, rows, i + 1)\n",
        "        image = np.reshape(images[i], [image_size, image_size])\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.savefig(filename)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close('all')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hqvK0oC6EOM"
      },
      "source": [
        "# 모델훈련"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOwczZnq5V1e"
      },
      "source": [
        "## 데이터셋 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_Qq5YpD5TNn",
        "outputId": "b53a45b7-a7e8-4fd7-edb0-4b01eaba81f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#MNIST 데이터 셋 로딩\n",
        "(x_train,_), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# CNN 을 위한 데이터형상 조정 및 정규화\n",
        "image_size = x_train.shape[1]\n",
        "x_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
        "x_train = x_train.astype('float32')/255"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62w2dSpW57vl"
      },
      "source": [
        "## 모델 훈련을 위한 네트워크 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJxdzGYR5TKY"
      },
      "source": [
        "model_name = \"dcgan_mnist\"\n",
        "\n",
        "# 네트워크 매개 변수 지정\n",
        "latent_size = 100\n",
        "batch_size = 64\n",
        "train_steps = 40000\n",
        "lr = 2e-4\n",
        "decay = 6e-8\n",
        "input_shape = (image_size, image_size, 1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiRGqf_U7Lw1",
        "outputId": "a1de51fc-1a8c-4bda-d697-db8f006782a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "# 판별기 모델 구성\n",
        "inputs = Input(shape = input_shape, name = 'discriminator_input')\n",
        "discriminator = build_discriminator(inputs)\n",
        "optimizer = RMSprop(lr=lr, decay=decay)\n",
        "\n",
        "discriminator.compile(loss = 'binary_crossentropy',\n",
        "                      optimizer = optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "discriminator.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "discriminator_input (InputLa [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 14, 14, 32)        832       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 64)          51264     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 4097      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,080,577\n",
            "Trainable params: 1,080,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsHXAcgx78TI",
        "outputId": "2497c538-2dcf-4537-d7e7-c6b59b435d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        }
      },
      "source": [
        "# 생성기 모델 구성\n",
        "input_gen = (latent_size,)\n",
        "inputs = Input(shape = input_gen, name = 'g_input')\n",
        "generator = build_generator(inputs, image_size)\n",
        "\n",
        "generator.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "g_input (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6272)              633472    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       409728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        51232     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         801       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,301,505\n",
            "Trainable params: 1,300,801\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQAj0tB88bft",
        "outputId": "6c6e32c4-e831-4c53-980e-0592e22861fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# 적대적 모델 구성 결합\n",
        "optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
        "#적대적 모델을 훈련하는 동안 판별기의 가중치는 고정한다.\n",
        "discriminator.trainable = False\n",
        "\n",
        "#adversarial = generator + discriminator\n",
        "adversarial = Model(inputs, discriminator(generator(inputs)), name=model_name)\n",
        "\n",
        "adversarial.compile(loss = 'binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "adversarial.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"dcgan_mnist\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "g_input (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "generator (Functional)       (None, 28, 28, 1)         1301505   \n",
            "_________________________________________________________________\n",
            "discriminator (Functional)   (None, 1)                 1080577   \n",
            "=================================================================\n",
            "Total params: 2,382,082\n",
            "Trainable params: 1,300,801\n",
            "Non-trainable params: 1,081,281\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am8N4-sE9hv3"
      },
      "source": [
        "models = (generator, discriminator, adversarial)\n",
        "params = (batch_size, latent_size, train_steps, model_name)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdrOalrp93Nb"
      },
      "source": [
        "# 모델 훈련 함수 지정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11rsVUNO-Ie1"
      },
      "source": [
        "GAN 의경우 맞춤 훈련을 위해 일반적인 fit() 함수를 사용하지 않는다. 그 대신, 데이터 배치가 주어졌을 때에 대해 단일 경사 업데이트를 실행하기 위해 train_on_batch() 함수를 사용한다.\n",
        "아래의 train 함수는 위에서 구현한 모델을 훈련하기 위한 함수를 나타낸다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0WwLoSu9wZA"
      },
      "source": [
        "def train(models, x_train, params):\n",
        "  # 함수의 인수로는 앞선 셀에서 리스트로 지정된 models 와 params, 그리고 훈련 이미지인 x_train 이 있다.\n",
        "  \n",
        "  \"\"\"\n",
        "  판별기와 적대적 네트워크를 훈련한 후, 배치 단위로 판별기와 적대적 네트워크를 교대로 훈련한다. \n",
        "  우선 판별기는 제대로 레이블이 붙은 진짜와 가짜 이미지를 가지고 훈련 시킨 후, \n",
        "  다음으로 적대적 네트워크를 진짜인척 하는 가짜 이미지를 사용하여 훈련시킨다.\n",
        "  \"\"\"\n",
        "\n",
        "  # GAN 모델 불러오기\n",
        "  generator, discriminator, adversarial = models\n",
        "\n",
        "  # 네트워크 매개변수\n",
        "  batch_size, latent_size, train_steps, model_name\n",
        "\n",
        "  # 500 단계 마다 생성기 이미지가 저장되도록 설정\n",
        "  save_interval = 500\n",
        "\n",
        "  #훈련 기간 동안 생성기 출력 이미지가 어떻게 변화하는지 보여주기 위한 노이즈 벡터\n",
        "  noise_input = np.random.uniform(-1.0, 1.0, size = [16, latent_size])\n",
        "  \n",
        "  # 훈련 이미지의 개수\n",
        "  train_size = x_train.shape[0]\n",
        "\n",
        "  for i in range(train_steps):\n",
        "    # 1 배치에 대해 판별기 훈련\n",
        "    # 데이터 셋에서 임의로 진짜 이미지를 선택한다\n",
        "    rand_indices = np.random.randint(0, train_size, size = batch_size)\n",
        "    real_images = x_train[rand_indices]\n",
        "\n",
        "    #생성기를 사용해 노이즈로 부터 가짜 이미지를 생성한다.\n",
        "    \n",
        "    # 노이즈 분포 사용해 노이즈 생성\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "\n",
        "    # 가짜 이미지 생성\n",
        "    fake_images = generator.predict(noise)\n",
        "    \n",
        "    # 진짜 이미지와 가짜이미지의 훈련데이터의 배치 \n",
        "    x = np.concatenate((real_images, fake_images))\n",
        "    # 레이블을 붙임\n",
        "    y = np.ones([2*batch_size, 1])\n",
        "    y[batch_size:, :] = 0.0\n",
        "\n",
        "    #판별기 훈련 및 손실과 정확도 기록\n",
        "    loss, acc = discriminator.train_on_batch(x, y)\n",
        "    log = \"%d:[discriminator loss = %f, acc: %f]\" %(i, loss, acc)\n",
        "\n",
        "    # 1 배치에 대한 적대적 네트워크 훈련 \n",
        "    # label = 1.0 인 가짜 이미지로 구성된 배치 \n",
        "\n",
        "    #판별기의 가중치가 고정되므로 생성기만 훈련된다.\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "    \n",
        "    # 가짜 이미지에 진짜 혹은 1.0 으로 레이블\n",
        "    y = np.ones([batch_size, 1])\n",
        "\n",
        "    #판별기를 훈련시키는 것과 달리 변수에 가짜 이미지를 저장하지 않는다.\n",
        "    #가짜 이미지는 분류를 위해 적대적 네트워크의 판별기 입력으로 전달됨\n",
        "\n",
        "    loss, acc = adversarial.train_on_batch(noise, y)\n",
        "    log = \"%s:[adversarial loss = %f, acc: %f]\" %(log, loss, acc)\n",
        "    print(log)\n",
        "\n",
        "    if (i+1) % save_interval == 0:\n",
        "      if (i+1) == train_steps:\n",
        "        show = True\n",
        "      else:\n",
        "        show = False\n",
        "\n",
        "      plot_images(generator, noise_input=noise_input, show=show, step=(i+1), model_name=model_name)\n",
        "    \n",
        "  genrator.save(model_name+\".h5\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbaYffVhE139",
        "outputId": "1c8ccbfa-730c-41ba-fd77-e38652fe6799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "train(models, x_train, params)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:[discriminator loss = 0.588144, acc: 0.632812]:[adversarial loss = 1.174504, acc: 0.000000]\n",
            "0.0 % completed\n",
            "1:[discriminator loss = 0.462510, acc: 0.851562]:[adversarial loss = 0.761054, acc: 0.000000]\n",
            "2.5e-05 % completed\n",
            "2:[discriminator loss = 0.323125, acc: 1.000000]:[adversarial loss = 1.425433, acc: 0.000000]\n",
            "5e-05 % completed\n",
            "3:[discriminator loss = 0.256075, acc: 0.960938]:[adversarial loss = 0.219605, acc: 1.000000]\n",
            "7.5e-05 % completed\n",
            "4:[discriminator loss = 0.224943, acc: 1.000000]:[adversarial loss = 1.550743, acc: 0.000000]\n",
            "0.0001 % completed\n",
            "5:[discriminator loss = 0.179983, acc: 0.968750]:[adversarial loss = 0.553902, acc: 1.000000]\n",
            "0.000125 % completed\n",
            "6:[discriminator loss = 0.077508, acc: 1.000000]:[adversarial loss = 0.397059, acc: 1.000000]\n",
            "0.00015 % completed\n",
            "7:[discriminator loss = 0.050873, acc: 1.000000]:[adversarial loss = 0.324146, acc: 1.000000]\n",
            "0.000175 % completed\n",
            "8:[discriminator loss = 0.039530, acc: 1.000000]:[adversarial loss = 0.255647, acc: 1.000000]\n",
            "0.0002 % completed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-068bfac9cb1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-4de8ca3e84cb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(models, x_train, params)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m#가짜 이미지는 분류를 위해 적대적 네트워크의 판별기 입력으로 전달됨\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s:[adversarial loss = %f, acc: %f]\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1tbjbD1F85W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}