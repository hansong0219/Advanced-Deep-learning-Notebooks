{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOiceecd8ts+ZHBFiXra6jL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansong0219/Advanced-DeepLearning-Study/blob/master/GAN/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrgrAucLW8_q"
      },
      "source": [
        "DCGAN\n",
        "----\n",
        "DCGAN 은 초기 심층 CNN 을 이용해 GAN 을 성공적으로 구현한 사례중 하나로, 다음과 같은 설계 원칙을 가지고 있다.\n",
        "\n",
        "- MaxPooling2D 나 UpSampling2D 대신 stride>1 인 합성곱을 사용한다. stride 가 >1 일 경우, CNN 은 특징 맵 크기를 조정하는 방법을 학습하게 된다.\n",
        "\n",
        "- Dense 계층의 사용을 피한다. 모든 계층에서 CNN 을 사용하도록 하며, Dense 계층은 생성기의 첫 번째 계층에서만 Z-vector 를 받기위해 사용된다. Dense 계층의 출력 크기는 조정되어 뒤따라 나오는 CNN 계층의 입력이 된다.\n",
        "\n",
        "- 각 계층의 입력이 평균 0 에 단위 분산을 가져서 학습을 안정화 시키도록 Batch Normaliztion 을 사용한다. 생성기 출력 계층과 판별기 입력 계층에는 Batch Normalization을 사용하지 않는다.\n",
        "\n",
        "- Rectitfied Linear Unit, ReLU 는 tanh 활성화 함수를 사용하는 출력 계층을 제외하고 생성기 전 층에서 사용된다. 아래에서는 tanh 대신 sigmoid 가 사용되는데, 일반적으로 MNIST 숫자에 대해 더 안정적으로 훈련시킬 수 있기 때문이다.\n",
        "\n",
        "- 판별기의 전 계층에서 Leaky ReLU 를 사용한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ke_xgxBW5Wl"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Activation, Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90c6Kh_WeJRT"
      },
      "source": [
        "모델 Build 를 위한 함수\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6PMI00PeQth"
      },
      "source": [
        "## 생성자 함수구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv_CbRR8eGI1"
      },
      "source": [
        "# 생성기 모델 구성\n",
        "\"\"\"\n",
        "가짜 이미지 생성을 위한 BN-ReLU-Conv2DTranspose 스택 \n",
        "출력계층의 활성화 함수로는 sigmoid 를 사용한다.\n",
        "\n",
        "함수의 인수\n",
        "inputs(Layer) : 생성기의 입력계층(z-vector 형태)\n",
        "image_size: 이미지의 한 축의 목표 scale  (정사각형으로 가정)\n",
        "\n",
        "return \n",
        "model: 생성기 모델\n",
        "\"\"\"\n",
        "\n",
        "def build_generator(inputs, image_size):\n",
        "  image_resize = image_size//4\n",
        "\n",
        "  kernel_size = 5\n",
        "  layer_filters = [128, 64, 32, 1]\n",
        "\n",
        "  x = Dense(image_resize*image_resize*layer_filters[0])(inputs)\n",
        "  x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n",
        "\n",
        "  for filters in layer_filters:\n",
        "    # 첫 두 합성곱 계층만 strides = 2 사용\n",
        "    if filters > layer_filters[-2]:\n",
        "      strides = 2\n",
        "    else:\n",
        "      strides = 1\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(filters=filters,\n",
        "                        kernel_size = kernel_size,\n",
        "                        strides = strides,\n",
        "                        padding = 'same')(x)\n",
        "  \n",
        "  x = Activation('sigmoid')(x)\n",
        "\n",
        "  generator = Model(inputs, x, name = 'generator')\n",
        "  \n",
        "  return generator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krQbbFgSeY8n"
      },
      "source": [
        "## 판별자 함수 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMPJMeqpeaTZ"
      },
      "source": [
        "# 판별기 모델 구성 \n",
        "\"\"\"\n",
        "진짜와 가짜를 구분하는 LeakyReLu - Conv2D 스택으로 구성이 되어있다.\n",
        "BN 으로는 네트워크가 수렴하지 않으므로 BN을 사용하지 않았다.\n",
        "\n",
        "inputs(Layer): 판별기의 입력 계층 (이미지)\n",
        "\n",
        "return\n",
        "Model: 판별기 모델 \n",
        "\"\"\"\n",
        "\n",
        "def build_discriminator(inputs):\n",
        "  kernel_size = 5\n",
        "  layer_filters = [32, 64, 128, 256]\n",
        "\n",
        "  x = inputs\n",
        "  for filters in layer_filters:\n",
        "    # 첫 3개의 합성곱 계층은 strides = 2 개 사용, 마지막 계층은 stride = 1 사용\n",
        "    if filters == layer_filters[-1]:\n",
        "      strides = 1\n",
        "    else:\n",
        "      strides = 2\n",
        "    \n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Conv2D(filters= filters,\n",
        "               kernel_size= kernel_size,\n",
        "               strides= strides,\n",
        "               padding= 'same')(x)\n",
        "    \n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1)(x)\n",
        "  x = Activation('sigmoid')(x)\n",
        "\n",
        "  discriminator = Model(inputs, x, name='discriminator')\n",
        "  \n",
        "  return discriminator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsBpRODHEFqZ"
      },
      "source": [
        "def plot_images(generator,\n",
        "                noise_input,\n",
        "                show=False,\n",
        "                step=0,\n",
        "                model_name=\"gan\"):\n",
        "    \"\"\"\n",
        "    생성한 이미지를 visualize 해주는 코드 \n",
        "    \"\"\"\n",
        "    os.makedirs(model_name, exist_ok=True)\n",
        "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
        "    images = generator.predict(noise_input)\n",
        "    plt.figure(figsize=(2.2, 2.2))\n",
        "    num_images = images.shape[0]\n",
        "    image_size = images.shape[1]\n",
        "    rows = int(math.sqrt(noise_input.shape[0]))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(rows, rows, i + 1)\n",
        "        image = np.reshape(images[i], [image_size, image_size])\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.savefig(filename)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close('all')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hqvK0oC6EOM"
      },
      "source": [
        "# 모델훈련"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOwczZnq5V1e"
      },
      "source": [
        "## 데이터셋 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_Qq5YpD5TNn"
      },
      "source": [
        "#MNIST 데이터 셋 로딩\n",
        "(x_train,_), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# CNN 을 위한 데이터형상 조정 및 정규화\n",
        "image_size = x_train.shape[1]\n",
        "x_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
        "x_train = x_train.astype('float32')/255"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62w2dSpW57vl"
      },
      "source": [
        "## 모델 훈련을 위한 네트워크 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJxdzGYR5TKY"
      },
      "source": [
        "model_name = \"dcgan_mnist\"\n",
        "\n",
        "# 네트워크 매개 변수 지정\n",
        "latent_size = 100\n",
        "batch_size = 64\n",
        "train_steps = 40000\n",
        "lr = 2e-4\n",
        "decay = 6e-8\n",
        "input_shape = (image_size, image_size, 1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiRGqf_U7Lw1",
        "outputId": "c9b95c09-9f58-44fd-c4d6-3135bf1108bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "# 판별기 모델 구성\n",
        "inputs = Input(shape = input_shape, name = 'discriminator_input')\n",
        "discriminator = build_discriminator(inputs)\n",
        "optimizer = RMSprop(lr=lr, decay=decay)\n",
        "\n",
        "discriminator.compile(loss = 'binary_crossentropy',\n",
        "                      optimizer = optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "discriminator.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "discriminator_input (InputLa [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 14, 14, 32)        832       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 64)          51264     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 4097      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,080,577\n",
            "Trainable params: 1,080,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsHXAcgx78TI",
        "outputId": "790db17c-68e2-4b66-b3d7-f40ac0e35e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        }
      },
      "source": [
        "# 생성기 모델 구성\n",
        "input_gen = (latent_size,)\n",
        "inputs = Input(shape = input_gen, name = 'g_input')\n",
        "generator = build_generator(inputs, image_size)\n",
        "\n",
        "generator.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "g_input (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6272)              633472    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       409728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        51232     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         801       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,301,505\n",
            "Trainable params: 1,300,801\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQAj0tB88bft",
        "outputId": "0268761f-2d31-4414-f3b4-bab818556232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# 적대적 모델 구성 결합\n",
        "optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
        "#적대적 모델을 훈련하는 동안 판별기의 가중치는 고정한다.\n",
        "discriminator.trainable = False\n",
        "\n",
        "#adversarial = generator + discriminator\n",
        "adversarial = Model(inputs, discriminator(generator(inputs)), name=model_name)\n",
        "\n",
        "adversarial.compile(loss = 'binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "adversarial.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"dcgan_mnist\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "g_input (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "generator (Functional)       (None, 28, 28, 1)         1301505   \n",
            "_________________________________________________________________\n",
            "discriminator (Functional)   (None, 1)                 1080577   \n",
            "=================================================================\n",
            "Total params: 2,382,082\n",
            "Trainable params: 1,300,801\n",
            "Non-trainable params: 1,081,281\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am8N4-sE9hv3"
      },
      "source": [
        "models = (generator, discriminator, adversarial)\n",
        "params = (batch_size, latent_size, train_steps, model_name)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdrOalrp93Nb"
      },
      "source": [
        "# 모델 훈련 함수 지정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11rsVUNO-Ie1"
      },
      "source": [
        "GAN 의경우 맞춤 훈련을 위해 일반적인 fit() 함수를 사용하지 않는다. 그 대신, 데이터 배치가 주어졌을 때에 대해 단일 경사 업데이트를 실행하기 위해 train_on_batch() 함수를 사용한다.\n",
        "아래의 train 함수는 위에서 구현한 모델을 훈련하기 위한 함수를 나타낸다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0WwLoSu9wZA"
      },
      "source": [
        "def train(models, x_train, params):\n",
        "  # 함수의 인수로는 앞선 셀에서 리스트로 지정된 models 와 params, 그리고 훈련 이미지인 x_train 이 있다.\n",
        "  \n",
        "  \"\"\"\n",
        "  판별기와 적대적 네트워크를 훈련한 후, 배치 단위로 판별기와 적대적 네트워크를 교대로 훈련한다. \n",
        "  우선 판별기는 제대로 레이블이 붙은 진짜와 가짜 이미지를 가지고 훈련 시킨 후, \n",
        "  다음으로 적대적 네트워크를 진짜인척 하는 가짜 이미지를 사용하여 훈련시킨다.\n",
        "  \"\"\"\n",
        "\n",
        "  # GAN 모델 불러오기\n",
        "  generator, discriminator, adversarial = models\n",
        "\n",
        "  # 네트워크 매개변수\n",
        "  batch_size, latent_size, train_steps, model_name\n",
        "\n",
        "  # 500 단계 마다 생성기 이미지가 저장되도록 설정\n",
        "  save_interval = 500\n",
        "\n",
        "  #훈련 기간 동안 생성기 출력 이미지가 어떻게 변화하는지 보여주기 위한 노이즈 벡터\n",
        "  noise_input = np.random.uniform(-1.0, 1.0, size = [16, latent_size])\n",
        "  \n",
        "  # 훈련 이미지의 개수\n",
        "  train_size = x_train.shape[0]\n",
        "\n",
        "  for i in range(train_steps):\n",
        "    # 1 배치에 대해 판별기 훈련\n",
        "    # 데이터 셋에서 임의로 진짜 이미지를 선택한다\n",
        "    rand_indices = np.random.randint(0, train_size, size = batch_size)\n",
        "    real_images = x_train[rand_indices]\n",
        "\n",
        "    #생성기를 사용해 노이즈로 부터 가짜 이미지를 생성한다.\n",
        "    \n",
        "    # 노이즈 분포 사용해 노이즈 생성\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "\n",
        "    # 가짜 이미지 생성\n",
        "    fake_images = generator.predict(noise)\n",
        "    \n",
        "    # 진짜 이미지와 가짜이미지의 훈련데이터의 배치 \n",
        "    x = np.concatenate((real_images, fake_images))\n",
        "    # 레이블을 붙임\n",
        "    y = np.ones([2*batch_size, 1])\n",
        "    y[batch_size:, :] = 0.0\n",
        "\n",
        "    #판별기 훈련 및 손실과 정확도 기록\n",
        "    loss, acc = discriminator.train_on_batch(x, y)\n",
        "    log = \"%d:[discriminator loss = %f, acc: %f]\" %(i, loss, acc)\n",
        "    print(log)\n",
        "\n",
        "    # 1 배치에 대한 적대적 네트워크 훈련 \n",
        "    # label = 1.0 인 가짜 이미지로 구성된 배치 \n",
        "\n",
        "    #판별기의 가중치가 고정되므로 생성기만 훈련된다.\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "    \n",
        "    # 가짜 이미지에 진짜 혹은 1.0 으로 레이블\n",
        "    y = np.ones([batch_size, 1])\n",
        "\n",
        "    #판별기를 훈련시키는 것과 달리 변수에 가짜 이미지를 저장하지 않는다.\n",
        "    #가짜 이미지는 분류를 위해 적대적 네트워크의 판별기 입력으로 전달됨\n",
        "\n",
        "    loss, acc = adversarial.train_on_batch(noise, y)\n",
        "    log = \"%d:[adversarial loss = %f, acc: %f]\" %(i, loss, acc)\n",
        "    print(log)\n",
        "\n",
        "    print(f'{i/train_steps} % completed')\n",
        "\n",
        "    if (i+1) % save_interval == 0:\n",
        "      if (i+1) == train_steps:\n",
        "        show = True\n",
        "      else:\n",
        "        show = False\n",
        "\n",
        "      plot_images(generator, noise_input=noise_input, show=show, step=(i+1), model_name=model_name)\n",
        "    \n",
        "  genrator.save(model_name+\".h5\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbaYffVhE139",
        "outputId": "520d055d-606c-4478-f30b-de5941a4807d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(models, x_train, params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:[discriminator loss = 0.689830, acc: 0.648438]\n",
            "0:[adversarial loss = 0.814838, acc: 0.000000]\n",
            "1:[discriminator loss = 0.611736, acc: 0.968750]\n",
            "1:[adversarial loss = 0.935328, acc: 0.000000]\n",
            "2:[discriminator loss = 0.488140, acc: 0.984375]\n",
            "2:[adversarial loss = 0.934961, acc: 0.000000]\n",
            "3:[discriminator loss = 0.337631, acc: 0.992188]\n",
            "3:[adversarial loss = 0.438438, acc: 1.000000]\n",
            "4:[discriminator loss = 0.216405, acc: 1.000000]\n",
            "4:[adversarial loss = 1.804330, acc: 0.000000]\n",
            "5:[discriminator loss = 0.266789, acc: 0.914062]\n",
            "5:[adversarial loss = 0.100641, acc: 1.000000]\n",
            "6:[discriminator loss = 0.161319, acc: 1.000000]\n",
            "6:[adversarial loss = 1.064527, acc: 0.000000]\n",
            "7:[discriminator loss = 0.120627, acc: 0.992188]\n",
            "7:[adversarial loss = 0.316615, acc: 1.000000]\n",
            "8:[discriminator loss = 0.063232, acc: 1.000000]\n",
            "8:[adversarial loss = 0.140429, acc: 1.000000]\n",
            "9:[discriminator loss = 0.037793, acc: 1.000000]\n",
            "9:[adversarial loss = 0.109585, acc: 1.000000]\n",
            "10:[discriminator loss = 0.034481, acc: 1.000000]\n",
            "10:[adversarial loss = 0.071038, acc: 1.000000]\n",
            "11:[discriminator loss = 0.027892, acc: 1.000000]\n",
            "11:[adversarial loss = 0.053800, acc: 1.000000]\n",
            "12:[discriminator loss = 0.022424, acc: 1.000000]\n",
            "12:[adversarial loss = 0.039030, acc: 1.000000]\n",
            "13:[discriminator loss = 0.015698, acc: 1.000000]\n",
            "13:[adversarial loss = 0.033859, acc: 1.000000]\n",
            "14:[discriminator loss = 0.015185, acc: 1.000000]\n",
            "14:[adversarial loss = 0.023030, acc: 1.000000]\n",
            "15:[discriminator loss = 0.011301, acc: 1.000000]\n",
            "15:[adversarial loss = 0.023517, acc: 1.000000]\n",
            "16:[discriminator loss = 0.008888, acc: 1.000000]\n",
            "16:[adversarial loss = 0.019583, acc: 1.000000]\n",
            "17:[discriminator loss = 0.008805, acc: 1.000000]\n",
            "17:[adversarial loss = 0.014919, acc: 1.000000]\n",
            "18:[discriminator loss = 0.006635, acc: 1.000000]\n",
            "18:[adversarial loss = 0.014470, acc: 1.000000]\n",
            "19:[discriminator loss = 0.006550, acc: 1.000000]\n",
            "19:[adversarial loss = 0.012263, acc: 1.000000]\n",
            "20:[discriminator loss = 0.006647, acc: 1.000000]\n",
            "20:[adversarial loss = 0.008314, acc: 1.000000]\n",
            "21:[discriminator loss = 0.006135, acc: 1.000000]\n",
            "21:[adversarial loss = 0.007733, acc: 1.000000]\n",
            "22:[discriminator loss = 0.004516, acc: 1.000000]\n",
            "22:[adversarial loss = 0.007077, acc: 1.000000]\n",
            "23:[discriminator loss = 0.003833, acc: 1.000000]\n",
            "23:[adversarial loss = 0.006136, acc: 1.000000]\n",
            "24:[discriminator loss = 0.003264, acc: 1.000000]\n",
            "24:[adversarial loss = 0.006188, acc: 1.000000]\n",
            "25:[discriminator loss = 0.003076, acc: 1.000000]\n",
            "25:[adversarial loss = 0.005609, acc: 1.000000]\n",
            "26:[discriminator loss = 0.004331, acc: 1.000000]\n",
            "26:[adversarial loss = 0.002922, acc: 1.000000]\n",
            "27:[discriminator loss = 0.003291, acc: 1.000000]\n",
            "27:[adversarial loss = 0.003181, acc: 1.000000]\n",
            "28:[discriminator loss = 0.002506, acc: 1.000000]\n",
            "28:[adversarial loss = 0.003202, acc: 1.000000]\n",
            "29:[discriminator loss = 0.002333, acc: 1.000000]\n",
            "29:[adversarial loss = 0.002965, acc: 1.000000]\n",
            "30:[discriminator loss = 0.002447, acc: 1.000000]\n",
            "30:[adversarial loss = 0.002126, acc: 1.000000]\n",
            "31:[discriminator loss = 0.002052, acc: 1.000000]\n",
            "31:[adversarial loss = 0.002197, acc: 1.000000]\n",
            "32:[discriminator loss = 0.001555, acc: 1.000000]\n",
            "32:[adversarial loss = 0.002381, acc: 1.000000]\n",
            "33:[discriminator loss = 0.001748, acc: 1.000000]\n",
            "33:[adversarial loss = 0.001782, acc: 1.000000]\n",
            "34:[discriminator loss = 0.001206, acc: 1.000000]\n",
            "34:[adversarial loss = 0.002138, acc: 1.000000]\n",
            "35:[discriminator loss = 0.001119, acc: 1.000000]\n",
            "35:[adversarial loss = 0.002186, acc: 1.000000]\n",
            "36:[discriminator loss = 0.001266, acc: 1.000000]\n",
            "36:[adversarial loss = 0.001696, acc: 1.000000]\n",
            "37:[discriminator loss = 0.001362, acc: 1.000000]\n",
            "37:[adversarial loss = 0.001230, acc: 1.000000]\n",
            "38:[discriminator loss = 0.002050, acc: 1.000000]\n",
            "38:[adversarial loss = 0.000459, acc: 1.000000]\n",
            "39:[discriminator loss = 0.001188, acc: 1.000000]\n",
            "39:[adversarial loss = 0.001043, acc: 1.000000]\n",
            "40:[discriminator loss = 0.000649, acc: 1.000000]\n",
            "40:[adversarial loss = 0.001248, acc: 1.000000]\n",
            "41:[discriminator loss = 0.000798, acc: 1.000000]\n",
            "41:[adversarial loss = 0.001163, acc: 1.000000]\n",
            "42:[discriminator loss = 0.001165, acc: 1.000000]\n",
            "42:[adversarial loss = 0.000658, acc: 1.000000]\n",
            "43:[discriminator loss = 0.000880, acc: 1.000000]\n",
            "43:[adversarial loss = 0.000699, acc: 1.000000]\n",
            "44:[discriminator loss = 0.000765, acc: 1.000000]\n",
            "44:[adversarial loss = 0.000625, acc: 1.000000]\n",
            "45:[discriminator loss = 0.000614, acc: 1.000000]\n",
            "45:[adversarial loss = 0.000644, acc: 1.000000]\n",
            "46:[discriminator loss = 0.000733, acc: 1.000000]\n",
            "46:[adversarial loss = 0.000449, acc: 1.000000]\n",
            "47:[discriminator loss = 0.000485, acc: 1.000000]\n",
            "47:[adversarial loss = 0.000667, acc: 1.000000]\n",
            "48:[discriminator loss = 0.000553, acc: 1.000000]\n",
            "48:[adversarial loss = 0.000575, acc: 1.000000]\n",
            "49:[discriminator loss = 0.000493, acc: 1.000000]\n",
            "49:[adversarial loss = 0.000552, acc: 1.000000]\n",
            "50:[discriminator loss = 0.000460, acc: 1.000000]\n",
            "50:[adversarial loss = 0.000477, acc: 1.000000]\n",
            "51:[discriminator loss = 0.000394, acc: 1.000000]\n",
            "51:[adversarial loss = 0.000502, acc: 1.000000]\n",
            "52:[discriminator loss = 0.000485, acc: 1.000000]\n",
            "52:[adversarial loss = 0.000363, acc: 1.000000]\n",
            "53:[discriminator loss = 0.000616, acc: 1.000000]\n",
            "53:[adversarial loss = 0.000191, acc: 1.000000]\n",
            "54:[discriminator loss = 0.000397, acc: 1.000000]\n",
            "54:[adversarial loss = 0.000417, acc: 1.000000]\n",
            "55:[discriminator loss = 0.000376, acc: 1.000000]\n",
            "55:[adversarial loss = 0.000321, acc: 1.000000]\n",
            "56:[discriminator loss = 0.000326, acc: 1.000000]\n",
            "56:[adversarial loss = 0.000355, acc: 1.000000]\n",
            "57:[discriminator loss = 0.000238, acc: 1.000000]\n",
            "57:[adversarial loss = 0.000452, acc: 1.000000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1tbjbD1F85W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}