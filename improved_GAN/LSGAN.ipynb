{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansong0219/Advanced-DeepLearning-Study/blob/master/improved_GAN/LSGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgURjbwjdbHK"
      },
      "source": [
        "# LSGAN\n",
        "\n",
        "GAN 이 훈련시키가 어려운 이유는 대체적으로 손실함수를 최적화 시킬때 발생한다. Jensen-Shannon 발산을 최적화 하는 것이 GAN 의 당면 과제이며, 두 분포함수가 중첩되는 부분이 거의 없을 경우에는 이를 최적화하기에는 어렵다. \n",
        "\n",
        "WGAN 의 경우, 두 분포사이에 중첩되는 영역이 거의 없을 때도 매끄러운 미분 가능함수를 갖도록 EMD 나 Wasserstein 손실을 사용함으로써 이문제를 해결한다.\n",
        "하지만 WGAN 은 생성 이미지의 품질에는 신경쓰지 않는 경향이 있고 이와 같은 부분에서 개선되어야 하는 점이 있다. \n",
        "\n",
        "LSGAN은 최소제곱 손실로서 위의 문제를 해결하는 방법이다. \n",
        "GAN 에서 Sigmoid Activation 과 Cross Entropy 손실함수를 사용했을때 생성된 데이터 품질이 나쁜 이유는 , 이상적으로, 가짜 샘플의 분포는 진짜 샘플의 분포와 가능한 가까워야 한다. 하지만, GAN 에서 가짜 샘플이 이미 결정경계에서 진짜로 분류가 되기 시작했을 경우, 경사가 소실된다.\n",
        "\n",
        "이는 생성기가 생성된 가짜 데이터의 품질을 개선하려고 더 노력할 필요가 없게 만들며, 결정 경계로 부터 멀리 떨어져 있는 가짜 샘플은 더 이상 진짜 샘플 분포에 가까워 지려고 시도하지 않는다.\n",
        "\n",
        "이 때, 최소제곱 손실을 사용한다면, 생성기는 가짜 샘플이 이미 결정 경계의 진짜 영역에 속해 있더라도, 실제 밀도 분포의 추정을 개선하려고 학습한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_IUcsXLhbwj"
      },
      "source": [
        "## GPU 할당 \n",
        "\n",
        "Colab 이 아닌 환경 (GPU 의 메모리가 부족할 경우)에서는 아래의 코드를 통해 우선적으로 gpu를 할당해준다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6X6ari3hbVf"
      },
      "source": [
        "import tensorflow as tf \n",
        "physical_devices =tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEDKe3EwZMbx"
      },
      "source": [
        "from tensorflow.keras.layers import Activation, Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyAITo6EiCEC"
      },
      "source": [
        "# 생성기와 판별기 등 함수 구성 \n",
        "생성기와 판별기의 함수는 DCGAN의 구성을 그대로 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXUDGEiHiC-C"
      },
      "source": [
        "def build_generator(inputs,\n",
        "              image_size,\n",
        "              activation='sigmoid'):\n",
        "\n",
        "    image_resize = image_size // 4\n",
        "    kernel_size = 5\n",
        "    layer_filters = [128, 64, 32, 1]\n",
        "    \n",
        "    x = inputs\n",
        "    x = Dense(image_resize * image_resize * layer_filters[0])(x)\n",
        "    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n",
        "\n",
        "    for filters in layer_filters:\n",
        "        if filters > layer_filters[-2]:\n",
        "            strides = 2\n",
        "        else:\n",
        "            strides = 1\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=filters,\n",
        "                            kernel_size=kernel_size,\n",
        "                            strides=strides,\n",
        "                            padding='same')(x)\n",
        "\n",
        "    if activation is not None:\n",
        "        x = Activation(activation)(x)\n",
        "\n",
        "    return Model(inputs, x, name='generator')\n",
        "\n",
        "\n",
        "def build_discriminator(inputs,\n",
        "                  activation='sigmoid'):\n",
        "\n",
        "    kernel_size = 5\n",
        "    layer_filters = [32, 64, 128, 256]\n",
        "\n",
        "    x = inputs\n",
        "    for filters in layer_filters:\n",
        "        # first 3 convolution layers use strides = 2\n",
        "        # last one uses strides = 1\n",
        "        if filters == layer_filters[-1]:\n",
        "            strides = 1\n",
        "        else:\n",
        "            strides = 2\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        x = Conv2D(filters=filters,\n",
        "                   kernel_size=kernel_size,\n",
        "                   strides=strides,\n",
        "                   padding='same')(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    # default output is probability that the image is real\n",
        "    outputs = Dense(1)(x)\n",
        "    if activation is not None:\n",
        "        print(activation)\n",
        "        outputs = Activation(activation)(outputs)\n",
        "\n",
        "    return Model(inputs, outputs, name='discriminator')\n",
        "\n",
        "\n",
        "def plot_images(generator,\n",
        "                noise_input,\n",
        "                noise_label=None,\n",
        "                noise_codes=None,\n",
        "                show=False,\n",
        "                step=0,\n",
        "                model_name=\"gan\"):\n",
        "  \n",
        "    os.makedirs(model_name, exist_ok=True)\n",
        "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
        "    rows = int(math.sqrt(noise_input.shape[0]))\n",
        "    if noise_label is not None:\n",
        "        noise_input = [noise_input, noise_label]\n",
        "        if noise_codes is not None:\n",
        "            noise_input += noise_codes\n",
        "\n",
        "    images = generator.predict(noise_input)\n",
        "    plt.figure(figsize=(2.2, 2.2))\n",
        "    num_images = images.shape[0]\n",
        "    image_size = images.shape[1]\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(rows, rows, i + 1)\n",
        "        image = np.reshape(images[i], [image_size, image_size])\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.savefig(filename)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close('all')\n",
        "\n",
        "\n",
        "def test_generator(generator):\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
        "    plot_images(generator,\n",
        "                noise_input=noise_input,\n",
        "                show=True,\n",
        "                model_name=\"test_outputs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y87zX4F7koYU"
      },
      "source": [
        "# LSGAN 구현 \n",
        "\n",
        "DCGAN 과 거의 동일한 구조이며, 아래와 같이 손실함수를 모두 mse 로 대체하고, Activation 층을 제거 해주면 된다. LSGAN 네트워크 모델은 선형출력 혹은 화성화 함수가 없다는 점에서 다른 성능을 나타낸다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b38xV9Mhksoy"
      },
      "source": [
        "#MNIST 데이터 세트 로딩\n",
        "(x_train,_),(_,_) = mnist.load_data()\n",
        "\n",
        "# 데이터 형상 변환 및 정규화\n",
        "image_size = x_train.shape[1]\n",
        "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
        "x_train = x_train.astype('float32')/255\n",
        "  \n",
        "model_name = \"lsgan_mnist\"\n",
        "\n",
        "#네트워크 매개 변수 지정 \n",
        "latent_size = 100\n",
        "batch_size = 64\n",
        "lr = 2e-4\n",
        "decay = 6e-8\n",
        "train_steps = 40000\n",
        "input_shape = (image_size, image_size, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc70e6giMnX1",
        "outputId": "dda10bb0-66e7-4476-f918-537ea3c85115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "source": [
        "#판별기 모델 구성\n",
        "inputs = Input(shape=input_shape, name = 'discriminator_input')\n",
        "\n",
        "#WGAN 은 선형 activation 을 사용한다. \n",
        "discriminator = build_discriminator(inputs, activation=None)\n",
        "optimizer = RMSprop(lr=lr, decay=decay)\n",
        "\n",
        "#WGAN 판별기는 Wasserstein loss 를 사용한다.\n",
        "discriminator.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear\n",
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "discriminator_input (InputLa [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 14, 14, 32)        832       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 64)          51264     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 4097      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,080,577\n",
            "Trainable params: 1,080,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msp_hSBRNdVG",
        "outputId": "1cdb28fe-35c9-4fc4-ed0c-1938754f9801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        }
      },
      "source": [
        "#생성기 모델 구성\n",
        "input_shape = (latent_size,)\n",
        "inputs = Input(shape=input_shape, name = 'z_input')\n",
        "generator = build_generator(inputs, image_size)\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_input (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6272)              633472    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       409728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        51232     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         801       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,301,505\n",
            "Trainable params: 1,300,801\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adGFv60ENv_u",
        "outputId": "91b5900f-25be-4c15-a821-d449f1107cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "#적대적 모델 구성\n",
        "optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
        "\n",
        "#적대적 네트워크를 훈련하는 동안 판별기의 가중치는 고정\n",
        "discriminator.trainable = False\n",
        "adversarial = Model(inputs, discriminator(generator(inputs)),name = model_name)\n",
        "\n",
        "adversarial.compile(loss='mse', optimizer=optimizer,metrics=['accuracy'])\n",
        "adversarial.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"wgan_mnist\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_input (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "generator (Functional)       (None, 28, 28, 1)         1301505   \n",
            "_________________________________________________________________\n",
            "discriminator (Functional)   (None, 1)                 1080577   \n",
            "=================================================================\n",
            "Total params: 2,382,082\n",
            "Trainable params: 1,300,801\n",
            "Non-trainable params: 1,081,281\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bUizp30Okl7"
      },
      "source": [
        "models = (generator, discriminator, adversarial)\n",
        "params = (batch_size, latent_size, train_steps, model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4xTOTWpO6qB"
      },
      "source": [
        "# WGAN 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nr5xVOHO6Ok"
      },
      "source": [
        "def train(models, x_train, params):\n",
        "  # 함수의 인수로는 앞선 셀에서 리스트로 지정된 models 와 params, 그리고 훈련 이미지인 x_train 이 있다.\n",
        "  \n",
        "  \"\"\"\n",
        "  판별기와 적대적 네트워크를 훈련한 후, 배치 단위로 판별기와 적대적 네트워크를 교대로 훈련한다. \n",
        "  우선 판별기는 제대로 레이블이 붙은 진짜와 가짜 이미지를 가지고 훈련 시킨 후, \n",
        "  다음으로 적대적 네트워크를 진짜인척 하는 가짜 이미지를 사용하여 훈련시킨다.\n",
        "  \"\"\"\n",
        "\n",
        "  # GAN 모델 불러오기\n",
        "  generator, discriminator, adversarial = models\n",
        "\n",
        "  # 네트워크 매개변수\n",
        "  batch_size, latent_size, train_steps, model_name = params\n",
        "\n",
        "  # 500 단계 마다 생성기 이미지가 저장되도록 설정\n",
        "  save_interval = 500\n",
        "\n",
        "  #훈련 기간 동안 생성기 출력 이미지가 어떻게 변화하는지 보여주기 위한 노이즈 벡터\n",
        "  noise_input = np.random.uniform(-1.0, 1.0, size = [16, latent_size])\n",
        "  \n",
        "  # 훈련 이미지의 개수\n",
        "  train_size = x_train.shape[0]\n",
        "\n",
        "  for i in range(train_steps):\n",
        "    # 1 배치에 대해 판별기 훈련\n",
        "    # 데이터 셋에서 임의로 진짜 이미지를 선택한다\n",
        "    rand_indices = np.random.randint(0, train_size, size = batch_size)\n",
        "    real_images = x_train[rand_indices]\n",
        "\n",
        "    #생성기를 사용해 노이즈로 부터 가짜 이미지를 생성한다.\n",
        "    \n",
        "    # 노이즈 분포 사용해 노이즈 생성\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "\n",
        "    # 가짜 이미지 생성\n",
        "    fake_images = generator.predict(noise)\n",
        "    \n",
        "    # 진짜 이미지와 가짜이미지의 훈련데이터의 배치 \n",
        "    x = np.concatenate((real_images, fake_images))\n",
        "    # 레이블을 붙임\n",
        "    y = np.ones([2*batch_size, 1])\n",
        "    y[batch_size:, :] = 0.0\n",
        "\n",
        "    #판별기 훈련 및 손실과 정확도 기록\n",
        "    loss, acc = discriminator.train_on_batch(x, y)\n",
        "    log = \"%d:[discriminator loss = %f, acc: %f]\" %(i, loss, acc)\n",
        "\n",
        "    # 1 배치에 대한 적대적 네트워크 훈련 \n",
        "    # label = 1.0 인 가짜 이미지로 구성된 배치 \n",
        "\n",
        "    #판별기의 가중치가 고정되므로 생성기만 훈련된다.\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "    \n",
        "    # 가짜 이미지에 진짜 혹은 1.0 으로 레이블\n",
        "    y = np.ones([batch_size, 1])\n",
        "\n",
        "    #판별기를 훈련시키는 것과 달리 변수에 가짜 이미지를 저장하지 않는다.\n",
        "    #가짜 이미지는 분류를 위해 적대적 네트워크의 판별기 입력으로 전달됨\n",
        "\n",
        "    loss, acc = adversarial.train_on_batch(noise, y)\n",
        "    log = \"%s:[adversarial loss = %f, acc: %f]\" %(log, loss, acc)\n",
        "    print(log)\n",
        "\n",
        "    if (i+1) % save_interval == 0:\n",
        "      if (i+1) == train_steps:\n",
        "        show = True\n",
        "      else:\n",
        "        show = False\n",
        "\n",
        "      plot_images(generator, noise_input=noise_input, show=show, step=(i+1), model_name=model_name)\n",
        "    \n",
        "  genrator.save(model_name+\".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfWlBq4sO5F_",
        "outputId": "36bdb80d-93b6-4416-d949-ecdae7403a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "train(models, x_train, params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: [discriminator loss: -5.973136, acc: 0.495312] [adversarial loss : -0.412923, acc: 0.328125]\n",
            "1: [discriminator loss: -8.316473, acc: 0.492188] [adversarial loss : -1.163935, acc: 1.000000]\n",
            "2: [discriminator loss: -11.028550, acc: 0.484375] [adversarial loss : -2.501282, acc: 1.000000]\n",
            "3: [discriminator loss: -14.628844, acc: 0.495312] [adversarial loss : -4.024241, acc: 1.000000]\n",
            "4: [discriminator loss: -19.044446, acc: 0.487500] [adversarial loss : -5.836015, acc: 1.000000]\n",
            "5: [discriminator loss: -23.716064, acc: 0.471875] [adversarial loss : -7.880697, acc: 1.000000]\n",
            "6: [discriminator loss: -29.877561, acc: 0.478125] [adversarial loss : -10.473497, acc: 1.000000]\n",
            "7: [discriminator loss: -37.336320, acc: 0.481250] [adversarial loss : -13.144060, acc: 1.000000]\n",
            "8: [discriminator loss: -45.206649, acc: 0.476562] [adversarial loss : -16.686695, acc: 1.000000]\n",
            "9: [discriminator loss: -54.784740, acc: 0.462500] [adversarial loss : -20.414776, acc: 1.000000]\n",
            "10: [discriminator loss: -66.503952, acc: 0.473438] [adversarial loss : -24.994194, acc: 1.000000]\n",
            "11: [discriminator loss: -79.277333, acc: 0.464062] [adversarial loss : -29.490265, acc: 1.000000]\n",
            "12: [discriminator loss: -94.101098, acc: 0.468750] [adversarial loss : -35.247082, acc: 1.000000]\n",
            "13: [discriminator loss: -108.896768, acc: 0.454688] [adversarial loss : -41.243004, acc: 1.000000]\n",
            "14: [discriminator loss: -128.491620, acc: 0.465625] [adversarial loss : -48.353386, acc: 1.000000]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-068bfac9cb1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-05e1c7586c2b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(models, x_train, params)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m#적대적 네트워크 훈련\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s [adversarial loss : %f, acc: %f]\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DGB_QAwbTFz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}