{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ACGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP/0+wuUMju0W3ZuKPzLIk2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansong0219/Advanced-DeepLearning-Study/blob/master/improved_GAN/ACGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY7C5OFdK_gr"
      },
      "source": [
        "# ACGAN \n",
        "\n",
        "**ACGAN(보조 분류 GAN)** 은 원리상 Conditional GAN 과 유사한 형태를 가진다. CGAN 의 경우, 판별기는 입력으로 이미지와 그 레이블을 받고 그 이미지가 진짜일 확률을 출력한다. 그러나 ACGAN 에서의 입력은 이미지이고 출력은 이미지가 진짜인지의 확률과 어떤 클래스인지를 동시에 출력하게 된다. \n",
        "\n",
        "기본적으로 CGAN 에서는 부가정보를 네트워크에 제공하지만, ACGAN에서는 이를 제공하지 않고 보조 클래스 디코더 네트워크(Axuiliary class decoder)를 이용하여 부가 정보를 재구성한다.\n",
        "\n",
        "ACGAN 에는 추가적으로 분류기의 손실함수가 주어지는데 진짜와 가짜 이미지를 추가적으로 분류하는 작업을 수행한다. \n",
        "또, 생성기의 손실함수에서도 판별기를 속이는 일 외에도 가짜이미지를 정확하게 분류했는지도 손실을 계산하게된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL80CZ420JhV"
      },
      "source": [
        "#GPU 할당\n",
        "\n",
        "Colab 이 아닌 환경에서 아래의 코드를 통해 우선적으로 gpu를 할당해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjtjnYiedN8u"
      },
      "source": [
        "import tensorflow as tf \n",
        "physical_devices =tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsQp1mmL0JAs"
      },
      "source": [
        "from tensorflow.keras.layers import Activation, Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ni42k6A0Q8c"
      },
      "source": [
        "# 생성기 및 판별기 함수구성\n",
        "CGAN 의 코드를 기반으로 하여 구성한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0fH9oPN0bJ9"
      },
      "source": [
        "def build_discriminator(inputs, activation='sigmoid', num_labels=None, num_codes=None):\n",
        "  \"\"\"\n",
        "  판별기 모델구성 \n",
        "  가짜와 진짜를 판별하기 위한 LeakyReLU - Conv2D 로 구성된 스택이다.\n",
        "  이 네트워크는 BN 으로 수렴되지 않으므로, 사용하지 않는다.\n",
        "  \"\"\"\n",
        "\n",
        "  # 입력 인수\n",
        "  \"\"\"\n",
        "  inputs(layer) : 판별기의 입력 계층(이미지)\n",
        "  activation (string) : 출력 활성화 계층의 이름\n",
        "  num_labels (int): ACGAN 과 InfoGAN 에서의 원-핫 레이블의 차원\n",
        "  num_codes(int) : Q network as output\n",
        "  \"\"\"\n",
        "\n",
        "  #출력 인수 : Model: 판별기 모델\n",
        "\n",
        "  kernel_size = 5\n",
        "  layer_filters = [32, 64, 128, 256]\n",
        "\n",
        "  x = inputs\n",
        "  for filters in layer_filters:\n",
        "    # 첫 세 개의 합성곱 계층에서는 strides = 2 를 사용\n",
        "    # 마지막 한 계층은 strides = 1을 사용\n",
        "    \n",
        "    if filters == layer_filters[-1]:\n",
        "      strides = 1\n",
        "    else:\n",
        "      strides = 2\n",
        "\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Conv2D(filters = filters, kernel_size = kernel_size, strides=strides, padding='same')(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  outputs = Dense(1)(x)\n",
        "  if activation is not None:\n",
        "    outputs = Activation(activation)(outputs)\n",
        "\n",
        "  if num_labels:\n",
        "    # ACGAN 과 InfoGAN 에는 두번째 출력이 있음\n",
        "    # MNIST 에서 두 번째 출력은 10차원 원-핫 레이블 벡터로 구성됨\n",
        "\n",
        "    layer = Dense(layer_filters[-2])(x)\n",
        "    labels = Dense(num_labels)(layer)\n",
        "    labels - Activation('softmax',name='label')(labels)\n",
        "    if num_codes is None:\n",
        "      outputs = [outputs, labels]\n",
        "\n",
        "    else:\n",
        "      #InfoGAN 에는 세 번쨰와 네 번째 출력이 있음\n",
        "      #세 번째 출력: x 가 주어졌을 때 첫번째 c 를 나타내는 1차원 연속 Q\n",
        "\n",
        "      code1 = Dense(1)(layer)\n",
        "      code1 = Activation('sigmoid', name='code1')(code1)\n",
        "\n",
        "      #네 번째 출력: x가 주어졌을 때 두 번째 c를 나타내는 1차원 연속 Q\n",
        "      code2 = Dense(1)(layer)\n",
        "      code2 = Activation('sigmoid',name='code2')(code2)\n",
        "\n",
        "      outputs = [outputs, labels, code1, code2]\n",
        "\n",
        "  elif num_codes is not None:\n",
        "    #z0_recon: z0 정규 분포를 재구성\n",
        "    z0_recon = Dense(num_codes)(x)\n",
        "    z0_recon = Activation('tanh', name='z0')(z0_recon)\n",
        "\n",
        "    outputs = [outputs, z0_recon]\n",
        "\n",
        "  return Model(inputs, outputs, name='discriminator')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOc-oA4124Cp"
      },
      "source": [
        "def build_generator(inputs, image_size, activation='sigmoid', labels=None, codes=None):\n",
        "  \"\"\"\n",
        "  생성기 모델 구성\n",
        "  가짜 이미지를 생성하는 BN-ReLU-Conv2DTranspose 스택으로 이루어진다.\n",
        "  출력 활성화로 sigmoid 를 사용한다.\n",
        "  \"\"\"\n",
        "  \n",
        "  #입력 인수\n",
        "  \"\"\"\n",
        "  inputs (Layer): 생성기의 입력계층 (z-vector)\n",
        "  image_size (int) : 한 변의 목표크기 (정사각형 이미지를 가정)\n",
        "  activation(string) : 출력 활성화 계층 이름\n",
        "  labels (tensor) : 입력 레이블\n",
        "  codes (list) : InfoGAN 에서 사용하는 2차원 풀링 코드\n",
        "  \"\"\"\n",
        "\n",
        "  # 출력 인수: Model : 생성기 모델\n",
        "\n",
        "  image_resize = image_size//4\n",
        "  \n",
        "  # 네트워크 매개 변수\n",
        "  kernel_size = 5\n",
        "  layer_filters = [128, 64, 32, 1]\n",
        "  \n",
        "  if labels is not None:\n",
        "    if codes is None:\n",
        "      #ACGAN 레이블\n",
        "      # z 노이즈 벡터와 원-핫 레이블을 연결\n",
        "      inputs = [inputs, labels]\n",
        "\n",
        "    else:\n",
        "      #InfoGAN 코드\n",
        "      #z 노이즈 벡터와 원-핫 레이블과 코드 1, 2 를 연결\n",
        "      inputs = [inputs, labels] + codes\n",
        "    \n",
        "    x = concatenate(inputs,axis=1)\n",
        "      \n",
        "  elif codes is not None:\n",
        "    #StackedGAN 의 생성기\n",
        "    inputs = [inputs, codes]\n",
        "    x = concatenate(inputs,axis=1)\n",
        "  \n",
        "  else:\n",
        "    x = inputs\n",
        "\n",
        "  x = Dense(image_resize*image_resize*layer_filters[0])(x)\n",
        "  x = Reshape((image_resize,image_resize,layer_filters[0]))(x)\n",
        "\n",
        "  for filters in layer_filters:\n",
        "    # 처음 두 합성곱 계층은 strides = 2 를 사용하여 이미지 사이즈를 변경함\n",
        "    # 마지막 두계층은 strides = 1을 사용\n",
        "    if filters > layer_filters[-2]:\n",
        "      strides = 2\n",
        "    else:\n",
        "      strides = 1\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(filters = filters, kernel_size = kernel_size, strides = strides, padding='same')(x)\n",
        "\n",
        "  if activation is not None:\n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "  return Model(inputs, x, name='generator')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbZ0v3MSZ1Tu"
      },
      "source": [
        "# 유틸 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgpryetpZxPG"
      },
      "source": [
        "def plot_images(generator,\n",
        "                noise_input,\n",
        "                noise_class,\n",
        "                show=False,\n",
        "                step=0,\n",
        "                model_name=\"gan\"):\n",
        "\n",
        "    os.makedirs(model_name, exist_ok=True)\n",
        "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
        "    images = generator.predict([noise_input, noise_class])\n",
        "    print(model_name , \" labels for generated images: \", np.argmax(noise_class, axis=1))\n",
        "    plt.figure(figsize=(2.2, 2.2))\n",
        "    num_images = images.shape[0]\n",
        "    image_size = images.shape[1]\n",
        "    rows = int(math.sqrt(noise_input.shape[0]))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(rows, rows, i + 1)\n",
        "        image = np.reshape(images[i], [image_size, image_size])\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.savefig(filename)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close('all')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3NYZMwLY7p9"
      },
      "source": [
        "# 데이터 세트 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry3RR6ypY6RP"
      },
      "source": [
        "# MNIST 불러오기 \n",
        "(x_train, y_train), (_, _) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lojEvsICYwVh"
      },
      "source": [
        "# CNN 을 위한 데이터형상 조정 및 정규화\n",
        "image_size = x_train.shape[1]\n",
        "x_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
        "x_train = x_train.astype('float32')/255\n",
        "\n",
        "# 라벨 지정\n",
        "num_labels = np.amax(y_train) + 1\n",
        "y_train = to_categorical(y_train)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZQu9RIYZ65U"
      },
      "source": [
        "# ACGAN 모델 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lzuc6ZQZjGg"
      },
      "source": [
        "model_name = \"acgan_mnist\"\n",
        "\n",
        "# 네트워크 매개 변수 지정\n",
        "latent_size = 100\n",
        "batch_size = 64\n",
        "train_steps = 40000\n",
        "lr = 2e-4\n",
        "decay = 6e-8\n",
        "input_shape = (image_size, image_size, 1)\n",
        "label_shape = (num_labels, )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VHw1YA7aDKY",
        "outputId": "f1a14839-a387-4f4d-bd10-84dc2097ff18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        }
      },
      "source": [
        "# 판별기 모델 구성\n",
        "inputs = Input(shape = input_shape, name = 'discriminator_input')\n",
        "\n",
        "# 예측 소스와 레이블, 두개의 출력으로 판별기 빌더 함수 호출\n",
        "discriminator = build_discriminator(inputs, num_labels=num_labels)\n",
        "\n",
        "# RMSProp 을 사용할 때 판별기가 쉽게 수렴한다.\n",
        "optimizer = RMSprop(lr=lr, decay=decay)\n",
        "\n",
        "# 손실함수는 두개를 사용한다 - 1) 이미지가 진짜일 확률, 2) 이미지의 클래스 레이블이 맞을 확률\n",
        "loss = ['binary_crossentropy', 'categorical_crossentropy']\n",
        "\n",
        "discriminator.compile(loss=loss, optimizer=optimizer, metrics = ['accuracy'])\n",
        "\n",
        "discriminator.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "discriminator_input (InputLayer [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 28, 28, 1)    0           discriminator_input[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 14, 14, 32)   832         leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 14, 14, 32)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 7, 7, 64)     51264       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 7, 7, 64)     0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 4, 4, 128)    204928      leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 4, 4, 128)    0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 4, 4, 256)    819456      leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 4096)         0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            4097        flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          524416      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 1)            0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1290        dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,606,283\n",
            "Trainable params: 1,606,283\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE91fq97a4OV",
        "outputId": "d268207f-686f-466c-8d0c-ec78f73ee8ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "# 생성기 모델 구성\n",
        "input_shape = (latent_size,)\n",
        "inputs = Input(shape=input_shape, name='z_input')\n",
        "labels = Input(shape=label_shape, name='labels')\n",
        "\n",
        "#입력 레이블로 생성기 빌더 함수 호출\n",
        "generator = build_generator(inputs, image_size, labels=labels)\n",
        "generator.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "z_input (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "labels (InputLayer)             [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 110)          0           z_input[0][0]                    \n",
            "                                                                 labels[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 6272)         696192      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 7, 7, 128)    0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 7, 7, 128)    512         reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 7, 7, 128)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 14, 14, 128)  409728      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 14, 14, 128)  512         conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 14, 14, 128)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 28, 28, 64)   204864      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 28, 28, 64)   256         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 28, 28, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 28, 28, 32)   51232       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 28, 28, 32)   128         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 28, 28, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 28, 28, 1)    801         activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 28, 28, 1)    0           conv2d_transpose_7[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 1,364,225\n",
            "Trainable params: 1,363,521\n",
            "Non-trainable params: 704\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS8e_kGHb8XI",
        "outputId": "1759dc62-25f8-439d-ff62-86f9f6ea2ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "# 적대적 모델 구성 \n",
        "optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
        "discriminator.trainable = False\n",
        "adversarial = Model([inputs,labels], discriminator(generator([inputs, labels])), name=model_name)\n",
        "\n",
        "#판별기와 동일한 2개 손실 함수 사용: 1) 이미지가 진짜일 확률, 2) 이미지 클래스 레이블이 맞을 확률\n",
        "adversarial.compile(loss=loss, optimizer=optimizer, metrics = ['accuracy'])\n",
        "adversarial.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"acgan_mnist\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "z_input (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "labels (InputLayer)             [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "generator (Functional)          (None, 28, 28, 1)    1364225     z_input[0][0]                    \n",
            "                                                                 labels[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "discriminator (Functional)      [(None, 1), (None, 1 1606283     generator[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,970,508\n",
            "Trainable params: 1,363,521\n",
            "Non-trainable params: 1,606,987\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ3zT0kecjqK"
      },
      "source": [
        "#훈련함수 input 형태로 변경\n",
        "models = (generator, discriminator, adversarial)\n",
        "data = (x_train, y_train)\n",
        "params = (batch_size, latent_size, train_steps, num_labels, model_name)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWG0yCMhe5_J"
      },
      "source": [
        "def train(models, data, params):\n",
        "  \"\"\"\n",
        "  판별기와 적대적 네트워크를 배치단위로 교대로 훈련 \n",
        "  먼저 판별기가 진짜와 가짜 이미지, 그에 해당하는 원- 핫 레이블을 사용해 훈련됨\n",
        "  다음으로 적대적 네트워크가 진짜인 척하는 가짜 이미지와 그에 해당하는 원-핫 레이블 사용해 운련됨\n",
        "  \"\"\"\n",
        "\n",
        "  # 입력 인수 \n",
        "  \"\"\"\n",
        "  models (list): 생성기, 판별기, 적대적 모델\n",
        "  data(list): x_train, y_train 데이터\n",
        "  params(list): 네트워크 매개변수\n",
        "  \"\"\"\n",
        "\n",
        "  # GAN 모델 \n",
        "  generator, discriminator, adversarial = models\n",
        "  # 이미지 레이블 \n",
        "  x_train, y_train = data  \n",
        "  # 네트워크 매개변수\n",
        "  batch_size, latent_size, train_steps, num_labels, model_name = params\n",
        "\n",
        "  # 생성기의 이미지는 500 epochs 마다 저장됨\n",
        "  save_interval = 500\n",
        "  # 훈련하는 동안 생성기 출력을 보여주기 위한 노이즈 벡터\n",
        "  noise_input = np.random.uniform(-1.0, 1.0, size=[16,latent_size])\n",
        "\n",
        "  #노이즈에 조건을 부여할 원-핫 레이블\n",
        "  noise_class = np.eye(num_labels)[np.arange(0, 16) % num_labels]\n",
        "  \n",
        "  # 훈련 데이터 세트의 요소 개수 \n",
        "  train_size = x_train.shape[0]\n",
        "\n",
        "  print(model_name, \"Labels for generated images:\", np.argmax(noise_class,axis=1))\n",
        "\n",
        "  for i in range(train_steps):\n",
        "    # 1 배치 에 대한 판별기 훈련 \n",
        "    \n",
        "    # 데이터 세트에서 진짜 이미지를 임의로 선정\n",
        "    rand_indices = np.random.randint(0, train_size, size=batch_size)\n",
        "    real_images = x_train[rand_indices]\n",
        "    # 대응하는 원-핫 레이블 생성 \n",
        "    real_labels = y_train[rand_indices]\n",
        "\n",
        "    #생성기를 사용해 노이즈로 부터 가짜 이미지 생성\n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
        "    \n",
        "    #임의의 원-핫 레이블 할당\n",
        "    fake_labels = np.eye(num_labels)[np.random.choice(num_labels, batch_size)]\n",
        "    #가짜레이블 조건으로 하는 가짜이미지 생성\n",
        "    fake_images = generator.predict([noise, fake_labels])\n",
        "\n",
        "    #진짜 이미지 + 가짜이미지 를 1배치 훈련데이터로 사용\n",
        "    x = np.concatenate((real_images, fake_images))\n",
        "    labels = np.concatenate((real_labels, fake_labels))\n",
        "\n",
        "    #진짜와 가짜 이미지에 레이블을 붙임\n",
        "    #진짜이미지 레이블은 1, 가짜 이미지 레이블은 0\n",
        "    y = np.ones([2*batch_size,1])\n",
        "    y[batch_size:,:] = 0.0\n",
        "\n",
        "    #판별기 네트워크 훈련, 손실과 정확도 기록\n",
        "    #['loss', 'activation_1_loss', 'label_loss, 'activation_1_acc', ' label_acc'] 로 생성\n",
        "    metrics = discriminator.train_on_batch(x,[y, labels])\n",
        "    fmt = \"%d: [disc loss: %f, srcloss: %f, lblloss:$f, srcacc: %f, lblacc: %f]\"\n",
        "    log = fmt %(i, metrics[0],metrics[1],metrics[2],metrics[3],metrics[4])\n",
        "\n",
        "    #1 배치에 대한 적대적 네트워크 훈련\n",
        "    #레이블이 1인 가짜 원핫 레이블을 조건으로 하는 가짜 이미지의 1배치\n",
        "    #적대적 네으퉈크에서 파별기의 가중치는 고정되기 때문에 생성기만 훈련이된다. \n",
        "\n",
        "    #균등분포를 통해 노이즈 생성 \n",
        "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size,latent_size])\n",
        "\n",
        "    #임의의 원-핫 레이블 할당\n",
        "    fake_labels = np.eye(num_labels)[np.random.choice(num_labels,batch_size)]\n",
        "\n",
        "    # 가짜 이미지에 진짜로 속이는 레이블을 붙임\n",
        "    y = np.ones([batch_size, 1])\n",
        "    \n",
        "    #적대적 네으퉈크 훈련\n",
        "    #판별기 훈련과 달리 변수에 가짜 이미지를 별도의 변수로 저장하지 않으며, 분류를 위해 가짜 이미지는 적대적 네트워크의 판별기 입력으로 전달됨\n",
        "\n",
        "    #log 기록\n",
        "    metrics = adversarial.train_on_batch([noise, fake_labels],[y, fake_labels])\n",
        "    fmt = \"%s: [advr loss: %f, srcloss: %f, lblloss:$f, srcacc: %f, lblacc: %f]\"\n",
        "    log = fmt%(log, metrics[0],metrics[1],metrics[2],metrics[3],metrics[4])\n",
        "    print(log)\n",
        "\n",
        "    if (i+1) % save_interval == 0:\n",
        "      if (i+1) == train_steps:\n",
        "        show = True\n",
        "      else:\n",
        "        show = False\n",
        "\n",
        "      plot_images(generator, noise_input=noise_input,noise_class=noise_class,show=show, step=(i+1), model_name=model_name) \n",
        "\n",
        "  generator.save(model_name+\".h5\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXSKoeA0jpcq"
      },
      "source": [
        "train(models, data, params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UaFLA45jtuT"
      },
      "source": [
        "def test_generator(generator, class_label=None):\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
        "    step = 0\n",
        "    if class_label is None:\n",
        "        num_labels = 10\n",
        "        noise_class = np.eye(num_labels)[np.random.choice(num_labels, 16)]\n",
        "    else:\n",
        "        noise_class = np.zeros((16, 10))\n",
        "        noise_class[:,class_label] = 1\n",
        "        step = class_label\n",
        "\n",
        "    plot_images(generator,\n",
        "                noise_input=noise_input,\n",
        "                noise_class=noise_class,\n",
        "                show=True,\n",
        "                step=step,\n",
        "                model_name=\"test_outputs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQAz5cqSj0SA"
      },
      "source": [
        "class_label = None\n",
        "test_generator(generator, class_label)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}