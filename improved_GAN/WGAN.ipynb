{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYA5qCdiOcXUwbPZdu9Hv2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansong0219/Advanced-DeepLearning-Study/blob/master/improved_GAN/WGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgURjbwjdbHK"
      },
      "source": [
        "# WGAN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEDKe3EwZMbx"
      },
      "source": [
        "from tensorflow.keras.layers import Activation, Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyAITo6EiCEC"
      },
      "source": [
        "# 생성기와 판별기 등 함수 구성 \n",
        "생성기와 판별기의 함수는 DCGAN의 구성을 그대로 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXUDGEiHiC-C"
      },
      "source": [
        "\n",
        "def generator(inputs,\n",
        "              image_size,\n",
        "              activation='sigmoid'):\n",
        "\n",
        "    image_resize = image_size // 4\n",
        "    kernel_size = 5\n",
        "    layer_filters = [128, 64, 32, 1]\n",
        "\n",
        "    x = Dense(image_resize * image_resize * layer_filters[0])(x)\n",
        "    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n",
        "\n",
        "    for filters in layer_filters:\n",
        "        if filters > layer_filters[-2]:\n",
        "            strides = 2\n",
        "        else:\n",
        "            strides = 1\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=filters,\n",
        "                            kernel_size=kernel_size,\n",
        "                            strides=strides,\n",
        "                            padding='same')(x)\n",
        "\n",
        "    if activation is not None:\n",
        "        x = Activation(activation)(x)\n",
        "\n",
        "    return Model(inputs, x, name='generator')\n",
        "\n",
        "\n",
        "def discriminator(inputs,\n",
        "                  activation='sigmoid'):\n",
        "\n",
        "    kernel_size = 5\n",
        "    layer_filters = [32, 64, 128, 256]\n",
        "\n",
        "    x = inputs\n",
        "    for filters in layer_filters:\n",
        "        # first 3 convolution layers use strides = 2\n",
        "        # last one uses strides = 1\n",
        "        if filters == layer_filters[-1]:\n",
        "            strides = 1\n",
        "        else:\n",
        "            strides = 2\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        x = Conv2D(filters=filters,\n",
        "                   kernel_size=kernel_size,\n",
        "                   strides=strides,\n",
        "                   padding='same')(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    # default output is probability that the image is real\n",
        "    outputs = Dense(1)(x)\n",
        "    if activation is not None:\n",
        "        print(activation)\n",
        "        outputs = Activation(activation)(outputs)\n",
        "\n",
        "    return Model(inputs, outputs, name='discriminator')\n",
        "\n",
        "\n",
        "def plot_images(generator,\n",
        "                noise_input,\n",
        "                noise_label=None,\n",
        "                noise_codes=None,\n",
        "                show=False,\n",
        "                step=0,\n",
        "                model_name=\"gan\"):\n",
        "  \n",
        "    os.makedirs(model_name, exist_ok=True)\n",
        "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
        "    rows = int(math.sqrt(noise_input.shape[0]))\n",
        "    if noise_label is not None:\n",
        "        noise_input = [noise_input, noise_label]\n",
        "        if noise_codes is not None:\n",
        "            noise_input += noise_codes\n",
        "\n",
        "    images = generator.predict(noise_input)\n",
        "    plt.figure(figsize=(2.2, 2.2))\n",
        "    num_images = images.shape[0]\n",
        "    image_size = images.shape[1]\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(rows, rows, i + 1)\n",
        "        image = np.reshape(images[i], [image_size, image_size])\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.savefig(filename)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close('all')\n",
        "\n",
        "\n",
        "def test_generator(generator):\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
        "    plot_images(generator,\n",
        "                noise_input=noise_input,\n",
        "                show=True,\n",
        "                model_name=\"test_outputs\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y87zX4F7koYU"
      },
      "source": [
        "# WGAN 구현 \n",
        "\n",
        "GAN 과 유사하게 생성기와 판별기를 교대로 훈련 시키지만 구현에 있어서 WGAN 의 가장 큰 특징은 Wasserstein Loss 를 사용함과 동시에 생성기를 1회 훈련시키기전에 판별기를 n 회 훈련 시킨다. \n",
        "\n",
        "이는 생성기와 판별기를 동일한 횟수로 훈련시키는 GAN 과는 다른 점이다. 판별기를 훈련시킨다는 것은 판별기의 매개변수를 학습한다는 것을 뜻한다. \n",
        "\n",
        "또, EMD의 제약 조건을 만족 시키기 위해 위해 립시츠 제약에 대한 변수 또한 필요하다. 립시츠 조건이란 두 점사이의 거리를 일정 비율 이상 증가시키지 않는다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b38xV9Mhksoy"
      },
      "source": [
        "def build_and_train_models():\n",
        "  #MNIST 데이터 세트 로딩\n",
        "  (x_train,_),(_,_) = mnist.load_data()\n",
        "\n",
        "  # 데이터 형상 변환 및 정규화\n",
        "  image_size = x_train.shape[1]\n",
        "  x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
        "  x_train = x_train.astype('float32')/255\n",
        "  \n",
        "  model_name = \"wgan_mnist\"\n",
        "\n",
        "  #네트워크 매개 변수 지정 \n",
        "  latent_size = 100\n",
        "  \n",
        "  n_critic = 5\n",
        "  clip_value = 0.01\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}