{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNet_upsample.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXTY190NqxuI6//uIas1kf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansong0219/Advanced-DeepLearning-Study/blob/master/UNET/UNet_upsample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hu4wcC1vdzP"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from tensorflow.keras.layers import Input, Dropout, Concatenate\n",
        "from tensorflow.keras.layers import Conv2DTranspose, Conv2D, UpSampling2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LeakyReLU, Activation\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBCQidy_viF5"
      },
      "source": [
        "import tensorflow as tf \n",
        "physical_devices =tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
        "tf.config.experimental.set_memory_growth(physical_devices[1],True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewb_nuRavjwn"
      },
      "source": [
        "def down_sample(layer_inputs,filters, size, apply_batchnorm=True):\n",
        "    initializer = tf.random_normal_initializer(0.,0.02)\n",
        "    d = Conv2D(filters, size, strides=1,padding='same', kernel_initializer=initializer, use_bias=False)(layer_inputs)\n",
        "    if apply_batchnorm:\n",
        "        d = BatchNormalization()(d)\n",
        "    \n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    d = MaxPooling2D(pool_size=(2, 2))(d)\n",
        "    return d\n",
        "\n",
        "def up_sample(layer_inputs, skip_input,filters, size, dropout_rate=0):\n",
        "    initializer = tf.random_normal_initializer(0.,0.02)\n",
        "    u = UpSampling2D(size=(2,2), interpolation = 'bilinear')(layer_inputs)\n",
        "    u = Conv2D(filters, size, strides=1,padding='same', kernel_initializer=initializer,use_bias=False)(u)\n",
        "    if dropout_rate:\n",
        "        u = Dropout(dropout_rate)(u)\n",
        "    \n",
        "    u = tf.keras.layers.ReLU()(u)\n",
        "    u = Concatenate()([u, skip_input])\n",
        "    return u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJrLq-savlm9"
      },
      "source": [
        "def Build_UNET():\n",
        "    input_shape = (256,256,3)\n",
        "    output_channel = 3\n",
        "    inputs = Input(shape=input_shape,name=\"inputs\")\n",
        "    \n",
        "    d1 = down_sample(inputs, 64, 3, apply_batchnorm=False) #(128,128,3)\n",
        "    d2 = down_sample(d1, 128, 3) #(64,64,128)\n",
        "    d3 = down_sample(d2, 256, 3)\n",
        "    d4 = down_sample(d3, 512, 3)\n",
        "    d5 = down_sample(d4, 512, 3)\n",
        "    d6 = down_sample(d5, 512, 3)\n",
        "    d7 = down_sample(d6, 512, 3)\n",
        "    d8 = down_sample(d7, 512, 3)\n",
        "    \n",
        "    u7 = up_sample(d8, d7, 512, 3, dropout_rate = 0.5)\n",
        "    u6 = up_sample(u7, d6, 512, 3, dropout_rate = 0.5)\n",
        "    u5 = up_sample(u6, d5, 512, 3)\n",
        "    u4 = up_sample(u5, d4, 512, 3)\n",
        "    u3 = up_sample(u4, d3, 256, 3)\n",
        "    u2 = up_sample(u3, d2, 128, 3)\n",
        "    u1 = up_sample(u2, d1, 64, 3)\n",
        "    \n",
        "    initializer = tf.random_normal_initializer(0.,0.02)\n",
        "    u0 = UpSampling2D(size=(2,2),interpolation='bilinear')(u1)\n",
        "    outputs = Conv2D(output_channel,\n",
        "                     kernel_size=4, \n",
        "                     strides=1, \n",
        "                     padding='same', \n",
        "                     kernel_initializer=initializer, \n",
        "                     activation='tanh')(u0)\n",
        "    \n",
        "    return Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzVIwS-PvnRY"
      },
      "source": [
        "unet = Build_UNET()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj_1JkFCvo2q"
      },
      "source": [
        "loss=BinaryCrossentropy(from_logits=True)\n",
        "optimizer = Adam(1e-4, beta_1=0.5)\n",
        "unet.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}