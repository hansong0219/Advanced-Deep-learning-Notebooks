{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet_CIFAR10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPdpg1ltJqeXFojbkt+gAfn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansong0219/Advanced-DeepLearning-Study/blob/master/CNN_based_Classification/DenseNet_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xP6ptNATvmr"
      },
      "source": [
        "# DenseNet\n",
        "\n",
        "DenseNet 은 ResNet 과 다른 방법으로 경사 소실 문제를 해결한다. 숏컷 연결을 사용하는 대신 , 이전 특징 맵 전체가 다음 계층의 입력이 된다. Conv2D 는 크기가 3인 커널을 사용한다. 계층마다 생성되는 특징맵의 개수를 성장률 k라고 할 때, 일반적으로 k = 12 를 사용하지만 , DenseNet 은 그보다 많은 성장률을 사용한다. 따라서 특징 맵의 개수가 k0 일때, 4개 계층으로 구성된 밀집 계층의 끝에서 특징맵의 전체 개수는 4 x k + k0가 된다.\n",
        "\n",
        "DenseNet도 BN-ReLU-Conv2D 뒤에 밀집 블록을 배치하여, 성장률 k0 = 2 x K 로 특징맵의 개수가 두배가 되기도 한다.\n",
        "\n",
        "DenseNet은 출력계층에서 Dense() 와 softmax 분류모델 전에 average pooling 을 수행하기를 권장한다. 데이터 확장을 사용하지 않는다면, 드롭아웃 계층이 밀집블록 Conv2D 다음에 와야 한다.\n",
        "\n",
        "네트워크가 깊어질수록 두 가지의 새로운 문제가 발생하는데, 먼저 모든 계층은 k 개의 특징 맵을 생성하기 때문에 계층 ㅣ에서의 입력 개수는 (l-1) x k + k0 이다. 그에 따라 특징 맵이 깊은 계층에서 급속도로 커지기 때문에 계산 속도가 느려진다. 둘째로 ResNet 과 유사하게 네트워크가 깊어질수록 특징 맵 크기가 줄어들면서 커널의 범위가 늘어난다. 따라서, DenseNet이 병합 연산에서 연결(concatenation)을 사용한다면, 크기의 차이를 일치 시켜야 한다.\n",
        "\n",
        "이와 같이 특징 맵의 개수가 계산상 비효율 지점까지 증가하는 것을 막기 위해 DenseNet 구조에는 병목 계층이 도입되어 있다. 모든 연결 후에 필터 크기가 4k 인 1 x 1 합성곱이 적용된다. 이 차원 축소 기법은 Conv2D(3) 에서 처리되는 특징 맵의 개수가 빠르게 증가하는 것을 방지한다.\n",
        "\n",
        "또, 특징 맵 크기가 서로다른 문제를 해결하기 위해 DenseNet 은 심층 신경망을 여러 밀집 블록으로 나누고 전이계층을 통해 서로 연결되게 만들었다. 각 밀집 블록 내에서 특징맵 크기는 일정하다. 전이 계층의 역할은 두 밀집 블록 사이에서 한 특징 맵 크기에서 더 작은 특징 맵 크기로 바꾸는 것이다. 이는 average pooling 계층에 의해서 수행된다. 특징맵이 애버리지 풀링으로 전달되기 전에 Conv2D(1) 을 사용해 그 개수를 특정 압축 비로 줄이는데 보통 이 압축 비는 0.5를 사용한다.\n",
        "\n",
        "위의 DenseNet 에대한 설계 원칙을 적용시 DenseNet-BC(Bottleneck-Compression) 으로 구성할 수 있다. 여기서 한가지 기억해두어야 할 점은 DenseNet 은 Adam 보다 더 잘 수렴하는 optimizer 인 RMSprop 을 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6G56YMnTgdw"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Input, Flatten, Dropout\n",
        "from tensorflow.keras.layers import concatenate, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWq7eF46T3lR"
      },
      "source": [
        "# training parameters\n",
        "batch_size = 32\n",
        "epochs = 200\n",
        "data_augmentation = True\n",
        "\n",
        "# network parameters\n",
        "num_classes = 10\n",
        "num_dense_blocks = 3\n",
        "use_max_pool = False\n",
        "\n",
        "# DenseNet-BC with dataset augmentation\n",
        "# Growth rate   | Depth |  Accuracy (paper)| Accuracy (this)      |\n",
        "# 12            | 100   |  95.49%          | 93.74%               |\n",
        "# 24            | 250   |  96.38%          | requires big mem GPU |\n",
        "# 40            | 190   |  96.54%          | requires big mem GPU |\n",
        "growth_rate = 12\n",
        "depth = 100\n",
        "num_bottleneck_layers = (depth - 4) // (2 * num_dense_blocks)\n",
        "\n",
        "num_filters_bef_dense_block = 2 * growth_rate\n",
        "compression_factor = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVj4ZkZiT5R6"
      },
      "source": [
        "# load the CIFAR10 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# input image dimensions\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# mormalize data\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# convert class vectors to binary class matrices.\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWu5OpzWT6uZ"
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    \n",
        "    print('Learning rate: ', lr)\n",
        "    \n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6QP6GdMT8KL"
      },
      "source": [
        "# start model definition\n",
        "# densenet CNNs (composite function) are made of BN-ReLU-Conv2D\n",
        "inputs = Input(shape=input_shape)\n",
        "x = BatchNormalization()(inputs)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(num_filters_bef_dense_block,\n",
        "           kernel_size=3,\n",
        "           padding='same',\n",
        "           kernel_initializer='he_normal')(x)\n",
        "x = concatenate([inputs, x])\n",
        "\n",
        "# stack of dense blocks bridged by transition layers\n",
        "for i in range(num_dense_blocks):\n",
        "    # a dense block is a stack of bottleneck layers\n",
        "    for j in range(num_bottleneck_layers):\n",
        "        #Bottlenec Layers\n",
        "        y = BatchNormalization()(x)\n",
        "        y = Activation('relu')(y)\n",
        "        y = Conv2D(4 * growth_rate,\n",
        "                   kernel_size=1,\n",
        "                   padding='same',\n",
        "                   kernel_initializer='he_normal')(y)\n",
        "        \n",
        "        if not data_augmentation:\n",
        "            y = Dropout(0.2)(y)\n",
        "        \n",
        "        #Conv2D(3)\n",
        "        y = BatchNormalization()(y)\n",
        "        y = Activation('relu')(y)\n",
        "        y = Conv2D(growth_rate,\n",
        "                   kernel_size=3,\n",
        "                   padding='same',\n",
        "                   kernel_initializer='he_normal')(y)\n",
        "        \n",
        "        if not data_augmentation:\n",
        "            y = Dropout(0.2)(y)\n",
        "        x = concatenate([x, y])\n",
        "\n",
        "    # no transition layer after the last dense block\n",
        "    if i == num_dense_blocks - 1:\n",
        "        continue\n",
        "\n",
        "    # transition layer compresses num of feature maps and reduces the size by 2\n",
        "    num_filters_bef_dense_block += num_bottleneck_layers * growth_rate\n",
        "    num_filters_bef_dense_block = int(num_filters_bef_dense_block * compression_factor)\n",
        "    \n",
        "    y = BatchNormalization()(x)\n",
        "    y = Conv2D(num_filters_bef_dense_block,\n",
        "               kernel_size=1,\n",
        "               padding='same',\n",
        "               kernel_initializer='he_normal')(y)\n",
        "    if not data_augmentation:\n",
        "        y = Dropout(0.2)(y)\n",
        "    x = AveragePooling2D()(y)\n",
        "\n",
        "\n",
        "# add classifier on top\n",
        "# after average pooling, size of feature map is 1 x 1\n",
        "x = AveragePooling2D(pool_size=8)(x)\n",
        "y = Flatten()(x)\n",
        "outputs = Dense(num_classes,\n",
        "                kernel_initializer='he_normal',\n",
        "                activation='softmax')(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ufpKdnlT_kC"
      },
      "source": [
        "# instantiate and compile model\n",
        "# orig paper uses SGD but RMSprop works better for DenseNet\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(1e-3),\n",
        "              metrics=['acc'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"cifar10-densenet.png\", show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fANDXYDFUBNz"
      },
      "source": [
        "# run training, with or without data augmentation\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # preprocessing  and realtime data augmentation\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (deg 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally\n",
        "        height_shift_range=0.1,  # randomly shift images vertically\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied)\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    steps_per_epoch = math.ceil(len(x_train) / batch_size)\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    model.fit(x=datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "              verbose=1,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              steps_per_epoch=steps_per_epoch,\n",
        "              callbacks=callbacks)\n",
        "\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow()\n",
        "    #model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    ##                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "    #                    validation_data=(x_test, y_test),\n",
        "    #                    epochs=epochs, verbose=1,\n",
        "    #                    callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc-7yoGVUCIf"
      },
      "source": [
        "# score trained model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}